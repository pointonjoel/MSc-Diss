{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preamble\n",
    "import PyPDF2 # For parsing PDF documents\n",
    "import ast  # covert embeddings saved as strings back to arrays\n",
    "import openai  # OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import tiktoken  # for counting tokens\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "import wikipedia # For sourcing Wikipedia article text\n",
    "import re  # for cutting <ref> links out of Wikipedia articles\n",
    "import mwparserfromhell  # for splitting Wikipedia articles into sections\n",
    "from copy import deepcopy # for copying dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Config\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "SAVE_PATH = \"assets/computer_vision_wiki_embeddings.csv\"\n",
    "BATCH_SIZE = 1000  # you can submit up to 2048 embedding inputs per request\n",
    "CHATBOT_KNOWLEDGE_TOPIC = \"Computer Vision\"\n",
    "ANSWER_NOT_FOUND_MSG = \"I could not find an answer in the text I\\'ve been provided, sorry! Please try again.\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 sections.\n",
      "0. ['Computer vision']: Computer vision tasks include \n",
      "1. ['Computer vision', '== Definition ==']: \n",
      "Computer vision is an interdi\n",
      "2. ['Computer vision', '== History ==']: \n",
      "In the late 1960s, computer v\n",
      "3. ['Computer vision', '== Related fields ==']: \n",
      "\n",
      "\n",
      "\n",
      "4. ['Computer vision', '== Related fields ==', '=== Solid-state physics ===']: \n",
      "Solid-state physics is anothe\n",
      "5. ['Computer vision', '== Related fields ==', '=== Neurobiology ===']: \n",
      "Neurobiology has greatly infl\n",
      "6. ['Computer vision', '== Related fields ==', '=== Signal processing ===']: \n",
      "Yet another field related to \n",
      "7. ['Computer vision', '== Related fields ==', '=== Robotic navigation ===']: \n",
      "Robot navigation sometimes de\n",
      "8. ['Computer vision', '== Related fields ==', '=== Other fields ===']: \n",
      "Besides the above-mentioned v\n",
      "9. ['Computer vision', '== Related fields ==', '=== Distinctions ===']: \n",
      "The fields most closely relat\n",
      "10. ['Computer vision', '== Applications ==']: \n",
      "Applications range from tasks\n",
      "11. ['Computer vision', '== Applications ==', '=== Medicine ===']: \n",
      "\n",
      "One of the most prominent ap\n",
      "12. ['Computer vision', '== Applications ==', '=== Machine vision ===']: \n",
      "A second application area in \n",
      "13. ['Computer vision', '== Applications ==', '=== Military ===']: \n",
      "Military applications are pro\n",
      "14. ['Computer vision', '== Applications ==', '=== Autonomous vehicles ===']: \n",
      "\n",
      "One of the newer application\n",
      "15. ['Computer vision', '== Applications ==', '=== Tactile feedback ===']: \n",
      "\n",
      "Materials such as rubber and\n",
      "16. ['Computer vision', '== Typical tasks ==']: \n",
      "Each of the application areas\n",
      "17. ['Computer vision', '== Typical tasks ==', '=== Recognition ===']: \n",
      "The classical problem in comp\n",
      "18. ['Computer vision', '== Typical tasks ==', '=== Motion analysis ===']: \n",
      "Several tasks relate to motio\n",
      "19. ['Computer vision', '== Typical tasks ==', '=== Scene reconstruction ===']: \n",
      "Given one or (typically) more\n",
      "20. ['Computer vision', '== Typical tasks ==', '=== Image restoration ===']: \n",
      "Image restoration comes into \n",
      "21. ['Computer vision', '== System methods ==']: \n",
      "The organization of a compute\n",
      "22. ['Computer vision', '== System methods ==', '=== Image-understanding systems ===']: \n",
      "Image-understanding systems (\n",
      "23. ['Computer vision', '== Hardware ==']: \n",
      "\n",
      "There are many kinds of comp\n"
     ]
    }
   ],
   "source": [
    "SECTIONS_TO_IGNORE = [\n",
    "    \"See also\",\n",
    "    \"References\",\n",
    "    \"External links\",\n",
    "    \"Further reading\",\n",
    "    \"Footnotes\",\n",
    "    \"Bibliography\",\n",
    "    \"Sources\",\n",
    "    \"Citations\",\n",
    "    \"Literature\",\n",
    "    \"Footnotes\",\n",
    "    \"Notes and references\",\n",
    "    \"Photo gallery\",\n",
    "    \"Works cited\",\n",
    "    \"Photos\",\n",
    "    \"Gallery\",\n",
    "    \"Notes\",\n",
    "    \"References and sources\",\n",
    "    \"References and notes\",\n",
    "]\n",
    "\n",
    "WIKI_PAGE = \"Computer vision\"\n",
    "\n",
    "def all_subsections_from_section(\n",
    "    section: mwparserfromhell.wikicode.Wikicode,\n",
    "    parent_titles: list[str],\n",
    "    sections_to_ignore: set[str],\n",
    ") -> list[tuple[list[str], str]]:\n",
    "    \"\"\"\n",
    "    From a Wikipedia section, return a flattened list of all nested subsections.\n",
    "    Each subsection is a tuple, where:\n",
    "        - the first element is a list of parent subtitles, starting with the page title\n",
    "        - the second element is the text of the subsection (but not any children)\n",
    "    \"\"\"\n",
    "    headings = [str(h) for h in section.filter_headings()]\n",
    "    title = headings[0]\n",
    "    if title.strip(\"=\" + \" \") in sections_to_ignore:\n",
    "        # ^wiki headings are wrapped like \"== Heading ==\"\n",
    "        return []\n",
    "    titles = parent_titles + [title]\n",
    "    full_text = str(section)\n",
    "    section_text = full_text.split(title)[1]\n",
    "    if len(headings) == 1:\n",
    "        return [(titles, section_text)]\n",
    "    else:\n",
    "        first_subtitle = headings[1]\n",
    "        section_text = section_text.split(first_subtitle)[0]\n",
    "        results = [(titles, section_text)]\n",
    "        for subsection in section.get_sections(levels=[len(titles) + 1]):\n",
    "            results.extend(all_subsections_from_section(subsection, titles, sections_to_ignore))\n",
    "        return results\n",
    "\n",
    "def all_subsections_from_title(\n",
    "    title: str = WIKI_PAGE,\n",
    "    sections_to_ignore: set[str] = SECTIONS_TO_IGNORE,\n",
    ") -> list[tuple[list[str], str]]:\n",
    "    \"\"\"From a Wikipedia page title, return a flattened list of all nested subsections.\n",
    "    Each subsection is a tuple, where:\n",
    "        - the first element is a list of parent subtitles, starting with the page title\n",
    "        - the second element is the text of the subsection (but not any children)\n",
    "    \"\"\"\n",
    "    site = wikipedia.page(title, auto_suggest=False)\n",
    "    text = site.content\n",
    "    parsed_text = mwparserfromhell.parse(text)\n",
    "    headings = [str(h) for h in parsed_text.filter_headings()]\n",
    "    if headings:\n",
    "        summary_text = str(parsed_text).split(headings[0])[0]\n",
    "    else:\n",
    "        summary_text = str(parsed_text)\n",
    "    results = [([title], summary_text)]\n",
    "    for subsection in parsed_text.get_sections(levels=[2]):\n",
    "        results.extend(all_subsections_from_section(subsection, [title], sections_to_ignore))\n",
    "    return results\n",
    "\n",
    "# split pages into sections\n",
    "# may take ~1 minute per 100 articles\n",
    "wikipedia_sections = []\n",
    "wikipedia_sections.extend(all_subsections_from_title(WIKI_PAGE))\n",
    "print(f\"Found {len(wikipedia_sections)} sections.\")\n",
    "i=0\n",
    "for tup in wikipedia_sections:\n",
    "    print(f'{i}. {tup[0]}: {str(tup[1])[0:30]}')\n",
    "    i+=1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered out 1 sections, leaving 23 sections.\n"
     ]
    }
   ],
   "source": [
    "# clean text\n",
    "def clean_section(section: tuple[list[str], str]) -> tuple[list[str], str]:\n",
    "    \"\"\"\n",
    "    Return a cleaned up section with:\n",
    "        - <ref>xyz</ref> patterns removed\n",
    "        - leading/trailing whitespace removed\n",
    "    \"\"\"\n",
    "    titles, text = section\n",
    "    text = re.sub(r\"<ref.*?</ref>\", \"\", text)\n",
    "    text = text.strip()\n",
    "    return (titles, text)\n",
    "\n",
    "\n",
    "wikipedia_sections = [clean_section(ws) for ws in wikipedia_sections]\n",
    "\n",
    "# filter out short/blank sections\n",
    "def keep_section(section: tuple[list[str], str]) -> bool:\n",
    "    \"\"\"Return True if the section should be kept, False otherwise.\"\"\"\n",
    "    titles, text = section\n",
    "    if len(text) < 16:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "\n",
    "original_num_sections = len(wikipedia_sections)\n",
    "wikipedia_sections = [ws for ws in wikipedia_sections if keep_section(ws)]\n",
    "print(f\"Filtered out {original_num_sections-len(wikipedia_sections)} sections, leaving {len(wikipedia_sections)} sections.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 Wikipedia sections split into 23 strings.\n"
     ]
    }
   ],
   "source": [
    "# recursively split long sections into smaller sections.\n",
    "\n",
    "def num_tokens(text: str, model: str = GPT_MODEL) -> int:\n",
    "    \"\"\"Return the number of tokens in a string.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "\n",
    "def halved_by_delimiter(string: str, delimiter: str = \"\\n\") -> list[str, str]:\n",
    "    \"\"\"Split a string in two, on a delimiter, trying to balance tokens on each side.\"\"\"\n",
    "    chunks = string.split(delimiter)\n",
    "    if len(chunks) == 1:\n",
    "        return [string, \"\"]  # no delimiter found\n",
    "    elif len(chunks) == 2:\n",
    "        return chunks  # no need to search for halfway point\n",
    "    else:\n",
    "        total_tokens = num_tokens(string)\n",
    "        halfway = total_tokens // 2\n",
    "        best_diff = halfway\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            left = delimiter.join(chunks[: i + 1])\n",
    "            left_tokens = num_tokens(left)\n",
    "            diff = abs(halfway - left_tokens)\n",
    "            if diff >= best_diff:\n",
    "                break\n",
    "            else:\n",
    "                best_diff = diff\n",
    "        left = delimiter.join(chunks[:i])\n",
    "        right = delimiter.join(chunks[i:])\n",
    "        return [left, right]\n",
    "\n",
    "\n",
    "def truncated_string(\n",
    "    string: str,\n",
    "    model: str,\n",
    "    max_tokens: int,\n",
    "    print_warning: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"Truncate a string to a maximum number of tokens.\"\"\"\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    encoded_string = encoding.encode(string)\n",
    "    truncated_string = encoding.decode(encoded_string[:max_tokens])\n",
    "    if print_warning and len(encoded_string) > max_tokens:\n",
    "        print(f\"Warning: Truncated string from {len(encoded_string)} tokens to {max_tokens} tokens.\")\n",
    "    return truncated_string\n",
    "\n",
    "\n",
    "def split_strings_from_subsection(\n",
    "    subsection: tuple[list[str], str],\n",
    "    max_tokens: int = 1000,\n",
    "    model: str = GPT_MODEL,\n",
    "    max_recursion: int = 5,\n",
    ") -> list[str]:\n",
    "    \"\"\"\n",
    "    Split a subsection into a list of subsections, each with no more than max_tokens.\n",
    "    Each subsection is a tuple of parent titles [H1, H2, ...] and text (str).\n",
    "    \"\"\"\n",
    "    titles, text = subsection\n",
    "    string = \"\\n\\n\".join([text])\n",
    "    num_tokens_in_string = num_tokens(string)\n",
    "    # if length is fine, return string\n",
    "    if num_tokens_in_string <= max_tokens:\n",
    "        return [string]\n",
    "    # if recursion hasn't found a split after X iterations, just truncate\n",
    "    elif max_recursion == 0:\n",
    "        return [truncated_string(string, model=model, max_tokens=max_tokens)]\n",
    "    # otherwise, split in half and recurse\n",
    "    else:\n",
    "        titles, text = subsection\n",
    "        for delimiter in [\"\\n\\n\", \"\\n\", \". \"]:\n",
    "            left, right = halved_by_delimiter(text, delimiter=delimiter)\n",
    "            if left == \"\" or right == \"\":\n",
    "                # if either half is empty, retry with a more fine-grained delimiter\n",
    "                continue\n",
    "            else:\n",
    "                # recurse on each half\n",
    "                results = []\n",
    "                for half in [left, right]:\n",
    "                    half_subsection = (titles, half)\n",
    "                    half_strings = split_strings_from_subsection(\n",
    "                        half_subsection,\n",
    "                        max_tokens=max_tokens,\n",
    "                        model=model,\n",
    "                        max_recursion=max_recursion - 1,\n",
    "                    )\n",
    "                    results.extend(half_strings)\n",
    "                return results\n",
    "    # otherwise no split was found, so just truncate (should be very rare)\n",
    "    return [truncated_string(string, model=model, max_tokens=max_tokens)]\n",
    "\n",
    "# split sections into chunks\n",
    "MAX_TOKENS = 1600\n",
    "wikipedia_strings = []\n",
    "for section in wikipedia_sections:\n",
    "    wikipedia_strings.extend(split_strings_from_subsection(section, max_tokens=MAX_TOKENS))\n",
    "\n",
    "print(f\"{len(wikipedia_sections)} Wikipedia sections split into {len(wikipedia_strings)} strings.\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Used throughout\n",
    "def num_tokens(\n",
    "        text: str,\n",
    "        encoding: tiktoken.encoding_for_model = tiktoken.encoding_for_model(GPT_MODEL)\n",
    ") -> int:\n",
    "    \"\"\"Returns the number of tokens in a string.\"\"\"\n",
    "    return len(encoding.encode(text))\n",
    "\n",
    "def get_embedding(content: str, model: str = EMBEDDING_MODEL):\n",
    "    return openai.Embedding.create(input=content, model=model)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 to 999\n"
     ]
    }
   ],
   "source": [
    "# Now that we've split our library into shorter self-contained strings, we can compute embeddings for each.\n",
    "# calculate embeddings\n",
    "\n",
    "embeddings = []\n",
    "wikipedia_strings = [str(i).removeprefix(\"\\n\") for i in wikipedia_strings]\n",
    "wikipedia_strings = [s for s in wikipedia_strings if s!='\\n\\n']\n",
    "for batch_start in range(0, len(wikipedia_strings), BATCH_SIZE):\n",
    "    batch_end = batch_start + BATCH_SIZE\n",
    "    batch = wikipedia_strings[batch_start:batch_end]\n",
    "    print(f\"Batch {batch_start} to {batch_end-1}\")\n",
    "    response = get_embedding(batch)\n",
    "    for i, be in enumerate(response[\"data\"]):\n",
    "        assert i == be[\"index\"]  # double check embeddings are in same order as input\n",
    "    batch_embeddings = [e[\"embedding\"] for e in response[\"data\"]]\n",
    "    embeddings.extend(batch_embeddings)\n",
    "\n",
    "df = pd.DataFrame({\"text\": wikipedia_strings, \"embedding\": embeddings})"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                 text  \\\n0   Computer vision tasks include methods for acqu...   \n1   Computer vision is an interdisciplinary field ...   \n2   In the late 1960s, computer vision began at un...   \n3   Solid-state physics is another field that is c...   \n4   Neurobiology has greatly influenced the develo...   \n5   Yet another field related to computer vision i...   \n6   Robot navigation sometimes deals with autonomo...   \n7   Besides the above-mentioned views on computer ...   \n8   The fields most closely related to computer vi...   \n9   Applications range from tasks such as industri...   \n10  One of the most prominent application fields i...   \n11  A second application area in computer vision i...   \n12  Military applications are probably one of the ...   \n13  One of the newer application areas is autonomo...   \n14  Materials such as rubber and silicon are being...   \n15  Each of the application areas described above ...   \n16  The classical problem in computer vision, imag...   \n17  Several tasks relate to motion estimation wher...   \n18  Given one or (typically) more images of a scen...   \n19  Image restoration comes into picture when the ...   \n20  The organization of a computer vision system i...   \n21  Image-understanding systems (IUS) include thre...   \n22  There are many kinds of computer vision system...   \n\n                                            embedding  \n0   [-0.017700279131531715, 0.000514430517796427, ...  \n1   [-0.018318993970751762, 0.001517261378467083, ...  \n2   [-0.012142791412770748, -0.0038553199265152216...  \n3   [0.0041972859762609005, 0.012276003137230873, ...  \n4   [-0.010451305657625198, -0.0007485592504963279...  \n5   [-0.029517987743020058, 0.009650111198425293, ...  \n6   [0.0059881932102143764, -0.01309896819293499, ...  \n7   [0.0016696708044037223, -0.005273657850921154,...  \n8   [-0.01812841184437275, 0.005136170424520969, 0...  \n9   [-0.022646257653832436, 0.005542135331779718, ...  \n10  [-0.014657611027359962, 0.02356996200978756, 0...  \n11  [-0.01603786274790764, 0.0009422244620509446, ...  \n12  [-0.022953981533646584, -0.001515690004453063,...  \n13  [0.001724685076624155, -0.006476707756519318, ...  \n14  [-0.013856389559805393, 0.023265909403562546, ...  \n15  [-0.018847335129976273, 0.007115695625543594, ...  \n16  [-0.0195198692381382, 0.020466286689043045, 0....  \n17  [-0.021316442638635635, 0.00012857838009949774...  \n18  [-0.02254006266593933, 0.016435734927654266, 0...  \n19  [-0.0015555588761344552, 0.031051410362124443,...  \n20  [-0.0011738382745534182, 0.027163632214069366,...  \n21  [0.0026188846677541733, -0.004435344133526087,...  \n22  [-0.005703717470169067, 0.015227568335831165, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Computer vision tasks include methods for acqu...</td>\n      <td>[-0.017700279131531715, 0.000514430517796427, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Computer vision is an interdisciplinary field ...</td>\n      <td>[-0.018318993970751762, 0.001517261378467083, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>In the late 1960s, computer vision began at un...</td>\n      <td>[-0.012142791412770748, -0.0038553199265152216...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Solid-state physics is another field that is c...</td>\n      <td>[0.0041972859762609005, 0.012276003137230873, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Neurobiology has greatly influenced the develo...</td>\n      <td>[-0.010451305657625198, -0.0007485592504963279...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Yet another field related to computer vision i...</td>\n      <td>[-0.029517987743020058, 0.009650111198425293, ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Robot navigation sometimes deals with autonomo...</td>\n      <td>[0.0059881932102143764, -0.01309896819293499, ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Besides the above-mentioned views on computer ...</td>\n      <td>[0.0016696708044037223, -0.005273657850921154,...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>The fields most closely related to computer vi...</td>\n      <td>[-0.01812841184437275, 0.005136170424520969, 0...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Applications range from tasks such as industri...</td>\n      <td>[-0.022646257653832436, 0.005542135331779718, ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>One of the most prominent application fields i...</td>\n      <td>[-0.014657611027359962, 0.02356996200978756, 0...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>A second application area in computer vision i...</td>\n      <td>[-0.01603786274790764, 0.0009422244620509446, ...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Military applications are probably one of the ...</td>\n      <td>[-0.022953981533646584, -0.001515690004453063,...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>One of the newer application areas is autonomo...</td>\n      <td>[0.001724685076624155, -0.006476707756519318, ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Materials such as rubber and silicon are being...</td>\n      <td>[-0.013856389559805393, 0.023265909403562546, ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Each of the application areas described above ...</td>\n      <td>[-0.018847335129976273, 0.007115695625543594, ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>The classical problem in computer vision, imag...</td>\n      <td>[-0.0195198692381382, 0.020466286689043045, 0....</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Several tasks relate to motion estimation wher...</td>\n      <td>[-0.021316442638635635, 0.00012857838009949774...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Given one or (typically) more images of a scen...</td>\n      <td>[-0.02254006266593933, 0.016435734927654266, 0...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Image restoration comes into picture when the ...</td>\n      <td>[-0.0015555588761344552, 0.031051410362124443,...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>The organization of a computer vision system i...</td>\n      <td>[-0.0011738382745534182, 0.027163632214069366,...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Image-understanding systems (IUS) include thre...</td>\n      <td>[0.0026188846677541733, -0.004435344133526087,...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>There are many kinds of computer vision system...</td>\n      <td>[-0.005703717470169067, 0.015227568335831165, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
