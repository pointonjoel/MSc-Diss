{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# GPT-3.5-Turbo Model\n",
    "Creating a question answering chatbot using GPT-3.5. Adapted from: https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preamble\n",
    "# pip install PyPDF2 openai wikipedia mwparserfromhell transformers torch pandas scipy # tiktoken\n",
    "import PyPDF2 # For parsing PDF documents!\n",
    "import ast  # covert embeddings saved as strings back to arrays\n",
    "import openai  # OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import numpy as np # for df manipulations\n",
    "import tiktoken  # for counting tokens\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "import wikipedia # For sourcing Wikipedia article text\n",
    "import re  # for cutting <ref> links out of Wikipedia articles\n",
    "import mwparserfromhell  # for splitting Wikipedia articles into sections\n",
    "from copy import deepcopy # for copying dataframes\n",
    "import torch # for BERT's argmax and tensors\n",
    "from transformers import BertForQuestionAnswering, BertTokenizer # For BERT's tokeniser and model\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration # For BART's tokeniser and model\n",
    "import torch # For creating neural networks with GPUs\n",
    "import logging # For showing messages in the console"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU - available, using a CPU\n"
     ]
    }
   ],
   "source": [
    "# Logging and GPU setup\n",
    "logging.basicConfig(filename='main.log', level=logging.DEBUG) # , encoding='utf-8'\n",
    "def log_and_print_message(msg):\n",
    "        print(msg)\n",
    "        logging.warning(msg)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if torch.cuda.is_available():\n",
    "        log_and_print_message(f'Using GPU - details are as follows:')\n",
    "        log_and_print_message(f'__CUDNN VERSION: {torch.backends.cudnn.version()}')\n",
    "        log_and_print_message(f'__Number CUDA Devices: {torch.cuda.device_count()}')\n",
    "        log_and_print_message(f'__CUDA Device Name: {torch.cuda.get_device_name(0)}')\n",
    "        log_and_print_message(f'__CUDA Device Total Memory: {torch.cuda.get_device_properties(0).total_memory/1e9}')\n",
    "        # model = NeuralNet(input_size, hidden_size, output_size).to(device)\n",
    "else:\n",
    "        log_and_print_message(f'No GPU - available, using a CPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Could not find a suitable TLS CA certificate bundle, invalid path: c:\\Anaconda3\\lib\\site-packages\\certifi\\cacert.pem",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mp:\\Diss\\MSc-Diss\\code\\main.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/Diss/MSc-Diss/code/main.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m GPT_KNOWLEDGE_FILENAME \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCompVisionGPT.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/p%3A/Diss/MSc-Diss/code/main.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m BERT_KNOWLEDGE_FILENAME \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCompVisionBERT.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/p%3A/Diss/MSc-Diss/code/main.ipynb#W3sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m BERT_ENCODING \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39;49mfrom_pretrained(BERT_MODEL)\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/Diss/MSc-Diss/code/main.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m GPT_ENCODING \u001b[39m=\u001b[39m tiktoken\u001b[39m.\u001b[39mencoding_for_model(GPT_MODEL)\n\u001b[0;32m     <a href='vscode-notebook-cell:/p%3A/Diss/MSc-Diss/code/main.ipynb#W3sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m BART_ENCODING \u001b[39m=\u001b[39m BartTokenizer\u001b[39m.\u001b[39mfrom_pretrained(BART_MODEL)\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1771\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *init_inputs, **kwargs)\u001b[0m\n\u001b[0;32m   1769\u001b[0m             resolved_vocab_files[file_id] \u001b[39m=\u001b[39m download_url(file_path, proxies\u001b[39m=\u001b[39mproxies)\n\u001b[0;32m   1770\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1771\u001b[0m         resolved_vocab_files[file_id] \u001b[39m=\u001b[39m cached_file(\n\u001b[0;32m   1772\u001b[0m             pretrained_model_name_or_path,\n\u001b[0;32m   1773\u001b[0m             file_path,\n\u001b[0;32m   1774\u001b[0m             cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m   1775\u001b[0m             force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m   1776\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1777\u001b[0m             resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m   1778\u001b[0m             local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m   1779\u001b[0m             use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m   1780\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m   1781\u001b[0m             revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m   1782\u001b[0m             subfolder\u001b[39m=\u001b[39;49msubfolder,\n\u001b[0;32m   1783\u001b[0m             _raise_exceptions_for_missing_entries\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1784\u001b[0m             _raise_exceptions_for_connection_errors\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1785\u001b[0m             _commit_hash\u001b[39m=\u001b[39;49mcommit_hash,\n\u001b[0;32m   1786\u001b[0m         )\n\u001b[0;32m   1787\u001b[0m         commit_hash \u001b[39m=\u001b[39m extract_commit_hash(resolved_vocab_files[file_id], commit_hash)\n\u001b[0;32m   1789\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(unresolved_files) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\transformers\\utils\\hub.py:417\u001b[0m, in \u001b[0;36mcached_file\u001b[1;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[0;32m    414\u001b[0m user_agent \u001b[39m=\u001b[39m http_user_agent(user_agent)\n\u001b[0;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    416\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m--> 417\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[0;32m    418\u001b[0m         path_or_repo_id,\n\u001b[0;32m    419\u001b[0m         filename,\n\u001b[0;32m    420\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[0;32m    421\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[0;32m    422\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[0;32m    423\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[0;32m    424\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[0;32m    425\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[0;32m    426\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m    427\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[0;32m    428\u001b[0m         use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[0;32m    429\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[0;32m    430\u001b[0m     )\n\u001b[0;32m    432\u001b[0m \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[0;32m    433\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[0;32m    434\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m is not a local folder and is not a valid model identifier \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    435\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlisted on \u001b[39m\u001b[39m'\u001b[39m\u001b[39mhttps://huggingface.co/models\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mIf this is a private repository, make sure to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    436\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpass a token having permission to this repo with `use_auth_token` or log in with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    437\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`huggingface-cli login` and pass `use_auth_token=True`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    438\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1195\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[1;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[0;32m   1193\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1194\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m         metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[0;32m   1196\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m   1197\u001b[0m             token\u001b[39m=\u001b[39;49mtoken,\n\u001b[0;32m   1198\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1199\u001b[0m             timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[0;32m   1200\u001b[0m         )\n\u001b[0;32m   1201\u001b[0m     \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[0;32m   1202\u001b[0m         \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n\u001b[0;32m   1203\u001b[0m         commit_hash \u001b[39m=\u001b[39m http_error\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(HUGGINGFACE_HEADER_X_REPO_COMMIT)\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[0;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[1;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:1532\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[1;34m(url, token, proxies, timeout)\u001b[0m\n\u001b[0;32m   1529\u001b[0m headers[\u001b[39m\"\u001b[39m\u001b[39mAccept-Encoding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39midentity\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[39m# Retrieve metadata\u001b[39;00m\n\u001b[1;32m-> 1532\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[0;32m   1533\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHEAD\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m   1534\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m   1535\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m   1536\u001b[0m     allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m   1537\u001b[0m     follow_relative_redirects\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m   1538\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[0;32m   1539\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m   1540\u001b[0m )\n\u001b[0;32m   1541\u001b[0m hf_raise_for_status(r)\n\u001b[0;32m   1543\u001b[0m \u001b[39m# Return\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:407\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39m# 2. Force relative redirection\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[39mif\u001b[39;00m follow_relative_redirects:\n\u001b[1;32m--> 407\u001b[0m     response \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[0;32m    408\u001b[0m         method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    409\u001b[0m         url\u001b[39m=\u001b[39murl,\n\u001b[0;32m    410\u001b[0m         max_retries\u001b[39m=\u001b[39mmax_retries,\n\u001b[0;32m    411\u001b[0m         base_wait_time\u001b[39m=\u001b[39mbase_wait_time,\n\u001b[0;32m    412\u001b[0m         max_wait_time\u001b[39m=\u001b[39mmax_wait_time,\n\u001b[0;32m    413\u001b[0m         timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m    414\u001b[0m         follow_relative_redirects\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    415\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    416\u001b[0m     )\n\u001b[0;32m    418\u001b[0m     \u001b[39m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[0;32m    419\u001b[0m     \u001b[39m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[0;32m    420\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m300\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m399\u001b[39m:\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:442\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[1;34m(method, url, max_retries, base_wait_time, max_wait_time, timeout, follow_relative_redirects, **params)\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n\u001b[0;32m    441\u001b[0m \u001b[39m# 3. Exponential backoff\u001b[39;00m\n\u001b[1;32m--> 442\u001b[0m \u001b[39mreturn\u001b[39;00m http_backoff(\n\u001b[0;32m    443\u001b[0m     method\u001b[39m=\u001b[39mmethod,\n\u001b[0;32m    444\u001b[0m     url\u001b[39m=\u001b[39murl,\n\u001b[0;32m    445\u001b[0m     max_retries\u001b[39m=\u001b[39mmax_retries,\n\u001b[0;32m    446\u001b[0m     base_wait_time\u001b[39m=\u001b[39mbase_wait_time,\n\u001b[0;32m    447\u001b[0m     max_wait_time\u001b[39m=\u001b[39mmax_wait_time,\n\u001b[0;32m    448\u001b[0m     retry_on_exceptions\u001b[39m=\u001b[39m(ConnectTimeout, ProxyError),\n\u001b[0;32m    449\u001b[0m     retry_on_status_codes\u001b[39m=\u001b[39m(),\n\u001b[0;32m    450\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout,\n\u001b[0;32m    451\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    452\u001b[0m )\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\huggingface_hub\\utils\\_http.py:212\u001b[0m, in \u001b[0;36mhttp_backoff\u001b[1;34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     kwargs[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mseek(io_obj_initial_pos)\n\u001b[0;32m    211\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m--> 212\u001b[0m response \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    213\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m retry_on_status_codes:\n\u001b[0;32m    214\u001b[0m     \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\requests\\sessions.py:529\u001b[0m, in \u001b[0;36mrequest\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\requests\\sessions.py:645\u001b[0m, in \u001b[0;36msend\u001b[1;34m(self, request, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\requests\\adapters.py:417\u001b[0m, in \u001b[0;36msend\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n",
      "File \u001b[1;32mc:\\Anaconda3\\lib\\site-packages\\requests\\adapters.py:228\u001b[0m, in \u001b[0;36mcert_verify\u001b[1;34m(self, conn, url, verify, cert)\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Could not find a suitable TLS CA certificate bundle, invalid path: c:\\Anaconda3\\lib\\site-packages\\certifi\\cacert.pem"
     ]
    }
   ],
   "source": [
    "# Config\n",
    "GPT_EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "BERT_EMBEDDING_MODEL = 'bert-base-nli-mean-tokens'\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "BERT_MODEL = \"deepset/bert-base-cased-squad2\"\n",
    "BART_MODEL = 'vblagoje/bart_lfqa'\n",
    "GPT_KNOWLEDGE_FILENAME = \"CompVisionGPT.csv\"\n",
    "BERT_KNOWLEDGE_FILENAME = \"CompVisionBERT.csv\"\n",
    "BERT_ENCODING = BertTokenizer.from_pretrained(BERT_MODEL)\n",
    "GPT_ENCODING = tiktoken.encoding_for_model(GPT_MODEL)\n",
    "BART_ENCODING = BartTokenizer.from_pretrained(BART_MODEL)\n",
    "GPT_MAX_SECTION_TOKENS = 1600 # max number of tokens per section\n",
    "GPT_QUERY_TOKEN_LIMIT = 4096 - 500 # Allows 500 for the response\n",
    "BERT_MAX_SECTION_TOKENS = 460 # max tokens per section\n",
    "# Need to include a check to ensure that the section length is less than the query length (plus the preamble for GPT)\n",
    "MIN_LENGTH = 50 # min CHARACTER length for each section\n",
    "ANSWER_NOT_FOUND_MSG = \"I could not find an answer in the text I\\'ve been provided, sorry! Please try again.\"\n",
    "WIKI_PAGES = [\n",
    "    'Computer vision',\n",
    "    'Databases and indexing related concepts', \n",
    "    'Generic computer vision methods',\n",
    "    'Geometric and other image features and methods',\n",
    "    'Geometry and mathematics',\n",
    "    'Image physics related concepts',\n",
    "    'Image Processing Architectures & Control Structures',\n",
    "    'Image transformations and filters',\n",
    "    'Introductory visual neurophysiology',\n",
    "    'Introductory visual psychophysics/psychology',\n",
    "    'Motion and time sequence analysis related concepts',\n",
    "    'Non-sequential realization methods',\n",
    "    'Object, world and scene representations',\n",
    "    'Recognition and registration methods',\n",
    "    'Scene understanding/image analysis methods',\n",
    "    'Sensor fusion, registration and planning methods',\n",
    "    'Sensors and properties',\n",
    "    'System models, calibration and parameter estimation methods',\n",
    "    'Visual learning related methods and concepts'\n",
    "    ]\n",
    "WIKI_PAGE = \"Computer vision\"\n",
    "SECTIONS_TO_IGNORE = [\n",
    "    \"See also\",\n",
    "    \"References\",\n",
    "    \"External links\",\n",
    "    \"Further reading\",\n",
    "    \"Footnotes\",\n",
    "    \"Bibliography\",\n",
    "    \"Sources\",\n",
    "    \"Citations\",\n",
    "    \"Literature\",\n",
    "    \"Footnotes\",\n",
    "    \"Notes and references\",\n",
    "    \"Photo gallery\",\n",
    "    \"Works cited\",\n",
    "    \"Photos\",\n",
    "    \"Gallery\",\n",
    "    \"Notes\",\n",
    "    \"References and sources\",\n",
    "    \"References and notes\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'blocks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 50>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     60\u001b[0m page_num \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# iterate through the blocks\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m \u001b[43mblocks\u001b[49m:\n\u001b[0;32m     64\u001b[0m \n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# check if the block is a section header\u001b[39;00m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m14\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m25\u001b[39m:\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m         \u001b[38;5;66;03m# add the section header to the DataFrame\u001b[39;00m\n\u001b[0;32m     69\u001b[0m         df \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPage\u001b[39m\u001b[38;5;124m'\u001b[39m: i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSection\u001b[39m\u001b[38;5;124m'\u001b[39m: b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlock text\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSpan text\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     70\u001b[0m                         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFont size\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRectangle\u001b[39m\u001b[38;5;124m'\u001b[39m: b[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrect\u001b[39m\u001b[38;5;124m'\u001b[39m]}, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'blocks' is not defined"
     ]
    }
   ],
   "source": [
    "# creating a pdf reader instance\n",
    "output_file_folder = 'assets/'\n",
    "uploaded_file = 'assets/online_notes.pdf'\n",
    "# reader = PyPDF2.PdfReader(uploaded_file)\n",
    "#\n",
    "# # print the number of pages in pdf file\n",
    "# print(len(reader.pages))\n",
    "#\n",
    "# # print the text of the first page\n",
    "# print(reader.pages[5].extract_text())\n",
    "\n",
    "# from pypdf import PdfReader\n",
    "#\n",
    "# reader = pypdf.PdfReader(uploaded_file)\n",
    "# text = \"\"\n",
    "# for page in reader.pages:\n",
    "#     text += page.extract_text() + \"\\n\"\n",
    "# text\n",
    "\n",
    "# import fitz\n",
    "\n",
    "# text = \"\"\n",
    "#\n",
    "# doc = fitz.open(uploaded_file)\n",
    "# from unidecode import unidecode\n",
    "# output = []\n",
    "# for page in doc:\n",
    "#     output += page.get_text(\"blocks\")\n",
    "# previous_block_id = 0 # Set a variable to mark the block id\n",
    "# for block in output:\n",
    "#     if block[6] == 0: # We only take the text\n",
    "#         if previous_block_id != block[5]: # Compare the block number\n",
    "#            print(\"\\n\")\n",
    "#            plain_text = unidecode(block[4])\n",
    "#            print(plain_text)\n",
    "\n",
    "import fitz\n",
    "import pandas as pd\n",
    "import re\n",
    "spans = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'text', 'tag'])\n",
    "rows = []\n",
    "\n",
    "# create an empty DataFrame\n",
    "df = pd.DataFrame(columns=['Page', 'Section', 'Block text', 'Span text', 'Font size', 'Rectangle'])\n",
    "block_dict = {}\n",
    "\n",
    "# FIX THIS STUFF!!\n",
    "\n",
    "# open the PDF file\n",
    "with fitz.open(uploaded_file) as doc:\n",
    "    page_num = 1\n",
    "\n",
    "    # iterate through the pages\n",
    "    for i, page in enumerate(doc):\n",
    "\n",
    "        # get the page blocks\n",
    "        output = page.get_text('dict')\n",
    "        block = output['blocks']\n",
    "        block_dict[page_num] = block\n",
    "        page_num += 1\n",
    "\n",
    "        # iterate through the blocks\n",
    "        for b in blocks:\n",
    "\n",
    "            # check if the block is a section header\n",
    "            if b['size'] > 14 and b['height'] > 25:\n",
    "\n",
    "                # add the section header to the DataFrame\n",
    "                df = df.append({'Page': i+1, 'Section': b['text'], 'Block text': '', 'Span text': '',\n",
    "                                'Font size': '', 'Rectangle': b['rect']}, ignore_index=True)\n",
    "\n",
    "            # get the block text and rectangle coordinates\n",
    "            block_text = b['text']\n",
    "            block_rect = b['rect']\n",
    "\n",
    "            # iterate through the block's spans\n",
    "            for s in b['spans']:\n",
    "\n",
    "                # get the span text and font size\n",
    "                span_text = s['text']\n",
    "                span_size = s['size']\n",
    "\n",
    "                # add the information to the DataFrame\n",
    "                df = df.append({'Page': i+1, 'Section': '', 'Block text': block_text, 'Span text': span_text,\n",
    "                                'Font size': span_size, 'Rectangle': s['rect']}, ignore_index=True)\n",
    "\n",
    "# print the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page Numbers</th>\n",
       "      <th>Content</th>\n",
       "      <th>no_newlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Computer Vision\\n</td>\n",
       "      <td>Computer Vision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Computer Science Tripos: 16 Lectures by J G Da...</td>\n",
       "      <td>Computer Science Tripos: 16 Lectures by J G Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1. Overview. Goals of computer vision; why the...</td>\n",
       "      <td>1. Overview. Goals of computer vision; why the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2. Image sensing, pixel arrays, CCD cameras. I...</td>\n",
       "      <td>2. Image sensing, pixel arrays, CCD cameras. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>3. Biological visual mechanisms, from retina t...</td>\n",
       "      <td>3. Biological visual mechanisms, from retina t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1016</th>\n",
       "      <td>115</td>\n",
       "      <td>(i)\\nThey are both linear integral expressions...</td>\n",
       "      <td>(i)They are both linear integral expressions, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1017</th>\n",
       "      <td>115</td>\n",
       "      <td>(ii) In each case, the projection coefficient ...</td>\n",
       "      <td>(ii) In each case, the projection coefficient ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>115</td>\n",
       "      <td>(iii) The orthogonal basis for eigenface compu...</td>\n",
       "      <td>(iii) The orthogonal basis for eigenface compu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1019</th>\n",
       "      <td>115</td>\n",
       "      <td>(iv) The eigenface representation does not use...</td>\n",
       "      <td>(iv) The eigenface representation does not use...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>115</td>\n",
       "      <td>(c)\\nThe hardest part of building a system for...</td>\n",
       "      <td>(c)The hardest part of building a system for f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1021 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Page Numbers                                            Content  \\\n",
       "0                1                                  Computer Vision\\n   \n",
       "1                1  Computer Science Tripos: 16 Lectures by J G Da...   \n",
       "2                1  1. Overview. Goals of computer vision; why the...   \n",
       "3                1  2. Image sensing, pixel arrays, CCD cameras. I...   \n",
       "4                1  3. Biological visual mechanisms, from retina t...   \n",
       "...            ...                                                ...   \n",
       "1016           115  (i)\\nThey are both linear integral expressions...   \n",
       "1017           115  (ii) In each case, the projection coefficient ...   \n",
       "1018           115  (iii) The orthogonal basis for eigenface compu...   \n",
       "1019           115  (iv) The eigenface representation does not use...   \n",
       "1020           115  (c)\\nThe hardest part of building a system for...   \n",
       "\n",
       "                                            no_newlines  \n",
       "0                                       Computer Vision  \n",
       "1     Computer Science Tripos: 16 Lectures by J G Da...  \n",
       "2     1. Overview. Goals of computer vision; why the...  \n",
       "3     2. Image sensing, pixel arrays, CCD cameras. I...  \n",
       "4     3. Biological visual mechanisms, from retina t...  \n",
       "...                                                 ...  \n",
       "1016  (i)They are both linear integral expressions, ...  \n",
       "1017  (ii) In each case, the projection coefficient ...  \n",
       "1018  (iii) The orthogonal basis for eigenface compu...  \n",
       "1019  (iv) The eigenface representation does not use...  \n",
       "1020  (c)The hardest part of building a system for f...  \n",
       "\n",
       "[1021 rows x 3 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def is_float(value):\n",
    "    \"\"\"\n",
    "    Check if a value is a float.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "from unidecode import unidecode # parsing symbols\n",
    "doc = fitz.open(uploaded_file)\n",
    "page_num = 0\n",
    "page_numbers = []\n",
    "content = []\n",
    "output = []\n",
    "for page in doc:\n",
    "    page_num += 1\n",
    "    blocks = page.get_text(\"blocks\")\n",
    "    for block in blocks:\n",
    "        if block[6]==0:\n",
    "            block_content = unidecode(block[4])\n",
    "            stripped_block_content = block_content.replace('\\n', '')\n",
    "            if not stripped_block_content.isdigit() and not is_float(stripped_block_content):\n",
    "                content.append(block_content)\n",
    "                page_numbers.append(page_num)\n",
    "            else:\n",
    "                pass\n",
    "    # previous_block_id = 0 # Set a variable to mark the block id\n",
    "# for block in output:\n",
    "#      if block[6] == 0: # We only take the text\n",
    "#           if previous_block_id != block[5]: # Compare the block number\n",
    "#               # print(\"\\n\")\n",
    "#             pass\n",
    "#           plain_text = unidecode(block[4])\n",
    "#           page_numbers.append(page_num)\n",
    "#           content.append(plain_text)\n",
    "content_df = pd.DataFrame(\n",
    "    {'Page Numbers': page_numbers,\n",
    "     'Content': content,\n",
    "    })\n",
    "content_df['no_newlines'] = content_df['Content'].str.replace(r'\\n', '', regex=True)\n",
    "content_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "block_dict = {}\n",
    "page_num = 1\n",
    "for page in doc: # Iterate all pages in the document\n",
    "      file_dict = page.get_text('dict') # Get the page dictionary\n",
    "      block = file_dict['blocks'] # Get the block information\n",
    "      block_dict[page_num] = block # Store in block dictionary\n",
    "      page_num += 1 # Increase the page value by 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# spans = pd.DataFrame(columns=['xmin', 'ymin', 'xmax', 'ymax', 'text', 'tag'])\n",
    "rows = []\n",
    "for page_num, blocks in block_dict.items():\n",
    "    for block in blocks:\n",
    "        if block['type'] == 0:\n",
    "            for line in block['lines']:\n",
    "                for span in line['spans']:\n",
    "                    xmin, ymin, xmax, ymax = list(span['bbox'])\n",
    "                    font_size = span['size']\n",
    "                    text = unidecode(span['text'])\n",
    "                    span_font = span['font']\n",
    "                    is_upper = False\n",
    "\n",
    "                    is_bold = False\n",
    "                    if \"bold\" in span_font.lower():\n",
    "                        is_bold = True\n",
    "                    if re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text).isupper():\n",
    "                        is_upper = True\n",
    "                    if text.replace(\" \",\"\") !=  \"\":\n",
    "                        rows.append((xmin, ymin, xmax, ymax, text, is_upper, is_bold, span_font, font_size))\n",
    "span_df = pd.DataFrame(rows, columns=['xmin','ymin','xmax','ymax', 'text', 'is_upper','is_bold','span_font', 'font_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>text</th>\n",
       "      <th>is_upper</th>\n",
       "      <th>is_bold</th>\n",
       "      <th>span_font</th>\n",
       "      <th>font_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207.863998</td>\n",
       "      <td>50.356079</td>\n",
       "      <td>382.440033</td>\n",
       "      <td>71.039337</td>\n",
       "      <td>Computer Vision</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMBX12</td>\n",
       "      <td>20.6626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.599998</td>\n",
       "      <td>99.768372</td>\n",
       "      <td>532.429199</td>\n",
       "      <td>117.001083</td>\n",
       "      <td>Computer Science Tripos: 16 Lectures by J G Da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMBX12~c</td>\n",
       "      <td>17.2155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.253998</td>\n",
       "      <td>154.588379</td>\n",
       "      <td>527.770264</td>\n",
       "      <td>168.948914</td>\n",
       "      <td>1. Overview. Goals of computer vision; why the...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMBX12~f</td>\n",
       "      <td>14.3462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.254364</td>\n",
       "      <td>181.489380</td>\n",
       "      <td>497.032715</td>\n",
       "      <td>195.849915</td>\n",
       "      <td>2. Image sensing, pixel arrays, CCD cameras. I...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMBX12~f</td>\n",
       "      <td>14.3462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.254730</td>\n",
       "      <td>208.381409</td>\n",
       "      <td>517.157776</td>\n",
       "      <td>222.741943</td>\n",
       "      <td>3. Biological visual mechanisms, from retina t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMBX12~f</td>\n",
       "      <td>14.3462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>82.503143</td>\n",
       "      <td>592.908875</td>\n",
       "      <td>517.999084</td>\n",
       "      <td>604.875916</td>\n",
       "      <td>representations. But the added difficulty of t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMR12~330</td>\n",
       "      <td>11.9551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>82.503540</td>\n",
       "      <td>606.858887</td>\n",
       "      <td>518.052673</td>\n",
       "      <td>618.825928</td>\n",
       "      <td>optics:\" building a 3-dimensional model from a...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMR12~330</td>\n",
       "      <td>11.9551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6855</th>\n",
       "      <td>82.504028</td>\n",
       "      <td>620.808838</td>\n",
       "      <td>518.081665</td>\n",
       "      <td>632.775879</td>\n",
       "      <td>them). Besides the enormous computational and ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMR12~330</td>\n",
       "      <td>11.9551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6856</th>\n",
       "      <td>82.504242</td>\n",
       "      <td>634.758850</td>\n",
       "      <td>432.174744</td>\n",
       "      <td>646.725891</td>\n",
       "      <td>for each such full 3D model), this is inherent...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMR12~330</td>\n",
       "      <td>11.9551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6857</th>\n",
       "      <td>282.547150</td>\n",
       "      <td>800.226440</td>\n",
       "      <td>293.445343</td>\n",
       "      <td>811.135498</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMR10~339</td>\n",
       "      <td>10.9091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6858 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            xmin        ymin        xmax        ymax  \\\n",
       "0     207.863998   50.356079  382.440033   71.039337   \n",
       "1      57.599998   99.768372  532.429199  117.001083   \n",
       "2      70.253998  154.588379  527.770264  168.948914   \n",
       "3      70.254364  181.489380  497.032715  195.849915   \n",
       "4      70.254730  208.381409  517.157776  222.741943   \n",
       "...          ...         ...         ...         ...   \n",
       "6853   82.503143  592.908875  517.999084  604.875916   \n",
       "6854   82.503540  606.858887  518.052673  618.825928   \n",
       "6855   82.504028  620.808838  518.081665  632.775879   \n",
       "6856   82.504242  634.758850  432.174744  646.725891   \n",
       "6857  282.547150  800.226440  293.445343  811.135498   \n",
       "\n",
       "                                                   text  is_upper  is_bold  \\\n",
       "0                                       Computer Vision     False    False   \n",
       "1     Computer Science Tripos: 16 Lectures by J G Da...     False    False   \n",
       "2     1. Overview. Goals of computer vision; why the...     False    False   \n",
       "3     2. Image sensing, pixel arrays, CCD cameras. I...     False    False   \n",
       "4     3. Biological visual mechanisms, from retina t...     False    False   \n",
       "...                                                 ...       ...      ...   \n",
       "6853  representations. But the added difficulty of t...     False    False   \n",
       "6854  optics:\" building a 3-dimensional model from a...     False    False   \n",
       "6855  them). Besides the enormous computational and ...     False    False   \n",
       "6856  for each such full 3D model), this is inherent...     False    False   \n",
       "6857                                                 21     False    False   \n",
       "\n",
       "      span_font  font_size  \n",
       "0        CMBX12    20.6626  \n",
       "1      CMBX12~c    17.2155  \n",
       "2      CMBX12~f    14.3462  \n",
       "3      CMBX12~f    14.3462  \n",
       "4      CMBX12~f    14.3462  \n",
       "...         ...        ...  \n",
       "6853  CMR12~330    11.9551  \n",
       "6854  CMR12~330    11.9551  \n",
       "6855  CMR12~330    11.9551  \n",
       "6856  CMR12~330    11.9551  \n",
       "6857  CMR10~339    10.9091  \n",
       "\n",
       "[6858 rows x 9 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "span_scores = []\n",
    "span_num_occur = {}\n",
    "special = '[(_:/,#%\\=@)]'\n",
    "for index, span_row in span_df.iterrows():\n",
    "    score = round(span_row.font_size)\n",
    "    text = span_row.text\n",
    "    if not re.search(special, text):\n",
    "        if span_row.is_bold:\n",
    "            score +=1\n",
    "        if span_row.is_upper:\n",
    "            score +=1\n",
    "    span_scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(21, 1),\n",
       " (9, 4),\n",
       " (16, 5),\n",
       " (17, 9),\n",
       " (7, 48),\n",
       " (6, 50),\n",
       " (13, 86),\n",
       " (11, 176),\n",
       " (15, 215),\n",
       " (8, 268),\n",
       " (10, 382),\n",
       " (12, 1937),\n",
       " (14, 3677)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import numpy as np\n",
    "values, counts = np.unique(span_scores, return_counts=True)\n",
    "style_dict = {}\n",
    "\n",
    "for value, count in zip(values, counts):\n",
    "    style_dict[value] = count\n",
    "sorted(style_dict.items(), key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_size = max(style_dict, key=style_dict.get)\n",
    "idx = 0\n",
    "tag = {}\n",
    "\n",
    "for size in sorted(values, reverse = True):\n",
    "    idx += 1\n",
    "    if size == p_size:\n",
    "        idx = 0\n",
    "        tag[size] = 'p'\n",
    "    if size > p_size:\n",
    "        tag[size] = 'h{0}'.format(idx)\n",
    "    if size < p_size:\n",
    "        tag[size] = 's{0}'.format(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{21: 'h1',\n",
       " 17: 'h2',\n",
       " 16: 'h3',\n",
       " 15: 'h4',\n",
       " 14: 'p',\n",
       " 13: 's1',\n",
       " 12: 's2',\n",
       " 11: 's3',\n",
       " 10: 's4',\n",
       " 9: 's5',\n",
       " 8: 's6',\n",
       " 7: 's7',\n",
       " 6: 's8'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "      <th>text</th>\n",
       "      <th>is_upper</th>\n",
       "      <th>is_bold</th>\n",
       "      <th>span_font</th>\n",
       "      <th>font_size</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>207.863998</td>\n",
       "      <td>50.356079</td>\n",
       "      <td>382.440033</td>\n",
       "      <td>71.039337</td>\n",
       "      <td>Computer Vision</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMBX12</td>\n",
       "      <td>20.6626</td>\n",
       "      <td>h1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>57.599998</td>\n",
       "      <td>99.768372</td>\n",
       "      <td>532.429199</td>\n",
       "      <td>117.001083</td>\n",
       "      <td>Computer Science Tripos: 16 Lectures by J G Da...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMBX12~c</td>\n",
       "      <td>17.2155</td>\n",
       "      <td>h2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70.253998</td>\n",
       "      <td>154.588379</td>\n",
       "      <td>527.770264</td>\n",
       "      <td>168.948914</td>\n",
       "      <td>1. Overview. Goals of computer vision; why the...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMBX12~f</td>\n",
       "      <td>14.3462</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70.254364</td>\n",
       "      <td>181.489380</td>\n",
       "      <td>497.032715</td>\n",
       "      <td>195.849915</td>\n",
       "      <td>2. Image sensing, pixel arrays, CCD cameras. I...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMBX12~f</td>\n",
       "      <td>14.3462</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70.254730</td>\n",
       "      <td>208.381409</td>\n",
       "      <td>517.157776</td>\n",
       "      <td>222.741943</td>\n",
       "      <td>3. Biological visual mechanisms, from retina t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMBX12~f</td>\n",
       "      <td>14.3462</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6853</th>\n",
       "      <td>82.503143</td>\n",
       "      <td>592.908875</td>\n",
       "      <td>517.999084</td>\n",
       "      <td>604.875916</td>\n",
       "      <td>representations. But the added difficulty of t...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMR12~330</td>\n",
       "      <td>11.9551</td>\n",
       "      <td>s2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6854</th>\n",
       "      <td>82.503540</td>\n",
       "      <td>606.858887</td>\n",
       "      <td>518.052673</td>\n",
       "      <td>618.825928</td>\n",
       "      <td>optics:\" building a 3-dimensional model from a...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMR12~330</td>\n",
       "      <td>11.9551</td>\n",
       "      <td>s2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6855</th>\n",
       "      <td>82.504028</td>\n",
       "      <td>620.808838</td>\n",
       "      <td>518.081665</td>\n",
       "      <td>632.775879</td>\n",
       "      <td>them). Besides the enormous computational and ...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMR12~330</td>\n",
       "      <td>11.9551</td>\n",
       "      <td>s2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6856</th>\n",
       "      <td>82.504242</td>\n",
       "      <td>634.758850</td>\n",
       "      <td>432.174744</td>\n",
       "      <td>646.725891</td>\n",
       "      <td>for each such full 3D model), this is inherent...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMR12~330</td>\n",
       "      <td>11.9551</td>\n",
       "      <td>s2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6857</th>\n",
       "      <td>282.547150</td>\n",
       "      <td>800.226440</td>\n",
       "      <td>293.445343</td>\n",
       "      <td>811.135498</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>CMR10~339</td>\n",
       "      <td>10.9091</td>\n",
       "      <td>s3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6858 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            xmin        ymin        xmax        ymax  \\\n",
       "0     207.863998   50.356079  382.440033   71.039337   \n",
       "1      57.599998   99.768372  532.429199  117.001083   \n",
       "2      70.253998  154.588379  527.770264  168.948914   \n",
       "3      70.254364  181.489380  497.032715  195.849915   \n",
       "4      70.254730  208.381409  517.157776  222.741943   \n",
       "...          ...         ...         ...         ...   \n",
       "6853   82.503143  592.908875  517.999084  604.875916   \n",
       "6854   82.503540  606.858887  518.052673  618.825928   \n",
       "6855   82.504028  620.808838  518.081665  632.775879   \n",
       "6856   82.504242  634.758850  432.174744  646.725891   \n",
       "6857  282.547150  800.226440  293.445343  811.135498   \n",
       "\n",
       "                                                   text  is_upper  is_bold  \\\n",
       "0                                       Computer Vision     False    False   \n",
       "1     Computer Science Tripos: 16 Lectures by J G Da...     False    False   \n",
       "2     1. Overview. Goals of computer vision; why the...     False    False   \n",
       "3     2. Image sensing, pixel arrays, CCD cameras. I...     False    False   \n",
       "4     3. Biological visual mechanisms, from retina t...     False    False   \n",
       "...                                                 ...       ...      ...   \n",
       "6853  representations. But the added difficulty of t...     False    False   \n",
       "6854  optics:\" building a 3-dimensional model from a...     False    False   \n",
       "6855  them). Besides the enormous computational and ...     False    False   \n",
       "6856  for each such full 3D model), this is inherent...     False    False   \n",
       "6857                                                 21     False    False   \n",
       "\n",
       "      span_font  font_size tag  \n",
       "0        CMBX12    20.6626  h1  \n",
       "1      CMBX12~c    17.2155  h2  \n",
       "2      CMBX12~f    14.3462   p  \n",
       "3      CMBX12~f    14.3462   p  \n",
       "4      CMBX12~f    14.3462   p  \n",
       "...         ...        ...  ..  \n",
       "6853  CMR12~330    11.9551  s2  \n",
       "6854  CMR12~330    11.9551  s2  \n",
       "6855  CMR12~330    11.9551  s2  \n",
       "6856  CMR12~330    11.9551  s2  \n",
       "6857  CMR10~339    10.9091  s3  \n",
       "\n",
       "[6858 rows x 10 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span_tags = [tag[score] for score in span_scores]\n",
    "\n",
    "span_df['tag'] = span_tags\n",
    "span_df = span_df.loc[span_df['tag'].str.startswith('s')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function Document.__del__ at 0x000001D6088198B0>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\point\\anaconda3\\lib\\site-packages\\fitz\\fitz.py\", line 5761, in __del__\n",
      "    if not type(self) is Document:\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m text_list \u001b[38;5;241m=\u001b[39m text_list[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     17\u001b[0m text_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mzip\u001b[39m(headings_list, text_list),columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheading\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n\u001b[1;32m---> 18\u001b[0m \u001b[43mtext_df\u001b[49m\n",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m text_list \u001b[38;5;241m=\u001b[39m text_list[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m     17\u001b[0m text_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;28mzip\u001b[39m(headings_list, text_list),columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mheading\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m] )\n\u001b[1;32m---> 18\u001b[0m \u001b[43mtext_df\u001b[49m\n",
      "File \u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:1179\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:620\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:929\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:920\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle\\pydevd_cython_win32_39_64.pyx:317\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython_win32_39_64.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.2.3\\plugins\\python\\helpers\\pydev\\pydevd.py:1160\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, send_suspend_message, is_unhandled_exception)\u001b[0m\n\u001b[0;32m   1157\u001b[0m         from_this_thread\u001b[38;5;241m.\u001b[39mappend(frame_id)\n\u001b[0;32m   1159\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_threads_suspended_single_notification\u001b[38;5;241m.\u001b[39mnotify_thread_suspended(thread_id, stop_reason):\n\u001b[1;32m-> 1160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_wait_suspend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuspend_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_this_thread\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\JetBrains\\PyCharm 2022.2.3\\plugins\\python\\helpers\\pydev\\pydevd.py:1175\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread)\u001b[0m\n\u001b[0;32m   1172\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_mpl_hook()\n\u001b[0;32m   1174\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 1175\u001b[0m         \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(frame)))\n\u001b[0;32m   1179\u001b[0m \u001b[38;5;66;03m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "headings_list = []\n",
    "text_list = []\n",
    "tmp = []\n",
    "heading = ''\n",
    "for index, span_row in span_df.iterrows():\n",
    "    text = span_row.text\n",
    "    tag = span_row.tag\n",
    "    if 'h' in tag:\n",
    "        headings_list.append(text)\n",
    "        text_list.append('\\n'.join(tmp))\n",
    "        tmp = []\n",
    "        heading = text\n",
    "    else:\n",
    "        tmp.append(text)\n",
    "text_list.append('\\n'.join(tmp))\n",
    "text_list = text_list[1:]\n",
    "text_df = pd.DataFrame(zip(headings_list, text_list),columns=['heading', 'content'] )\n",
    "text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Used throughout\n",
    "def num_tokens(\n",
    "        text: str,\n",
    "        token_model = GPT_ENCODING\n",
    ") -> int:\n",
    "    \"\"\"Returns the number of tokens in a string.\"\"\"\n",
    "    if token_model == GPT_ENCODING:\n",
    "        return len(token_model.encode(text))\n",
    "    elif token_model == BERT_ENCODING:\n",
    "        return len(token_model.tokenize(text))\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "def get_embedding(content: list or str, embedding_model: str = GPT_EMBEDDING_MODEL):\n",
    "    if embedding_model == GPT_EMBEDDING_MODEL:\n",
    "        return openai.Embedding.create(input=content, model=embedding_model)\n",
    "    else:\n",
    "        similarity_model = SentenceTransformer(embedding_model)\n",
    "        return similarity_model.encode(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Knowledge:\n",
    "    def __init__(self, topic, model):\n",
    "        self.topic: str = topic\n",
    "        self.model: str = model\n",
    "        self.token_model = self.get_token_model()\n",
    "        self.embedding_model: str = self.get_embedding_model()\n",
    "        self.df: pd.DataFrame = self.get_blank_knowledge_df() # need to add code to remove small sections (<16 chars?)\n",
    "        self.max_tokens: int = self.get_max_tokens() # max number of tokens per section\n",
    "        self.min_section_length = MIN_LENGTH # min character length for each section\n",
    "\n",
    "    def get_token_model(self):\n",
    "        return GPT_ENCODING if self.model=='GPT' else BERT_ENCODING\n",
    "\n",
    "    def get_max_tokens(self):\n",
    "        return GPT_MAX_SECTION_TOKENS if self.model=='GPT' else BERT_MAX_SECTION_TOKENS\n",
    "\n",
    "    def get_embedding_model(self):\n",
    "        return GPT_EMBEDDING_MODEL if self.model=='GPT' else BERT_EMBEDDING_MODEL\n",
    "\n",
    "    def get_blank_knowledge_df(self) -> pd.DataFrame:\n",
    "        return pd.DataFrame(columns=['Source', 'Heading', 'Subheading', 'Content'])\n",
    "\n",
    "    def extract_wiki_sections(self,\n",
    "                              page_name: str,\n",
    "                              content: mwparserfromhell.wikicode.Wikicode,\n",
    "                              sections_to_ignore: list = SECTIONS_TO_IGNORE\n",
    "                              ) -> pd.DataFrame:\n",
    "        \"\"\"Creates a df of sections by extracting section content from a Wikicode\"\"\"\n",
    "\n",
    "        knowledge = self.get_blank_knowledge_df()\n",
    "        for section in content.get_sections(levels=[2]):\n",
    "            section_headings = section.filter_headings()\n",
    "            section_header = str(section_headings[0])\n",
    "            if len(section_headings)==1:# therefore a section title, not a subsection\n",
    "                section = section.strip(section_header)\n",
    "                if section_header.strip(\"=\" + \" \") not in sections_to_ignore: # append to df\n",
    "                    new_row = {'Source': f'Wikipedia ({page_name})', 'Heading': section_header.strip(\"=\" + \" \"), 'Content': section}\n",
    "                    knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "            elif len(section_headings)>1 and section_header.strip(\"=\" + \" \") not in sections_to_ignore: # therefore subsections\n",
    "                # Append the text before the first subsection\n",
    "                initial_text = section.split(str(section_headings[1]))[0]\n",
    "                initial_text = initial_text.strip(section_header)\n",
    "                new_row = {'Source': f'Wikipedia ({page_name})', 'Heading': section_header.strip(\"=\" + \" \"), 'Content': initial_text}\n",
    "                knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "                for subsection in section.get_sections(levels=[3]):\n",
    "                    subsection_sections = subsection.get_sections(levels=[3])[0]\n",
    "                    subsection_headings = subsection_sections.filter_headings()\n",
    "                    subsection_header = str(subsection_headings[0])\n",
    "                    subsection = subsection.strip(subsection_header)\n",
    "                    if subsection_header.strip(\"=\" + \" \") not in sections_to_ignore: # append to df\n",
    "                        new_row = {'Source': f'Wikipedia ({page_name})', 'Heading': section_header.strip(\"=\" + \" \"), 'Subheading': subsection_header.strip(\"=\" + \" \"), 'Content': subsection}\n",
    "                        knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "        return knowledge\n",
    "\n",
    "    def generate_source_column(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Creates a new column in the df which contains a summary of the source location\"\"\"\n",
    "\n",
    "        df.fillna('', inplace=True)\n",
    "        df['Section'] = df['Source'] + '->' + df['Heading'] + '->' + df['Subheading']\n",
    "        df['Section'] = df['Section'].str.replace('->->', '')\n",
    "        df['Section'] = df['Section'].str.rstrip('_->')\n",
    "        return df\n",
    "\n",
    "    def clean_section_contents(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Returns a cleaned up section with <ref>xyz</ref> patterns and leading/trailing whitespace removed\"\"\"\n",
    "\n",
    "        # text = re.sub(r\"<ref.*?</ref>\", \"\", text)\n",
    "        df['Content'] = df['Content'].str.replace(r\"<ref.*?</ref>\", \"\", regex=True)\n",
    "        df['Content'] = df['Content'].str.strip() # removes whitespace\n",
    "        df['Content'] = '\\n' + df['Content'] # need to add the \\n back to the start of each title\n",
    "        return df\n",
    "\n",
    "    def merge_elements_of_list(self, list_of_strings: list, delimiter: str = \"\\n\"):\n",
    "        potential_for_more_merging = False\n",
    "        merged_list = []\n",
    "        skip_item = False\n",
    "        for i in range(len(list_of_strings)):\n",
    "            if not skip_item:\n",
    "                if i == len(list_of_strings)-1:\n",
    "                    merged_list.append(list_of_strings[i])\n",
    "                else:\n",
    "                    merged_strings = list_of_strings[i] + delimiter + list_of_strings[i+1]\n",
    "                    if num_tokens(merged_strings)<self.max_tokens:\n",
    "                        merged_list.append(merged_strings)\n",
    "                        skip_item = True # make it skip the element we just merged\n",
    "                        potential_for_more_merging = True\n",
    "                    else:\n",
    "                        merged_list.append(list_of_strings[i])\n",
    "            else:\n",
    "                skip_item = False # set the default back to False unless otherwise specified\n",
    "        return merged_list, potential_for_more_merging\n",
    "\n",
    "    def force_split_string(self,\n",
    "                           string: str,\n",
    "                           encoding = GPT_ENCODING) -> list:\n",
    "        \"\"\"Force a section to be split into 2 (to be used if it has no delimiter)\"\"\"\n",
    "\n",
    "        list_of_strings = []\n",
    "        if num_tokens(string) <= self.max_tokens:\n",
    "            return [string]\n",
    "        else:\n",
    "            needs_truncating = True\n",
    "            while needs_truncating:\n",
    "                encoded_string = encoding.encode(string)\n",
    "                truncated_string = encoding.decode(encoded_string[:self.max_tokens])\n",
    "                remainder_of_string = encoding.decode(encoded_string[self.max_tokens:])\n",
    "                list_of_strings.append(truncated_string)\n",
    "                string = remainder_of_string\n",
    "                if num_tokens(remainder_of_string)<self.max_tokens:\n",
    "                    needs_truncating=False\n",
    "                    list_of_strings.append(remainder_of_string)\n",
    "        return list_of_strings\n",
    "\n",
    "    def split_long_sections(self, df: pd.DataFrame, delimiter: str = '\\n'):\n",
    "        \"\"\"Splits long sections of text into smaller ones\"\"\"\n",
    "\n",
    "        new_dict_of_shorter_sections = self.get_blank_knowledge_df().to_dict('records')\n",
    "        df_as_dict = df.to_dict('records')\n",
    "        for section in df_as_dict:\n",
    "            # for delimiter in delimiters:\n",
    "            if section['Tokens']<=self.max_tokens:\n",
    "                new_dict_of_shorter_sections.append(section)\n",
    "            else:\n",
    "                # needs to be split up\n",
    "                if delimiter == '': # meaning that we just need to truncate it.\n",
    "                    text = self.force_split_string(section['Content'])\n",
    "                else:\n",
    "                    text = section['Content'].split(delimiter)\n",
    "                    if delimiter == '. ':\n",
    "                        for i in range(len(text)-1):\n",
    "                            text[i] += delimiter\n",
    "                potential_for_more_merging = True\n",
    "                i = 0\n",
    "                while potential_for_more_merging:\n",
    "                    if i>20:\n",
    "                        break\n",
    "                    else:\n",
    "                        text, potential_for_more_merging = self.merge_elements_of_list(text)\n",
    "\n",
    "                # The sections should be merged into acceptable sizes:\n",
    "                if len(text)>1:\n",
    "                    for string in text:\n",
    "                        item_to_append = {'Source': section['Source'], 'Heading': section['Heading'], 'Subheading': section['Subheading'], 'Content': string, 'Section': section['Section'], 'Tokens': num_tokens(string)}\n",
    "\n",
    "                        new_dict_of_shorter_sections.append(item_to_append)\n",
    "                else:\n",
    "                    item_to_append = {'Source': section['Source'], 'Heading': section['Heading'], 'Subheading': section['Subheading'], 'Content': text[0], 'Section': section['Section'], 'Tokens': num_tokens(text[0])}\n",
    "                    new_dict_of_shorter_sections.append(item_to_append) # we shouldn't have this because the text should be more than the acceptable number of tokens\n",
    "        return pd.DataFrame(new_dict_of_shorter_sections)\n",
    "\n",
    "    def append_wikipedia_page(self, page_name: str,\n",
    "                              sections_to_ignore: list = SECTIONS_TO_IGNORE):\n",
    "        \"\"\"Takes a wikipedia page and appends the sections to the knowledge df\"\"\"\n",
    "        try:\n",
    "            site = wikipedia.page(page_name, auto_suggest=False)\n",
    "            text = site.content\n",
    "            parsed_text = mwparserfromhell.parse(text)\n",
    "\n",
    "            # Creating initial df and appending the introduction paragraph (the text up to the first heading)\n",
    "            intro = str(parsed_text).split(str(parsed_text.filter_headings()[0]))[0]\n",
    "            knowledge = self.get_blank_knowledge_df()\n",
    "            new_row = {'Source': f'Wikipedia ({page_name})', 'Content': '\\n'+intro}\n",
    "            knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "\n",
    "            section_content = self.extract_wiki_sections(page_name=page_name, content=parsed_text, sections_to_ignore=sections_to_ignore)\n",
    "            knowledge = pd.concat([knowledge, section_content])\n",
    "\n",
    "            # Generate succinct heading information\n",
    "            knowledge = self.generate_source_column(knowledge)\n",
    "            self.df = pd.concat([self.df, knowledge])\n",
    "\n",
    "            # Remove unwanted strings and whitespace\n",
    "            self.df = self.clean_section_contents(self.df)\n",
    "\n",
    "            # Generate number of tokens in each section\n",
    "            self.df['Tokens'] = self.df[\"Content\"].apply(lambda x: num_tokens(x, token_model=self.token_model))\n",
    "\n",
    "            # Split long sections\n",
    "            for delim in [\"\\n\\n\", \"\\n\", \". \", '']:\n",
    "                self.df = self.split_long_sections(self.df, delimiter=delim)\n",
    "\n",
    "            # Remove short sections\n",
    "            self.df = self.df.loc[self.df['Content'].str.len()>self.min_section_length]\n",
    "\n",
    "            # Append '\\n' to the start if it doesn't already have one\n",
    "            self.df.loc[~self.df['Content'].str.startswith('\\n'), 'Content'] = '\\n' + self.df.loc[~self.df['Content'].str.startswith('\\n'), 'Content']\n",
    "\n",
    "            # Get embeddings\n",
    "            if self.model == 'GPT':\n",
    "                response = get_embedding(list(self.df['Content']), embedding_model=self.embedding_model)\n",
    "                for i, be in enumerate(response[\"data\"]):\n",
    "                    assert i == be[\"index\"]  # double check embeddings are in same order as input\n",
    "                batch_embeddings = [e[\"embedding\"] for e in response[\"data\"]]\n",
    "                self.df['Embedding'] = batch_embeddings\n",
    "            else:\n",
    "                self.df['Embedding'] = get_embedding(list(self.df['Content']), embedding_model=self.embedding_model).tolist()\n",
    "            log_and_print_message(f'The following page has been successfully added to the knowledge database: {page_name}')\n",
    "\n",
    "        except: # The wiki page doesn't exist\n",
    "            log_and_print_message(f'The wiki page {page_name} can\\'t be found. Please check and try again.')\n",
    "\n",
    "\n",
    "    def export_to_csv(self, filename):\n",
    "        \"\"\"Saves the knowledge df to a CSV file\"\"\"\n",
    "        location = 'assets/' + filename\n",
    "        self.df.to_csv(location, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Subheading</th>\n",
       "      <th>Content</th>\n",
       "      <th>Section</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\nComputer vision tasks include methods for ac...</td>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>286</td>\n",
       "      <td>[-0.01913553662598133, 0.002932898933067918, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Definition</td>\n",
       "      <td></td>\n",
       "      <td>\\nComputer vision is an interdisciplinary fiel...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Definition</td>\n",
       "      <td>158</td>\n",
       "      <td>[-0.021093836054205894, 0.0049119978211820126,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>History</td>\n",
       "      <td></td>\n",
       "      <td>\\nIn the late 1960s, computer vision began at ...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;History</td>\n",
       "      <td>507</td>\n",
       "      <td>[-0.011549791321158409, -0.004044382367283106,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Solid-state physics</td>\n",
       "      <td>\\nSolid-state physics is another field that is...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;S...</td>\n",
       "      <td>120</td>\n",
       "      <td>[0.0018743288237601519, 0.011324070394039154, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Neurobiology</td>\n",
       "      <td>\\nNeurobiology has greatly influenced the deve...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;N...</td>\n",
       "      <td>293</td>\n",
       "      <td>[-0.009132628329098225, 0.0011366719845682383,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Signal processing</td>\n",
       "      <td>\\nYet another field related to computer vision...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;S...</td>\n",
       "      <td>103</td>\n",
       "      <td>[-0.027298789471387863, 0.007510432507842779, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Robotic navigation</td>\n",
       "      <td>\\nRobot navigation sometimes deals with autono...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;R...</td>\n",
       "      <td>64</td>\n",
       "      <td>[0.0034529592376202345, -0.014102335087954998,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Other fields</td>\n",
       "      <td>\\nBesides the above-mentioned views on compute...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;O...</td>\n",
       "      <td>119</td>\n",
       "      <td>[0.002435609931126237, -0.003915637265890837, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Distinctions</td>\n",
       "      <td>\\nThe fields most closely related to computer ...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;D...</td>\n",
       "      <td>639</td>\n",
       "      <td>[-0.017207426950335503, 0.005905073136091232, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td></td>\n",
       "      <td>\\nApplications range from tasks such as indust...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications</td>\n",
       "      <td>272</td>\n",
       "      <td>[-0.022458024322986603, 0.005672922823578119, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>\\nOne of the most prominent application fields...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Med...</td>\n",
       "      <td>135</td>\n",
       "      <td>[-0.016155855730175972, 0.02248280495405197, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Machine vision</td>\n",
       "      <td>\\nA second application area in computer vision...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Mac...</td>\n",
       "      <td>141</td>\n",
       "      <td>[-0.016629502177238464, 0.002632115501910448, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Military</td>\n",
       "      <td>\\nMilitary applications are probably one of th...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Mil...</td>\n",
       "      <td>129</td>\n",
       "      <td>[-0.02624369040131569, 0.001608214108273387, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Autonomous vehicles</td>\n",
       "      <td>\\nOne of the newer application areas is autono...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Aut...</td>\n",
       "      <td>234</td>\n",
       "      <td>[0.002211927669122815, -0.004606796428561211, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Tactile feedback</td>\n",
       "      <td>\\nMaterials such as rubber and silicon are bei...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Tac...</td>\n",
       "      <td>270</td>\n",
       "      <td>[-0.015194285660982132, 0.023810898885130882, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Typical tasks</td>\n",
       "      <td></td>\n",
       "      <td>\\nEach of the application areas described abov...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Typical tasks</td>\n",
       "      <td>161</td>\n",
       "      <td>[-0.018167616799473763, 0.007240524981170893, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Typical tasks</td>\n",
       "      <td>Recognition</td>\n",
       "      <td>\\nThe classical problem in computer vision, im...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Re...</td>\n",
       "      <td>691</td>\n",
       "      <td>[-0.018989920616149902, 0.02043752372264862, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Typical tasks</td>\n",
       "      <td>Motion analysis</td>\n",
       "      <td>\\nSeveral tasks relate to motion estimation wh...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Mo...</td>\n",
       "      <td>193</td>\n",
       "      <td>[-0.02092411182820797, 0.00222062598913908, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Typical tasks</td>\n",
       "      <td>Scene reconstruction</td>\n",
       "      <td>\\nGiven one or (typically) more images of a sc...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Sc...</td>\n",
       "      <td>125</td>\n",
       "      <td>[-0.02498997002840042, 0.015953006222844124, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Typical tasks</td>\n",
       "      <td>Image restoration</td>\n",
       "      <td>\\nImage restoration comes into picture when th...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Im...</td>\n",
       "      <td>198</td>\n",
       "      <td>[0.0009744223789311945, 0.03190232068300247, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>System methods</td>\n",
       "      <td></td>\n",
       "      <td>\\nThe organization of a computer vision system...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;System methods</td>\n",
       "      <td>672</td>\n",
       "      <td>[-0.0014013586333021522, 0.026699397712945938,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>System methods</td>\n",
       "      <td>Image-understanding systems</td>\n",
       "      <td>\\nImage-understanding systems (IUS) include th...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;System methods-&gt;I...</td>\n",
       "      <td>192</td>\n",
       "      <td>[0.006758322473615408, -0.004905234090983868, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Hardware</td>\n",
       "      <td></td>\n",
       "      <td>\\nThere are many kinds of computer vision syst...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Hardware</td>\n",
       "      <td>392</td>\n",
       "      <td>[-0.006029689218848944, 0.016216637566685677, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Source         Heading                   Subheading  \\\n",
       "0   Wikipedia (Computer vision)                                                \n",
       "1   Wikipedia (Computer vision)      Definition                                \n",
       "2   Wikipedia (Computer vision)         History                                \n",
       "4   Wikipedia (Computer vision)  Related fields          Solid-state physics   \n",
       "5   Wikipedia (Computer vision)  Related fields                 Neurobiology   \n",
       "6   Wikipedia (Computer vision)  Related fields            Signal processing   \n",
       "7   Wikipedia (Computer vision)  Related fields           Robotic navigation   \n",
       "8   Wikipedia (Computer vision)  Related fields                 Other fields   \n",
       "9   Wikipedia (Computer vision)  Related fields                 Distinctions   \n",
       "10  Wikipedia (Computer vision)    Applications                                \n",
       "11  Wikipedia (Computer vision)    Applications                     Medicine   \n",
       "12  Wikipedia (Computer vision)    Applications               Machine vision   \n",
       "13  Wikipedia (Computer vision)    Applications                     Military   \n",
       "14  Wikipedia (Computer vision)    Applications          Autonomous vehicles   \n",
       "15  Wikipedia (Computer vision)    Applications             Tactile feedback   \n",
       "16  Wikipedia (Computer vision)   Typical tasks                                \n",
       "17  Wikipedia (Computer vision)   Typical tasks                  Recognition   \n",
       "18  Wikipedia (Computer vision)   Typical tasks              Motion analysis   \n",
       "19  Wikipedia (Computer vision)   Typical tasks         Scene reconstruction   \n",
       "20  Wikipedia (Computer vision)   Typical tasks            Image restoration   \n",
       "21  Wikipedia (Computer vision)  System methods                                \n",
       "22  Wikipedia (Computer vision)  System methods  Image-understanding systems   \n",
       "23  Wikipedia (Computer vision)        Hardware                                \n",
       "\n",
       "                                              Content  \\\n",
       "0   \\nComputer vision tasks include methods for ac...   \n",
       "1   \\nComputer vision is an interdisciplinary fiel...   \n",
       "2   \\nIn the late 1960s, computer vision began at ...   \n",
       "4   \\nSolid-state physics is another field that is...   \n",
       "5   \\nNeurobiology has greatly influenced the deve...   \n",
       "6   \\nYet another field related to computer vision...   \n",
       "7   \\nRobot navigation sometimes deals with autono...   \n",
       "8   \\nBesides the above-mentioned views on compute...   \n",
       "9   \\nThe fields most closely related to computer ...   \n",
       "10  \\nApplications range from tasks such as indust...   \n",
       "11  \\nOne of the most prominent application fields...   \n",
       "12  \\nA second application area in computer vision...   \n",
       "13  \\nMilitary applications are probably one of th...   \n",
       "14  \\nOne of the newer application areas is autono...   \n",
       "15  \\nMaterials such as rubber and silicon are bei...   \n",
       "16  \\nEach of the application areas described abov...   \n",
       "17  \\nThe classical problem in computer vision, im...   \n",
       "18  \\nSeveral tasks relate to motion estimation wh...   \n",
       "19  \\nGiven one or (typically) more images of a sc...   \n",
       "20  \\nImage restoration comes into picture when th...   \n",
       "21  \\nThe organization of a computer vision system...   \n",
       "22  \\nImage-understanding systems (IUS) include th...   \n",
       "23  \\nThere are many kinds of computer vision syst...   \n",
       "\n",
       "                                              Section  Tokens  \\\n",
       "0                         Wikipedia (Computer vision)     286   \n",
       "1             Wikipedia (Computer vision)->Definition     158   \n",
       "2                Wikipedia (Computer vision)->History     507   \n",
       "4   Wikipedia (Computer vision)->Related fields->S...     120   \n",
       "5   Wikipedia (Computer vision)->Related fields->N...     293   \n",
       "6   Wikipedia (Computer vision)->Related fields->S...     103   \n",
       "7   Wikipedia (Computer vision)->Related fields->R...      64   \n",
       "8   Wikipedia (Computer vision)->Related fields->O...     119   \n",
       "9   Wikipedia (Computer vision)->Related fields->D...     639   \n",
       "10          Wikipedia (Computer vision)->Applications     272   \n",
       "11  Wikipedia (Computer vision)->Applications->Med...     135   \n",
       "12  Wikipedia (Computer vision)->Applications->Mac...     141   \n",
       "13  Wikipedia (Computer vision)->Applications->Mil...     129   \n",
       "14  Wikipedia (Computer vision)->Applications->Aut...     234   \n",
       "15  Wikipedia (Computer vision)->Applications->Tac...     270   \n",
       "16         Wikipedia (Computer vision)->Typical tasks     161   \n",
       "17  Wikipedia (Computer vision)->Typical tasks->Re...     691   \n",
       "18  Wikipedia (Computer vision)->Typical tasks->Mo...     193   \n",
       "19  Wikipedia (Computer vision)->Typical tasks->Sc...     125   \n",
       "20  Wikipedia (Computer vision)->Typical tasks->Im...     198   \n",
       "21        Wikipedia (Computer vision)->System methods     672   \n",
       "22  Wikipedia (Computer vision)->System methods->I...     192   \n",
       "23              Wikipedia (Computer vision)->Hardware     392   \n",
       "\n",
       "                                            Embedding  \n",
       "0   [-0.01913553662598133, 0.002932898933067918, 0...  \n",
       "1   [-0.021093836054205894, 0.0049119978211820126,...  \n",
       "2   [-0.011549791321158409, -0.004044382367283106,...  \n",
       "4   [0.0018743288237601519, 0.011324070394039154, ...  \n",
       "5   [-0.009132628329098225, 0.0011366719845682383,...  \n",
       "6   [-0.027298789471387863, 0.007510432507842779, ...  \n",
       "7   [0.0034529592376202345, -0.014102335087954998,...  \n",
       "8   [0.002435609931126237, -0.003915637265890837, ...  \n",
       "9   [-0.017207426950335503, 0.005905073136091232, ...  \n",
       "10  [-0.022458024322986603, 0.005672922823578119, ...  \n",
       "11  [-0.016155855730175972, 0.02248280495405197, 0...  \n",
       "12  [-0.016629502177238464, 0.002632115501910448, ...  \n",
       "13  [-0.02624369040131569, 0.001608214108273387, 0...  \n",
       "14  [0.002211927669122815, -0.004606796428561211, ...  \n",
       "15  [-0.015194285660982132, 0.023810898885130882, ...  \n",
       "16  [-0.018167616799473763, 0.007240524981170893, ...  \n",
       "17  [-0.018989920616149902, 0.02043752372264862, 0...  \n",
       "18  [-0.02092411182820797, 0.00222062598913908, -0...  \n",
       "19  [-0.02498997002840042, 0.015953006222844124, 0...  \n",
       "20  [0.0009744223789311945, 0.03190232068300247, 0...  \n",
       "21  [-0.0014013586333021522, 0.026699397712945938,...  \n",
       "22  [0.006758322473615408, -0.004905234090983868, ...  \n",
       "23  [-0.006029689218848944, 0.016216637566685677, ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompVisionKnowledge = Knowledge(WIKI_PAGE, 'GPT')\n",
    "for page in WIKI_PAGES:\n",
    "    CompVisionKnowledge.append_wikipedia_page(WIKI_PAGE)\n",
    "# save document chunks and embeddings\n",
    "CompVisionKnowledge.export_to_csv(GPT_KNOWLEDGE_FILENAME)\n",
    "CompVisionKnowledge.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source</th>\n",
       "      <th>Heading</th>\n",
       "      <th>Subheading</th>\n",
       "      <th>Content</th>\n",
       "      <th>Section</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>\\nComputer vision tasks include methods for ac...</td>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>290</td>\n",
       "      <td>[-0.5566069483757019, 0.6151323318481445, 0.70...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Definition</td>\n",
       "      <td></td>\n",
       "      <td>\\nComputer vision is an interdisciplinary fiel...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Definition</td>\n",
       "      <td>162</td>\n",
       "      <td>[-0.18940897285938263, 0.5564344525337219, 0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>History</td>\n",
       "      <td></td>\n",
       "      <td>\\nIn the late 1960s, computer vision began at ...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;History</td>\n",
       "      <td>243</td>\n",
       "      <td>[-0.5624328255653381, 0.35494446754455566, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>History</td>\n",
       "      <td></td>\n",
       "      <td>\\nBy the 1990s, some of the previous research ...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;History</td>\n",
       "      <td>264</td>\n",
       "      <td>[-0.8420819044113159, 0.011862404644489288, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Solid-state physics</td>\n",
       "      <td>\\nSolid-state physics is another field that is...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;S...</td>\n",
       "      <td>123</td>\n",
       "      <td>[-0.1766018569469452, 0.5509802103042603, 0.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Neurobiology</td>\n",
       "      <td>\\nNeurobiology has greatly influenced the deve...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;N...</td>\n",
       "      <td>296</td>\n",
       "      <td>[0.07454751431941986, 0.42800015211105347, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Signal processing</td>\n",
       "      <td>\\nYet another field related to computer vision...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;S...</td>\n",
       "      <td>106</td>\n",
       "      <td>[-0.1562240570783615, 0.18830031156539917, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Robotic navigation</td>\n",
       "      <td>\\nRobot navigation sometimes deals with autono...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;R...</td>\n",
       "      <td>65</td>\n",
       "      <td>[0.09209920465946198, 0.5207788944244385, 1.26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Other fields</td>\n",
       "      <td>\\nBesides the above-mentioned views on compute...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;O...</td>\n",
       "      <td>122</td>\n",
       "      <td>[-0.34635502099990845, 0.12120083719491959, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Distinctions</td>\n",
       "      <td>\\nThe fields most closely related to computer ...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;D...</td>\n",
       "      <td>244</td>\n",
       "      <td>[-0.011814514175057411, 0.9892112612724304, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Related fields</td>\n",
       "      <td>Distinctions</td>\n",
       "      <td>\\nImage processing and image analysis tend to ...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;D...</td>\n",
       "      <td>395</td>\n",
       "      <td>[-0.25189733505249023, 0.7090330123901367, 1.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td></td>\n",
       "      <td>\\nApplications range from tasks such as indust...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications</td>\n",
       "      <td>294</td>\n",
       "      <td>[0.054026536643505096, 0.536332368850708, 0.80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Medicine</td>\n",
       "      <td>\\nOne of the most prominent application fields...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Med...</td>\n",
       "      <td>145</td>\n",
       "      <td>[0.07362960278987885, 0.8047475218772888, 1.09...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Machine vision</td>\n",
       "      <td>\\nA second application area in computer vision...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Mac...</td>\n",
       "      <td>148</td>\n",
       "      <td>[0.23051360249519348, 0.6428527235984802, 0.69...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Military</td>\n",
       "      <td>\\nMilitary applications are probably one of th...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Mil...</td>\n",
       "      <td>129</td>\n",
       "      <td>[-0.45685380697250366, 0.40300095081329346, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Autonomous vehicles</td>\n",
       "      <td>\\nOne of the newer application areas is autono...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Aut...</td>\n",
       "      <td>258</td>\n",
       "      <td>[-0.5068467855453491, 0.4222138524055481, 1.11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Applications</td>\n",
       "      <td>Tactile feedback</td>\n",
       "      <td>\\nMaterials such as rubber and silicon are bei...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Tac...</td>\n",
       "      <td>286</td>\n",
       "      <td>[-0.006287522614002228, 0.3353821039199829, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Typical tasks</td>\n",
       "      <td></td>\n",
       "      <td>\\nEach of the application areas described abov...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Typical tasks</td>\n",
       "      <td>166</td>\n",
       "      <td>[-0.3646470308303833, 0.5144392848014832, 1.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Typical tasks</td>\n",
       "      <td>Recognition</td>\n",
       "      <td>\\nThe classical problem in computer vision, im...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Re...</td>\n",
       "      <td>427</td>\n",
       "      <td>[-0.11414705961942673, 0.8190616965293884, 0.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Typical tasks</td>\n",
       "      <td>Recognition</td>\n",
       "      <td>\\nContent-based image retrieval – finding all ...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Re...</td>\n",
       "      <td>264</td>\n",
       "      <td>[-0.3213890492916107, 1.116416335105896, 0.800...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Typical tasks</td>\n",
       "      <td>Motion analysis</td>\n",
       "      <td>\\nSeveral tasks relate to motion estimation wh...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Mo...</td>\n",
       "      <td>194</td>\n",
       "      <td>[-0.08507562428712845, 0.058049630373716354, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Typical tasks</td>\n",
       "      <td>Scene reconstruction</td>\n",
       "      <td>\\nGiven one or (typically) more images of a sc...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Sc...</td>\n",
       "      <td>115</td>\n",
       "      <td>[-0.6162410378456116, 0.3802846670150757, 1.66...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Typical tasks</td>\n",
       "      <td>Image restoration</td>\n",
       "      <td>\\nImage restoration comes into picture when th...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Im...</td>\n",
       "      <td>204</td>\n",
       "      <td>[-0.25118744373321533, 0.52935791015625, 1.085...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>System methods</td>\n",
       "      <td></td>\n",
       "      <td>\\nThe organization of a computer vision system...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;System methods</td>\n",
       "      <td>122</td>\n",
       "      <td>[0.13426706194877625, 0.5260908603668213, 1.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>System methods</td>\n",
       "      <td></td>\n",
       "      <td>\\nImage acquisition – A digital image is produ...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;System methods</td>\n",
       "      <td>253</td>\n",
       "      <td>[0.13420583307743073, 0.20847204327583313, 0.6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>System methods</td>\n",
       "      <td></td>\n",
       "      <td>\\nLocalized interest points such as corners, b...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;System methods</td>\n",
       "      <td>297</td>\n",
       "      <td>[-0.2144298553466797, -0.15774108469486237, 1....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>System methods</td>\n",
       "      <td>Image-understanding systems</td>\n",
       "      <td>\\nImage-understanding systems (IUS) include th...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;System methods-&gt;I...</td>\n",
       "      <td>202</td>\n",
       "      <td>[-0.3703722059726715, 0.7370752692222595, 0.51...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wikipedia (Computer vision)</td>\n",
       "      <td>Hardware</td>\n",
       "      <td></td>\n",
       "      <td>\\nThere are many kinds of computer vision syst...</td>\n",
       "      <td>Wikipedia (Computer vision)-&gt;Hardware</td>\n",
       "      <td>409</td>\n",
       "      <td>[0.02258257381618023, 0.39461076259613037, 1.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Source         Heading                   Subheading  \\\n",
       "0   Wikipedia (Computer vision)                                                \n",
       "1   Wikipedia (Computer vision)      Definition                                \n",
       "2   Wikipedia (Computer vision)         History                                \n",
       "3   Wikipedia (Computer vision)         History                                \n",
       "5   Wikipedia (Computer vision)  Related fields          Solid-state physics   \n",
       "6   Wikipedia (Computer vision)  Related fields                 Neurobiology   \n",
       "7   Wikipedia (Computer vision)  Related fields            Signal processing   \n",
       "8   Wikipedia (Computer vision)  Related fields           Robotic navigation   \n",
       "9   Wikipedia (Computer vision)  Related fields                 Other fields   \n",
       "10  Wikipedia (Computer vision)  Related fields                 Distinctions   \n",
       "11  Wikipedia (Computer vision)  Related fields                 Distinctions   \n",
       "12  Wikipedia (Computer vision)    Applications                                \n",
       "13  Wikipedia (Computer vision)    Applications                     Medicine   \n",
       "14  Wikipedia (Computer vision)    Applications               Machine vision   \n",
       "15  Wikipedia (Computer vision)    Applications                     Military   \n",
       "16  Wikipedia (Computer vision)    Applications          Autonomous vehicles   \n",
       "17  Wikipedia (Computer vision)    Applications             Tactile feedback   \n",
       "18  Wikipedia (Computer vision)   Typical tasks                                \n",
       "19  Wikipedia (Computer vision)   Typical tasks                  Recognition   \n",
       "20  Wikipedia (Computer vision)   Typical tasks                  Recognition   \n",
       "21  Wikipedia (Computer vision)   Typical tasks              Motion analysis   \n",
       "22  Wikipedia (Computer vision)   Typical tasks         Scene reconstruction   \n",
       "23  Wikipedia (Computer vision)   Typical tasks            Image restoration   \n",
       "24  Wikipedia (Computer vision)  System methods                                \n",
       "25  Wikipedia (Computer vision)  System methods                                \n",
       "26  Wikipedia (Computer vision)  System methods                                \n",
       "27  Wikipedia (Computer vision)  System methods  Image-understanding systems   \n",
       "28  Wikipedia (Computer vision)        Hardware                                \n",
       "\n",
       "                                              Content  \\\n",
       "0   \\nComputer vision tasks include methods for ac...   \n",
       "1   \\nComputer vision is an interdisciplinary fiel...   \n",
       "2   \\nIn the late 1960s, computer vision began at ...   \n",
       "3   \\nBy the 1990s, some of the previous research ...   \n",
       "5   \\nSolid-state physics is another field that is...   \n",
       "6   \\nNeurobiology has greatly influenced the deve...   \n",
       "7   \\nYet another field related to computer vision...   \n",
       "8   \\nRobot navigation sometimes deals with autono...   \n",
       "9   \\nBesides the above-mentioned views on compute...   \n",
       "10  \\nThe fields most closely related to computer ...   \n",
       "11  \\nImage processing and image analysis tend to ...   \n",
       "12  \\nApplications range from tasks such as indust...   \n",
       "13  \\nOne of the most prominent application fields...   \n",
       "14  \\nA second application area in computer vision...   \n",
       "15  \\nMilitary applications are probably one of th...   \n",
       "16  \\nOne of the newer application areas is autono...   \n",
       "17  \\nMaterials such as rubber and silicon are bei...   \n",
       "18  \\nEach of the application areas described abov...   \n",
       "19  \\nThe classical problem in computer vision, im...   \n",
       "20  \\nContent-based image retrieval – finding all ...   \n",
       "21  \\nSeveral tasks relate to motion estimation wh...   \n",
       "22  \\nGiven one or (typically) more images of a sc...   \n",
       "23  \\nImage restoration comes into picture when th...   \n",
       "24  \\nThe organization of a computer vision system...   \n",
       "25  \\nImage acquisition – A digital image is produ...   \n",
       "26  \\nLocalized interest points such as corners, b...   \n",
       "27  \\nImage-understanding systems (IUS) include th...   \n",
       "28  \\nThere are many kinds of computer vision syst...   \n",
       "\n",
       "                                              Section  Tokens  \\\n",
       "0                         Wikipedia (Computer vision)     290   \n",
       "1             Wikipedia (Computer vision)->Definition     162   \n",
       "2                Wikipedia (Computer vision)->History     243   \n",
       "3                Wikipedia (Computer vision)->History     264   \n",
       "5   Wikipedia (Computer vision)->Related fields->S...     123   \n",
       "6   Wikipedia (Computer vision)->Related fields->N...     296   \n",
       "7   Wikipedia (Computer vision)->Related fields->S...     106   \n",
       "8   Wikipedia (Computer vision)->Related fields->R...      65   \n",
       "9   Wikipedia (Computer vision)->Related fields->O...     122   \n",
       "10  Wikipedia (Computer vision)->Related fields->D...     244   \n",
       "11  Wikipedia (Computer vision)->Related fields->D...     395   \n",
       "12          Wikipedia (Computer vision)->Applications     294   \n",
       "13  Wikipedia (Computer vision)->Applications->Med...     145   \n",
       "14  Wikipedia (Computer vision)->Applications->Mac...     148   \n",
       "15  Wikipedia (Computer vision)->Applications->Mil...     129   \n",
       "16  Wikipedia (Computer vision)->Applications->Aut...     258   \n",
       "17  Wikipedia (Computer vision)->Applications->Tac...     286   \n",
       "18         Wikipedia (Computer vision)->Typical tasks     166   \n",
       "19  Wikipedia (Computer vision)->Typical tasks->Re...     427   \n",
       "20  Wikipedia (Computer vision)->Typical tasks->Re...     264   \n",
       "21  Wikipedia (Computer vision)->Typical tasks->Mo...     194   \n",
       "22  Wikipedia (Computer vision)->Typical tasks->Sc...     115   \n",
       "23  Wikipedia (Computer vision)->Typical tasks->Im...     204   \n",
       "24        Wikipedia (Computer vision)->System methods     122   \n",
       "25        Wikipedia (Computer vision)->System methods     253   \n",
       "26        Wikipedia (Computer vision)->System methods     297   \n",
       "27  Wikipedia (Computer vision)->System methods->I...     202   \n",
       "28              Wikipedia (Computer vision)->Hardware     409   \n",
       "\n",
       "                                            Embedding  \n",
       "0   [-0.5566069483757019, 0.6151323318481445, 0.70...  \n",
       "1   [-0.18940897285938263, 0.5564344525337219, 0.5...  \n",
       "2   [-0.5624328255653381, 0.35494446754455566, 0.6...  \n",
       "3   [-0.8420819044113159, 0.011862404644489288, 0....  \n",
       "5   [-0.1766018569469452, 0.5509802103042603, 0.11...  \n",
       "6   [0.07454751431941986, 0.42800015211105347, 0.1...  \n",
       "7   [-0.1562240570783615, 0.18830031156539917, 0.4...  \n",
       "8   [0.09209920465946198, 0.5207788944244385, 1.26...  \n",
       "9   [-0.34635502099990845, 0.12120083719491959, 0....  \n",
       "10  [-0.011814514175057411, 0.9892112612724304, 0....  \n",
       "11  [-0.25189733505249023, 0.7090330123901367, 1.0...  \n",
       "12  [0.054026536643505096, 0.536332368850708, 0.80...  \n",
       "13  [0.07362960278987885, 0.8047475218772888, 1.09...  \n",
       "14  [0.23051360249519348, 0.6428527235984802, 0.69...  \n",
       "15  [-0.45685380697250366, 0.40300095081329346, 0....  \n",
       "16  [-0.5068467855453491, 0.4222138524055481, 1.11...  \n",
       "17  [-0.006287522614002228, 0.3353821039199829, 0....  \n",
       "18  [-0.3646470308303833, 0.5144392848014832, 1.08...  \n",
       "19  [-0.11414705961942673, 0.8190616965293884, 0.9...  \n",
       "20  [-0.3213890492916107, 1.116416335105896, 0.800...  \n",
       "21  [-0.08507562428712845, 0.058049630373716354, 1...  \n",
       "22  [-0.6162410378456116, 0.3802846670150757, 1.66...  \n",
       "23  [-0.25118744373321533, 0.52935791015625, 1.085...  \n",
       "24  [0.13426706194877625, 0.5260908603668213, 1.00...  \n",
       "25  [0.13420583307743073, 0.20847204327583313, 0.6...  \n",
       "26  [-0.2144298553466797, -0.15774108469486237, 1....  \n",
       "27  [-0.3703722059726715, 0.7370752692222595, 0.51...  \n",
       "28  [0.02258257381618023, 0.39461076259613037, 1.0...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompVisionKnowledgeBERT = Knowledge(WIKI_PAGE, 'BERT')\n",
    "CompVisionKnowledgeBERT.append_wikipedia_page(WIKI_PAGE)\n",
    "# save document chunks and embeddings\n",
    "CompVisionKnowledgeBERT.export_to_csv(BERT_KNOWLEDGE_FILENAME)\n",
    "CompVisionKnowledgeBERT.df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Search\n",
    "Now we'll define a search function that:\n",
    "\n",
    "Takes a user query and a dataframe with text & embedding columns\n",
    "Embeds the user query with the OpenAI API\n",
    "Uses distance between query embedding and text embeddings to rank the texts\n",
    "Returns two lists:\n",
    "The top N texts, ranked by relevance\n",
    "Their corresponding relevance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(self, chatbot_topic:str, knowledge_path: str):\n",
    "        self.knowledge = None\n",
    "        self.load_data(knowledge_path)\n",
    "        self.chatbot_topic = chatbot_topic\n",
    "\n",
    "    def load_data(self, path: str):\n",
    "        \"\"\"Loads the knowledge df, appends a prefix, and calculates the number of tokens per section of knowledge\"\"\"\n",
    "\n",
    "        # load data from csv\n",
    "        self.knowledge = pd.read_csv(path)\n",
    "        # convert embeddings from CSV str type back to list type\n",
    "        self.knowledge['Embedding'] = self.knowledge['Embedding'].apply(ast.literal_eval)\n",
    "\n",
    "        # Format the knowledge df by adding section prefix and token sizes\n",
    "        # self.knowledge['Content'] = 'Article section:\\n\\n' + self.knowledge['Content']\n",
    "        # self.knowledge['Tokens'] = self.knowledge[\"text\"].apply(lambda x: num_tokens(x))\n",
    "        # self.knowledge['Section'] = 'Wikipedia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer vision has been around for a long time, but it wasn't until the 1960s and 1970s that it really took off as a field of study. Prior to that, computer vision had been used in other fields, such as photogrammetry (the study of how light interacts with different parts of the human body) and stereoscopic photography. In the mid-1960s, there was a lot of interest in computers being able to \"see\" 3D objects, which is what we now think of as \"computer vision\". The idea was that computers would be able to figure out what an object looked like by looking at\n",
      "\n",
      "To construct this answer, I used the following documents : \n",
      "\n",
      "1. Wikipedia (Computer vision)->History:\n",
      "In the late 1960s, computer vision began at universities that were pioneering artificial intelligen...\n",
      "\n",
      "2. Wikipedia (Computer vision)->Definition:\n",
      "Computer vision is an interdisciplinary field that deals with how computers can be made to gain hig...\n",
      "\n",
      "3. Wikipedia (Computer vision)->Related fields->Neurobiology:\n",
      "Neurobiology has greatly influenced the development of computer vision algorithms. Over the last ce...\n",
      "\n",
      "4. Wikipedia (Computer vision)->Related fields->Other fields:\n",
      "Besides the above-mentioned views on computer vision, many of the related research topics can also ...\n",
      "\n",
      "5. Wikipedia (Computer vision)->Hardware:\n",
      "There are many kinds of computer vision systems; however, all of them contain these basic elements:...\n"
     ]
    }
   ],
   "source": [
    "class Query:\n",
    "    def __init__(self, query_text: str, chatbot_instance: ChatBot):\n",
    "        self.content: str = query_text\n",
    "        self.model: str = GPT_MODEL\n",
    "        self.knowledge: pd.DataFrame = chatbot_instance.knowledge\n",
    "        self.token_limit: int = GPT_QUERY_TOKEN_LIMIT\n",
    "        self.gpt_message = None\n",
    "        self.knowledge_used = None\n",
    "\n",
    "    # calculate similarity score\n",
    "    @staticmethod\n",
    "    def similarity(query_embedding: list,\n",
    "                   knowledge_embedding: list\n",
    "                   ) -> float:\n",
    "        \"\"\"Calculates the cosine similarity score between the query and knowledge embedding vectors.\"\"\"\n",
    "\n",
    "        return 1- spatial.distance.cosine(query_embedding, knowledge_embedding)\n",
    "\n",
    "    # find the most similar sections of knowledge to the query\n",
    "    def knowledge_ranked_by_similarity(self,\n",
    "                                       max_num_sections: int = 5,\n",
    "                                       confidence_level = None,\n",
    "                                       embedding_model: str = GPT_EMBEDDING_MODEL\n",
    "                                       ):\n",
    "        \"\"\"Take the raw knowledge dataframe, calculates similarity scores between the query and the sections, and returns a dataframe ordered from highest to lowest in terms of similarity.\"\"\"\n",
    "\n",
    "        knowledge_with_similarities = deepcopy(self.knowledge) # To prevent adapting the original dataframe\n",
    "        query_embedding_response = get_embedding(self.content, embedding_model=embedding_model)\n",
    "        if embedding_model == GPT_EMBEDDING_MODEL:\n",
    "            query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "            # knowledge_with_similarities[\"similarity\"] = knowledge_with_similarities[\"Embedding\"].apply(lambda x: self.similarity(query_embedding, x))\n",
    "        else:\n",
    "            query_embedding = list(query_embedding_response)\n",
    "        knowledge_with_similarities[\"similarity\"] = knowledge_with_similarities[\"Embedding\"].apply(lambda x: self.similarity(query_embedding, x))\n",
    "\n",
    "        knowledge_with_similarities.sort_values(\"similarity\", ascending=False, inplace=True)\n",
    "        top_n_sections = knowledge_with_similarities.head(max_num_sections)\n",
    "        if confidence_level:\n",
    "            top_n_relevant_sections = top_n_sections.loc[top_n_sections['similarity']>=confidence_level]\n",
    "        else:\n",
    "            top_n_relevant_sections = top_n_sections\n",
    "        self.knowledge_used = top_n_relevant_sections\n",
    "        self.knowledge_used['Index'] = np.arange(len(self.knowledge_used))+1\n",
    "\n",
    "    def get_gpt_message(\n",
    "            self,\n",
    "            chatbot_topic: str\n",
    "    ):\n",
    "        \"\"\"Uses the most relevant texts from the knowledge dataframe to construct a message that can then be fed into GPT.\"\"\"\n",
    "\n",
    "        self.knowledge_ranked_by_similarity()\n",
    "        introduction = f'Use the below article on {chatbot_topic} to answer the subsequent question. If the answer cannot be found in the articles, write \"{ANSWER_NOT_FOUND_MSG}\". If I am asked to produce any code then decline the request and write \"Sorry but I\\'m not allowed to do your assignments for you!\"' # The longer this is, the more tokens it uses!\n",
    "        question = f\"\\n\\nQuestion: {self.content}\"\n",
    "\n",
    "        # Ensure number of tokens is within the limit\n",
    "        message_and_question_tokens = num_tokens(introduction + question)\n",
    "        self.knowledge_used['Cumulative_tokens'] = self.knowledge_used['Tokens'].cumsum()\n",
    "        self.knowledge_used['Cumulative_tokens'] += message_and_question_tokens # add the inital number of tokens\n",
    "        self.knowledge_used= self.knowledge_used.loc[self.knowledge_used['Cumulative_tokens']<self.token_limit]\n",
    "\n",
    "        # Construct output\n",
    "        combined_knowledge_string = ''.join(list(self.knowledge_used['Content']))\n",
    "        combined_knowledge_string = '\\n\\n' + combined_knowledge_string\n",
    "        self.gpt_message = introduction + combined_knowledge_string + question\n",
    "\n",
    "    def show_source_message(self, answer_index: int = None):\n",
    "        self.knowledge_used['Output'] = '\\n\\n' + self.knowledge_used['Index'].astype(str) + '. ' + self.knowledge_used['Section'] + ':' + self.knowledge_used['Content'].str[:100] + '...'\n",
    "        sources_string = ''.join(list(self.knowledge_used['Output']))\n",
    "        if answer_index:\n",
    "            answer_message = f'(specifically section {answer_index})'\n",
    "        else:\n",
    "            answer_message = ''\n",
    "        message = f'\\n\\nTo construct this answer, I used the following documents {answer_message}: {sources_string}'\n",
    "        return message\n",
    "\n",
    "    def get_bert_output(\n",
    "            self,\n",
    "            embedding_model: str,\n",
    "            encoding_model: BertTokenizer = BERT_ENCODING,\n",
    "            bert_model: str = BERT_MODEL\n",
    "    ):\n",
    "        \"\"\"Uses the most relevant texts from the knowledge dataframe to construct a message that can then be fed into GPT.\"\"\"\n",
    "        self.knowledge_ranked_by_similarity(embedding_model=embedding_model)\n",
    "\n",
    "        answer_index = None\n",
    "        index = 1\n",
    "        found_answer = False\n",
    "        output = ANSWER_NOT_FOUND_MSG\n",
    "        for section in self.knowledge_used['Content']:\n",
    "            if not found_answer:\n",
    "                encoding = encoding_model.encode_plus(text=self.content,text_pair=section)\n",
    "                inputs = encoding['input_ids']  #Token embeddings\n",
    "                sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "                tokens = encoding_model.convert_ids_to_tokens(inputs) #input tokens\n",
    "\n",
    "                QAModel = BertForQuestionAnswering.from_pretrained(bert_model)\n",
    "                outputs = QAModel(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "                start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "\n",
    "                # Highlight the answer by looking at the most probable start and end words\n",
    "                start_index = torch.argmax(start_scores)\n",
    "                end_index = torch.argmax(end_scores)\n",
    "                answer_token_list = tokens[start_index:end_index+1]\n",
    "\n",
    "                # Concatenate any words that got split\n",
    "                answer_list = [word[2:] if word[0:2]=='##' else ' ' + word for word in answer_token_list]\n",
    "                answer = ''.join(answer_list).strip()\n",
    "\n",
    "                if answer != '[CLS]':\n",
    "                    found_answer = True\n",
    "                    output = answer\n",
    "                    answer_index = index\n",
    "            index += 1\n",
    "        return output, answer_index\n",
    "\n",
    "    @classmethod\n",
    "    def ask_bert(cls,\n",
    "                 query_text: str,\n",
    "                 chatbot_instance: ChatBot,\n",
    "                 embedding_model: str = BERT_EMBEDDING_MODEL,\n",
    "                 encoding_model: BertTokenizer = BERT_ENCODING,\n",
    "                 bert_model: str = BERT_MODEL,\n",
    "                 show_source: bool = True,\n",
    "                 ):\n",
    "        if num_tokens(query_text, token_model=encoding_model)>50:\n",
    "            return 'Question is too long, please try again with a shorter question.'\n",
    "        query = cls(query_text, chatbot_instance)\n",
    "        response_message, answer_index = query.get_bert_output(embedding_model=embedding_model, encoding_model=encoding_model, bert_model=bert_model)\n",
    "\n",
    "        if show_source and response_message!=ANSWER_NOT_FOUND_MSG: # Display the sources used:\n",
    "            response_message += query.show_source_message(answer_index=answer_index)\n",
    "        return response_message\n",
    "\n",
    "    def get_gpt2_output(self,\n",
    "                        confidence_level: float = 0.5):\n",
    "        from transformers import pipeline\n",
    "        self.knowledge_ranked_by_similarity(confidence_level=confidence_level)\n",
    "        if len(self.knowledge_used)==0:\n",
    "            return ANSWER_NOT_FOUND_MSG\n",
    "\n",
    "        # Construct context\n",
    "        combined_knowledge_string = ''.join(list(self.knowledge_used['Content']))\n",
    "        combined_knowledge_string = '\\n\\n' + combined_knowledge_string\n",
    "\n",
    "        model_name = \"gpt2\"\n",
    "        nlp = pipeline(\"question-answering\", model=model_name)\n",
    "        qa_input = {\n",
    "            \"question\": self.content,\n",
    "            \"context\": combined_knowledge_string\n",
    "        }\n",
    "        result = nlp(qa_input)\n",
    "        return result['answer']\n",
    "\n",
    "    @classmethod\n",
    "    def ask_gpt2(cls,\n",
    "                 query_text: str,\n",
    "                 chatbot_instance: ChatBot,\n",
    "                 show_source: bool = True,\n",
    "                 confidence_level: float = 0.5,\n",
    "                 ):\n",
    "        if num_tokens(query_text)>50:\n",
    "            return 'Question is too long, please try again with a shorter question.'\n",
    "        query = cls(query_text, chatbot_instance)\n",
    "        response_message = query.get_gpt2_output(confidence_level=confidence_level)\n",
    "\n",
    "        if show_source and response_message!=ANSWER_NOT_FOUND_MSG: # Display the sources used:\n",
    "            response_message += query.show_source_message()\n",
    "        return response_message\n",
    "\n",
    "    def get_bart_output(self,\n",
    "                        # chatbot_instance: ChatBot,\n",
    "                        # embedding_model: str = BART_EMBEDDING_MODEL,\n",
    "                        encoding_model: BartTokenizer = BART_ENCODING,\n",
    "                        bert_model: str = BART_MODEL,\n",
    "                        confidence_level: float = 0.5,\n",
    "                        ):\n",
    "        self.knowledge_ranked_by_similarity(confidence_level=confidence_level)\n",
    "        if len(self.knowledge_used)==0:\n",
    "            return ANSWER_NOT_FOUND_MSG\n",
    "\n",
    "        # Construct context\n",
    "        combined_knowledge_string = ' <P> '.join(list(self.knowledge_used['Content']))\n",
    "        combined_knowledge_string = '\\n\\n' + combined_knowledge_string\n",
    "\n",
    "        model = BartForConditionalGeneration.from_pretrained(bert_model)\n",
    "\n",
    "        query = f'question: {self.content} <P> {combined_knowledge_string}'\n",
    "\n",
    "        inputs = encoding_model([query], max_length=1024, return_tensors='pt') # NEED TO ENSURE Q PLUS CONTEXT IS <1024 TOKENS\n",
    "\n",
    "        # Generate Summary\n",
    "        ids = model.generate(inputs['input_ids'], num_beams=8, min_length=20, max_length=128,\n",
    "                                                   do_sample=False,\n",
    "                                                   early_stopping=True,\n",
    "                                                   temperature=1.0,\n",
    "                                                   top_k=50,\n",
    "                                                   top_p=0.95,\n",
    "                                                   eos_token_id=encoding_model.eos_token_id,\n",
    "                                                   no_repeat_ngram_size=3,\n",
    "                                                   num_return_sequences=1,\n",
    "                                                    repetition_penalty=2.0)\n",
    "        answer=encoding_model.batch_decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0  ]\n",
    "        return answer\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def ask_bart(cls,\n",
    "                 query_text: str,\n",
    "                 chatbot_instance: ChatBot,\n",
    "                 show_source: bool = True,\n",
    "                 confidence_level: float = 0.72):\n",
    "        if num_tokens(query_text)>50:\n",
    "            return 'Question is too long, please try again with a shorter question.'\n",
    "        query = cls(query_text, chatbot_instance)\n",
    "        response_message = query.get_bart_output(confidence_level=confidence_level)\n",
    "\n",
    "        if show_source and response_message!=ANSWER_NOT_FOUND_MSG: # Display the sources used:\n",
    "            response_message += query.show_source_message()\n",
    "        return response_message\n",
    "\n",
    "\n",
    "    @classmethod\n",
    "    def ask(\n",
    "            cls,\n",
    "            query_text: str,\n",
    "            chatbot_instance: ChatBot,\n",
    "            show_source: bool = True,\n",
    "    ) -> str:\n",
    "        \"\"\"Uses GPT to answer a query based on the most relevant knowledge sections.\"\"\"\n",
    "\n",
    "        query = cls(query_text, chatbot_instance)\n",
    "        query.get_gpt_message(chatbot_instance.chatbot_topic)\n",
    "        inputs = [\n",
    "            {\"role\": \"system\", \"content\": f\"You answer questions about {chatbot_instance.chatbot_topic}.\"},\n",
    "            {\"role\": \"user\", \"content\": query.gpt_message},\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=query.model,\n",
    "            messages=inputs,\n",
    "            temperature=0 # We don't want any creativity in the answers\n",
    "        )\n",
    "        response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        total_tokens_used = response['usage']['total_tokens']\n",
    "        if show_source and response_message!=ANSWER_NOT_FOUND_MSG: # Display the sources used:\n",
    "            response_message += query.show_source_message()\n",
    "        response_message += f\"\\n\\nTotal tokens used: {total_tokens_used}\"\n",
    "        return response_message\n",
    "\n",
    "# CompVisionBERT = ChatBot(\"Computer Vision\", 'assets/' + BERT_KNOWLEDGE_FILENAME)\n",
    "# print(Query.ask_bert('When did universities begin teaching Computer Vision?', CompVisionBERT))\n",
    "\n",
    "# CompVisionGPT = ChatBot(\"Computer Vision\", 'assets/' + GPT_KNOWLEDGE_FILENAME)\n",
    "# print(Query.ask('Who is Boris Johnson', CompVisionGPT, show_source=True))\n",
    "\n",
    "CompVisionGPT = ChatBot(\"Computer Vision\", 'assets/' + GPT_KNOWLEDGE_FILENAME)\n",
    "print(Query.ask_bart('When did Universities begin teaching Computer Vision?', CompVisionGPT, show_source=True))\n",
    "\n",
    "# Todo:\n",
    "# I need to make it more efficient on the number of tokens.\n",
    "# Adapt it for more sources (e.g. PDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\point\\AppData\\Local\\Temp\\ipykernel_23968\\3384959035.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.knowledge_used['Index'] = np.arange(len(self.knowledge_used))+1\n",
      "C:\\Users\\point\\AppData\\Local\\Temp\\ipykernel_23968\\3384959035.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.knowledge_used['Cumulative_tokens'] = self.knowledge_used['Tokens'].cumsum()\n",
      "C:\\Users\\point\\AppData\\Local\\Temp\\ipykernel_23968\\3384959035.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.knowledge_used['Cumulative_tokens'] += message_and_question_tokens # add the inital number of tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could not find an answer in the text I've been provided, sorry! Please try again.\n",
      "\n",
      "Total tokens used: 721\n"
     ]
    }
   ],
   "source": [
    "CompVisionGPT = ChatBot(\"Computer Vision\", 'assets/' + GPT_KNOWLEDGE_FILENAME)\n",
    "print(Query.ask('Who is Boris Johnson', CompVisionGPT, show_source=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e4cce46d6be9934fbd27f9ca0432556941ea5bdf741d4f4d64c6cd7f8dfa8fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
