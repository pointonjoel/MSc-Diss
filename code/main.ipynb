{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GPT-3.5-Turbo Model\n",
    "Creating a question answering chatbot using GPT-3.5. Adapted from: https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preamble\n",
    "import PyPDF2 # For parsing PDF documents\n",
    "import ast  # covert embeddings saved as strings back to arrays\n",
    "import openai  # OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import numpy as np # for df manipulations\n",
    "import tiktoken  # for counting tokens\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "import wikipedia # For sourcing Wikipedia article text\n",
    "import re  # for cutting <ref> links out of Wikipedia articles\n",
    "import mwparserfromhell  # for splitting Wikipedia articles into sections\n",
    "from copy import deepcopy # for copying dataframes\n",
    "import torch # for BERT's argmax and tensors\n",
    "from transformers import BertForQuestionAnswering # Not used\n",
    "from transformers import BertTokenizer # For BERT's tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# Config\n",
    "GPT_EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "BERT_EMBEDDING_MODEL = 'bert-base-nli-mean-tokens'\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "BERT_MODEL = \"deepset/bert-base-cased-squad2\"\n",
    "GPT_KNOWLEDGE_FILENAME = \"CompVisionGPT.csv\"\n",
    "BERT_KNOWLEDGE_FILENAME = \"CompVisionBERT.csv\"\n",
    "BERT_ENCODING = BertTokenizer.from_pretrained(BERT_MODEL)\n",
    "GPT_ENCODING = tiktoken.encoding_for_model(GPT_MODEL)\n",
    "BATCH_SIZE = 1000  # you can submit up to 2048 embedding inputs per request\n",
    "GPT_MAX_TOKENS = 1600 # max number of tokens per section\n",
    "BERT_MAX_TOKENS = 460 # max tokens per section\n",
    "MIN_LENGTH = 50 # min character length for each section\n",
    "ANSWER_NOT_FOUND_MSG = \"I could not find an answer in the text I\\'ve been provided, sorry! Please try again.\"\n",
    "WIKI_PAGE = \"Computer vision\"\n",
    "SECTIONS_TO_IGNORE = [\n",
    "    \"See also\",\n",
    "    \"References\",\n",
    "    \"External links\",\n",
    "    \"Further reading\",\n",
    "    \"Footnotes\",\n",
    "    \"Bibliography\",\n",
    "    \"Sources\",\n",
    "    \"Citations\",\n",
    "    \"Literature\",\n",
    "    \"Footnotes\",\n",
    "    \"Notes and references\",\n",
    "    \"Photo gallery\",\n",
    "    \"Works cited\",\n",
    "    \"Photos\",\n",
    "    \"Gallery\",\n",
    "    \"Notes\",\n",
    "    \"References and sources\",\n",
    "    \"References and notes\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "2.Veryfewvisual taskscanbesuccessfully performed inapurely data-driv en\n",
      "way(\\bottom-up\" image analysis). Consider thenextimage example:\n",
      "aged bytheirtextured backgrounds; thefoxes\n",
      "occlude eachother; theyappearinseveraldi\u000Beren tposesandperspective\n",
      "angles; etc.Howcanthere possibly existmathematical operators forsuch\n",
      "animage thatcan:\n",
      "\u000Fperform the\fgure-ground segmen tation ofthescene (intoitsobjects\n",
      "andbackground)\n",
      "\u000Finferthe3Darrangemen tsofobjectsfromtheirmutual occlusions\n",
      "\u000Finfersurface properties (texture, colour) fromthe2Dimage statistics\n",
      "\u000Finfervolumetric objectproperties fromtheir2Dimage projections\n",
      "\u000Fanddoallofthisin\\real time?\" (This matters quite alotinthe\n",
      "natural world\\redintoothandclaw,\"sincesurviv aldependsonit.)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# creating a pdf reader instance\n",
    "reader = PyPDF2.PdfReader('assets/online_notes.pdf')\n",
    "\n",
    "# print the number of pages in pdf file\n",
    "print(len(reader.pages))\n",
    "\n",
    "# print the text of the first page\n",
    "print(reader.pages[5].extract_text())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Used throughout\n",
    "def num_tokens(\n",
    "        text: str,\n",
    "        token_model = GPT_ENCODING\n",
    ") -> int:\n",
    "    \"\"\"Returns the number of tokens in a string.\"\"\"\n",
    "    if token_model == GPT_ENCODING:\n",
    "        return len(token_model.encode(text))\n",
    "    elif token_model == BERT_ENCODING:\n",
    "        return len(token_model.tokenize(text))\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "def get_embedding(content: list or str, embedding_model: str = GPT_EMBEDDING_MODEL):\n",
    "    if embedding_model == GPT_EMBEDDING_MODEL:\n",
    "        return openai.Embedding.create(input=content, model=embedding_model)\n",
    "    else:\n",
    "        similarity_model = SentenceTransformer(embedding_model)\n",
    "        return similarity_model.encode(content)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class Knowledge:\n",
    "    def __init__(self, topic, model):\n",
    "        self.topic: str = topic\n",
    "        self.model: str = model\n",
    "        self.token_model = self.get_token_model()\n",
    "        self.embedding_model: str = self.get_embedding_model()\n",
    "        self.df: pd.DataFrame = self.get_blank_knowledge_df() # need to add code to remove small sections (<16 chars?)\n",
    "        self.max_tokens: int = self.get_max_tokens() # max number of tokens per section\n",
    "        self.min_section_length = MIN_LENGTH # min character length for each section\n",
    "\n",
    "    def get_token_model(self):\n",
    "        return GPT_ENCODING if self.model=='GPT' else BERT_ENCODING\n",
    "\n",
    "    def get_max_tokens(self):\n",
    "        return GPT_MAX_TOKENS if self.model=='GPT' else BERT_MAX_TOKENS\n",
    "\n",
    "    def get_embedding_model(self):\n",
    "        return GPT_EMBEDDING_MODEL if self.model=='GPT' else BERT_EMBEDDING_MODEL\n",
    "\n",
    "    def get_blank_knowledge_df(self) -> pd.DataFrame:\n",
    "        return pd.DataFrame(columns=['Source', 'Heading', 'Subheading', 'Content'])\n",
    "\n",
    "    def extract_wiki_sections(self,\n",
    "                              page_name: str,\n",
    "                              content: mwparserfromhell.wikicode.Wikicode,\n",
    "                              sections_to_ignore: list = SECTIONS_TO_IGNORE\n",
    "                              ) -> pd.DataFrame:\n",
    "        \"\"\"Creates a df of sections by extracting section content from a Wikicode\"\"\"\n",
    "\n",
    "        knowledge = self.get_blank_knowledge_df()\n",
    "        for section in content.get_sections(levels=[2]):\n",
    "            section_headings = section.filter_headings()\n",
    "            section_header = str(section_headings[0])\n",
    "            if len(section_headings)==1:# therefore a section title, not a subsection\n",
    "                section = section.strip(section_header)\n",
    "                if section_header.strip(\"=\" + \" \") not in sections_to_ignore: # append to df\n",
    "                    new_row = {'Source': f'Wikipedia ({page_name})', 'Heading': section_header.strip(\"=\" + \" \"), 'Content': section}\n",
    "                    knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "            elif len(section_headings)>1 and section_header.strip(\"=\" + \" \") not in sections_to_ignore: # therefore subsections\n",
    "                # Append the text before the first subsection\n",
    "                initial_text = section.split(str(section_headings[1]))[0]\n",
    "                initial_text = initial_text.strip(section_header)\n",
    "                new_row = {'Source': f'Wikipedia ({page_name})', 'Heading': section_header.strip(\"=\" + \" \"), 'Content': initial_text}\n",
    "                knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "                for subsection in section.get_sections(levels=[3]):\n",
    "                    subsection_sections = subsection.get_sections(levels=[3])[0]\n",
    "                    subsection_headings = subsection_sections.filter_headings()\n",
    "                    subsection_header = str(subsection_headings[0])\n",
    "                    subsection = subsection.strip(subsection_header)\n",
    "                    if subsection_header.strip(\"=\" + \" \") not in sections_to_ignore: # append to df\n",
    "                        new_row = {'Source': f'Wikipedia ({page_name})', 'Heading': section_header.strip(\"=\" + \" \"), 'Subheading': subsection_header.strip(\"=\" + \" \"), 'Content': subsection}\n",
    "                        knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "        return knowledge\n",
    "\n",
    "    def generate_source_column(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Creates a new column in the df which contains a summary of the source location\"\"\"\n",
    "\n",
    "        df.fillna('', inplace=True)\n",
    "        df['Section'] = df['Source'] + '->' + df['Heading'] + '->' + df['Subheading']\n",
    "        df['Section'] = df['Section'].str.replace('->->', '')\n",
    "        df['Section'] = df['Section'].str.rstrip('_->')\n",
    "        return df\n",
    "\n",
    "    def clean_section_contents(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Returns a cleaned up section with <ref>xyz</ref> patterns and leading/trailing whitespace removed\"\"\"\n",
    "\n",
    "        # text = re.sub(r\"<ref.*?</ref>\", \"\", text)\n",
    "        df['Content'] = df['Content'].str.replace(r\"<ref.*?</ref>\", \"\", regex=True)\n",
    "        df['Content'] = df['Content'].str.strip() # removes whitespace\n",
    "        df['Content'] = '\\n' + df['Content'] # need to add the \\n back to the start of each title\n",
    "        return df\n",
    "\n",
    "    def merge_elements_of_list(self, list_of_strings: list, delimiter: str = \"\\n\"):\n",
    "        potential_for_more_merging = False\n",
    "        merged_list = []\n",
    "        skip_item = False\n",
    "        for i in range(len(list_of_strings)):\n",
    "            if not skip_item:\n",
    "                if i == len(list_of_strings)-1:\n",
    "                    merged_list.append(list_of_strings[i])\n",
    "                else:\n",
    "                    merged_strings = list_of_strings[i] + delimiter + list_of_strings[i+1]\n",
    "                    if num_tokens(merged_strings)<self.max_tokens:\n",
    "                        merged_list.append(merged_strings)\n",
    "                        skip_item = True # make it skip the element we just merged\n",
    "                        potential_for_more_merging = True\n",
    "                    else:\n",
    "                        merged_list.append(list_of_strings[i])\n",
    "            else:\n",
    "                skip_item = False # set the default back to False unless otherwise specified\n",
    "        return merged_list, potential_for_more_merging\n",
    "\n",
    "    def force_split_string(self,\n",
    "                           string: str,\n",
    "                           encoding = GPT_ENCODING) -> list:\n",
    "        \"\"\"Force a section to be split into 2 (to be used if it has no delimiter)\"\"\"\n",
    "\n",
    "        list_of_strings = []\n",
    "        if num_tokens(string) <= self.max_tokens:\n",
    "            return [string]\n",
    "        else:\n",
    "            needs_truncating = True\n",
    "            while needs_truncating:\n",
    "                encoded_string = encoding.encode(string)\n",
    "                truncated_string = encoding.decode(encoded_string[:self.max_tokens])\n",
    "                remainder_of_string = encoding.decode(encoded_string[self.max_tokens:])\n",
    "                list_of_strings.append(truncated_string)\n",
    "                string = remainder_of_string\n",
    "                if num_tokens(remainder_of_string)<self.max_tokens:\n",
    "                    needs_truncating=False\n",
    "                    list_of_strings.append(remainder_of_string)\n",
    "        return list_of_strings\n",
    "\n",
    "    def split_long_sections(self, df: pd.DataFrame, delimiter: str = '\\n'):\n",
    "        \"\"\"Splits long sections of text into smaller ones\"\"\"\n",
    "\n",
    "        new_dict_of_shorter_sections = self.get_blank_knowledge_df().to_dict('records')\n",
    "        df_as_dict = df.to_dict('records')\n",
    "        for section in df_as_dict:\n",
    "            # for delimiter in delimiters:\n",
    "            if section['Tokens']<=self.max_tokens:\n",
    "                new_dict_of_shorter_sections.append(section)\n",
    "            else:\n",
    "                # needs to be split up\n",
    "                if delimiter == '': # meaning that we just need to truncate it.\n",
    "                    text = self.force_split_string(section['Content'])\n",
    "                else:\n",
    "                    text = section['Content'].split(delimiter)\n",
    "                    if delimiter == '. ':\n",
    "                        for i in range(len(text)-1):\n",
    "                            text[i] += delimiter\n",
    "                potential_for_more_merging = True\n",
    "                i = 0\n",
    "                while potential_for_more_merging:\n",
    "                    if i>20:\n",
    "                        break\n",
    "                    else:\n",
    "                        text, potential_for_more_merging = self.merge_elements_of_list(text)\n",
    "\n",
    "                # The sections should be merged into acceptable sizes:\n",
    "                if len(text)>1:\n",
    "                    for string in text:\n",
    "                        item_to_append = {'Source': section['Source'], 'Heading': section['Heading'], 'Subheading': section['Subheading'], 'Content': string, 'Section': section['Section'], 'Tokens': num_tokens(string)}\n",
    "\n",
    "                        new_dict_of_shorter_sections.append(item_to_append)\n",
    "                else:\n",
    "                    item_to_append = {'Source': section['Source'], 'Heading': section['Heading'], 'Subheading': section['Subheading'], 'Content': text[0], 'Section': section['Section'], 'Tokens': num_tokens(text[0])}\n",
    "                    new_dict_of_shorter_sections.append(item_to_append) # we shouldn't have this because the text should be more than the acceptable number of tokens\n",
    "        return pd.DataFrame(new_dict_of_shorter_sections)\n",
    "\n",
    "    def append_wikipedia_page(self, page_name: str,\n",
    "                              sections_to_ignore: list = SECTIONS_TO_IGNORE):\n",
    "        \"\"\"Takes a wikipedia page and appends the sections to the knowledge df\"\"\"\n",
    "\n",
    "        site = wikipedia.page(page_name, auto_suggest=False)\n",
    "        text = site.content\n",
    "        parsed_text = mwparserfromhell.parse(text)\n",
    "\n",
    "        # Creating initial df and appending the introduction paragraph (the text up to the first heading)\n",
    "        intro = str(parsed_text).split(str(parsed_text.filter_headings()[0]))[0]\n",
    "        knowledge = self.get_blank_knowledge_df()\n",
    "        new_row = {'Source': f'Wikipedia ({page_name})', 'Content': '\\n'+intro}\n",
    "        knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "\n",
    "        section_content = self.extract_wiki_sections(page_name=page_name, content=parsed_text, sections_to_ignore=sections_to_ignore)\n",
    "        knowledge = pd.concat([knowledge, section_content])\n",
    "\n",
    "        # Generate succinct heading information\n",
    "        knowledge = self.generate_source_column(knowledge)\n",
    "        self.df = pd.concat([self.df, knowledge])\n",
    "\n",
    "        # Remove unwanted strings and whitespace\n",
    "        self.df = self.clean_section_contents(self.df)\n",
    "\n",
    "        # Generate number of tokens in each section\n",
    "        self.df['Tokens'] = self.df[\"Content\"].apply(lambda x: num_tokens(x, token_model=self.token_model))\n",
    "\n",
    "        # Split long sections\n",
    "        for delim in [\"\\n\\n\", \"\\n\", \". \", '']:\n",
    "            self.df = self.split_long_sections(self.df, delimiter=delim)\n",
    "\n",
    "        # Remove short sections\n",
    "        self.df = self.df.loc[self.df['Content'].str.len()>self.min_section_length]\n",
    "\n",
    "        # Append '\\n' to the start if it doesn't already have one\n",
    "        self.df.loc[~self.df['Content'].str.startswith('\\n'), 'Content'] = '\\n' + self.df.loc[~self.df['Content'].str.startswith('\\n'), 'Content']\n",
    "\n",
    "        # Get embeddings\n",
    "        if self.model == 'GPT':\n",
    "            response = get_embedding(list(self.df['Content']), embedding_model=self.embedding_model)\n",
    "            for i, be in enumerate(response[\"data\"]):\n",
    "                assert i == be[\"index\"]  # double check embeddings are in same order as input\n",
    "            batch_embeddings = [e[\"embedding\"] for e in response[\"data\"]]\n",
    "            self.df['Embedding'] = batch_embeddings\n",
    "        else:\n",
    "            self.df['Embedding'] = get_embedding(list(self.df['Content']), embedding_model=self.embedding_model).tolist()\n",
    "\n",
    "    def export_to_csv(self, filename):\n",
    "        \"\"\"Saves the knowledge df to a CSV file\"\"\"\n",
    "        location = 'assets/' + filename\n",
    "        self.df.to_csv(location, index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Source         Heading                   Subheading  \\\n0   Wikipedia (Computer vision)                                                \n1   Wikipedia (Computer vision)      Definition                                \n2   Wikipedia (Computer vision)         History                                \n4   Wikipedia (Computer vision)  Related fields          Solid-state physics   \n5   Wikipedia (Computer vision)  Related fields                 Neurobiology   \n6   Wikipedia (Computer vision)  Related fields            Signal processing   \n7   Wikipedia (Computer vision)  Related fields           Robotic navigation   \n8   Wikipedia (Computer vision)  Related fields                 Other fields   \n9   Wikipedia (Computer vision)  Related fields                 Distinctions   \n10  Wikipedia (Computer vision)    Applications                                \n11  Wikipedia (Computer vision)    Applications                     Medicine   \n12  Wikipedia (Computer vision)    Applications               Machine vision   \n13  Wikipedia (Computer vision)    Applications                     Military   \n14  Wikipedia (Computer vision)    Applications          Autonomous vehicles   \n15  Wikipedia (Computer vision)    Applications             Tactile feedback   \n16  Wikipedia (Computer vision)   Typical tasks                                \n17  Wikipedia (Computer vision)   Typical tasks                  Recognition   \n18  Wikipedia (Computer vision)   Typical tasks              Motion analysis   \n19  Wikipedia (Computer vision)   Typical tasks         Scene reconstruction   \n20  Wikipedia (Computer vision)   Typical tasks            Image restoration   \n21  Wikipedia (Computer vision)  System methods                                \n22  Wikipedia (Computer vision)  System methods  Image-understanding systems   \n23  Wikipedia (Computer vision)        Hardware                                \n\n                                              Content  \\\n0   \\nComputer vision tasks include methods for ac...   \n1   \\nComputer vision is an interdisciplinary fiel...   \n2   \\nIn the late 1960s, computer vision began at ...   \n4   \\nSolid-state physics is another field that is...   \n5   \\nNeurobiology has greatly influenced the deve...   \n6   \\nYet another field related to computer vision...   \n7   \\nRobot navigation sometimes deals with autono...   \n8   \\nBesides the above-mentioned views on compute...   \n9   \\nThe fields most closely related to computer ...   \n10  \\nApplications range from tasks such as indust...   \n11  \\nOne of the most prominent application fields...   \n12  \\nA second application area in computer vision...   \n13  \\nMilitary applications are probably one of th...   \n14  \\nOne of the newer application areas is autono...   \n15  \\nMaterials such as rubber and silicon are bei...   \n16  \\nEach of the application areas described abov...   \n17  \\nThe classical problem in computer vision, im...   \n18  \\nSeveral tasks relate to motion estimation wh...   \n19  \\nGiven one or (typically) more images of a sc...   \n20  \\nImage restoration comes into picture when th...   \n21  \\nThe organization of a computer vision system...   \n22  \\nImage-understanding systems (IUS) include th...   \n23  \\nThere are many kinds of computer vision syst...   \n\n                                              Section  Tokens  \\\n0                         Wikipedia (Computer vision)     286   \n1             Wikipedia (Computer vision)->Definition     158   \n2                Wikipedia (Computer vision)->History     507   \n4   Wikipedia (Computer vision)->Related fields->S...     120   \n5   Wikipedia (Computer vision)->Related fields->N...     293   \n6   Wikipedia (Computer vision)->Related fields->S...     103   \n7   Wikipedia (Computer vision)->Related fields->R...      64   \n8   Wikipedia (Computer vision)->Related fields->O...     119   \n9   Wikipedia (Computer vision)->Related fields->D...     639   \n10          Wikipedia (Computer vision)->Applications     272   \n11  Wikipedia (Computer vision)->Applications->Med...     135   \n12  Wikipedia (Computer vision)->Applications->Mac...     141   \n13  Wikipedia (Computer vision)->Applications->Mil...     129   \n14  Wikipedia (Computer vision)->Applications->Aut...     234   \n15  Wikipedia (Computer vision)->Applications->Tac...     270   \n16         Wikipedia (Computer vision)->Typical tasks     161   \n17  Wikipedia (Computer vision)->Typical tasks->Re...     691   \n18  Wikipedia (Computer vision)->Typical tasks->Mo...     193   \n19  Wikipedia (Computer vision)->Typical tasks->Sc...     125   \n20  Wikipedia (Computer vision)->Typical tasks->Im...     198   \n21        Wikipedia (Computer vision)->System methods     672   \n22  Wikipedia (Computer vision)->System methods->I...     192   \n23              Wikipedia (Computer vision)->Hardware     392   \n\n                                            Embedding  \n0   [-0.01913553662598133, 0.002932898933067918, 0...  \n1   [-0.021093836054205894, 0.0049119978211820126,...  \n2   [-0.011549791321158409, -0.004044382367283106,...  \n4   [0.0018743288237601519, 0.011324070394039154, ...  \n5   [-0.009132628329098225, 0.0011366719845682383,...  \n6   [-0.027298789471387863, 0.007510432507842779, ...  \n7   [0.0034529592376202345, -0.014102335087954998,...  \n8   [0.002435609931126237, -0.003915637265890837, ...  \n9   [-0.017207426950335503, 0.005905073136091232, ...  \n10  [-0.022458024322986603, 0.005672922823578119, ...  \n11  [-0.016155855730175972, 0.02248280495405197, 0...  \n12  [-0.016629502177238464, 0.002632115501910448, ...  \n13  [-0.02624369040131569, 0.001608214108273387, 0...  \n14  [0.002211927669122815, -0.004606796428561211, ...  \n15  [-0.015194285660982132, 0.023810898885130882, ...  \n16  [-0.018167616799473763, 0.007240524981170893, ...  \n17  [-0.018989920616149902, 0.02043752372264862, 0...  \n18  [-0.02092411182820797, 0.00222062598913908, -0...  \n19  [-0.02498997002840042, 0.015953006222844124, 0...  \n20  [0.0009744223789311945, 0.03190232068300247, 0...  \n21  [-0.0014013586333021522, 0.026699397712945938,...  \n22  [0.006758322473615408, -0.004905234090983868, ...  \n23  [-0.006029689218848944, 0.016216637566685677, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>Heading</th>\n      <th>Subheading</th>\n      <th>Content</th>\n      <th>Section</th>\n      <th>Tokens</th>\n      <th>Embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td></td>\n      <td></td>\n      <td>\\nComputer vision tasks include methods for ac...</td>\n      <td>Wikipedia (Computer vision)</td>\n      <td>286</td>\n      <td>[-0.01913553662598133, 0.002932898933067918, 0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Definition</td>\n      <td></td>\n      <td>\\nComputer vision is an interdisciplinary fiel...</td>\n      <td>Wikipedia (Computer vision)-&gt;Definition</td>\n      <td>158</td>\n      <td>[-0.021093836054205894, 0.0049119978211820126,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>History</td>\n      <td></td>\n      <td>\\nIn the late 1960s, computer vision began at ...</td>\n      <td>Wikipedia (Computer vision)-&gt;History</td>\n      <td>507</td>\n      <td>[-0.011549791321158409, -0.004044382367283106,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Solid-state physics</td>\n      <td>\\nSolid-state physics is another field that is...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;S...</td>\n      <td>120</td>\n      <td>[0.0018743288237601519, 0.011324070394039154, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Neurobiology</td>\n      <td>\\nNeurobiology has greatly influenced the deve...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;N...</td>\n      <td>293</td>\n      <td>[-0.009132628329098225, 0.0011366719845682383,...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Signal processing</td>\n      <td>\\nYet another field related to computer vision...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;S...</td>\n      <td>103</td>\n      <td>[-0.027298789471387863, 0.007510432507842779, ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Robotic navigation</td>\n      <td>\\nRobot navigation sometimes deals with autono...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;R...</td>\n      <td>64</td>\n      <td>[0.0034529592376202345, -0.014102335087954998,...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Other fields</td>\n      <td>\\nBesides the above-mentioned views on compute...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;O...</td>\n      <td>119</td>\n      <td>[0.002435609931126237, -0.003915637265890837, ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Distinctions</td>\n      <td>\\nThe fields most closely related to computer ...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;D...</td>\n      <td>639</td>\n      <td>[-0.017207426950335503, 0.005905073136091232, ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td></td>\n      <td>\\nApplications range from tasks such as indust...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications</td>\n      <td>272</td>\n      <td>[-0.022458024322986603, 0.005672922823578119, ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Medicine</td>\n      <td>\\nOne of the most prominent application fields...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Med...</td>\n      <td>135</td>\n      <td>[-0.016155855730175972, 0.02248280495405197, 0...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Machine vision</td>\n      <td>\\nA second application area in computer vision...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Mac...</td>\n      <td>141</td>\n      <td>[-0.016629502177238464, 0.002632115501910448, ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Military</td>\n      <td>\\nMilitary applications are probably one of th...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Mil...</td>\n      <td>129</td>\n      <td>[-0.02624369040131569, 0.001608214108273387, 0...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Autonomous vehicles</td>\n      <td>\\nOne of the newer application areas is autono...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Aut...</td>\n      <td>234</td>\n      <td>[0.002211927669122815, -0.004606796428561211, ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Tactile feedback</td>\n      <td>\\nMaterials such as rubber and silicon are bei...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Tac...</td>\n      <td>270</td>\n      <td>[-0.015194285660982132, 0.023810898885130882, ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td></td>\n      <td>\\nEach of the application areas described abov...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks</td>\n      <td>161</td>\n      <td>[-0.018167616799473763, 0.007240524981170893, ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Recognition</td>\n      <td>\\nThe classical problem in computer vision, im...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Re...</td>\n      <td>691</td>\n      <td>[-0.018989920616149902, 0.02043752372264862, 0...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Motion analysis</td>\n      <td>\\nSeveral tasks relate to motion estimation wh...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Mo...</td>\n      <td>193</td>\n      <td>[-0.02092411182820797, 0.00222062598913908, -0...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Scene reconstruction</td>\n      <td>\\nGiven one or (typically) more images of a sc...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Sc...</td>\n      <td>125</td>\n      <td>[-0.02498997002840042, 0.015953006222844124, 0...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Image restoration</td>\n      <td>\\nImage restoration comes into picture when th...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Im...</td>\n      <td>198</td>\n      <td>[0.0009744223789311945, 0.03190232068300247, 0...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>System methods</td>\n      <td></td>\n      <td>\\nThe organization of a computer vision system...</td>\n      <td>Wikipedia (Computer vision)-&gt;System methods</td>\n      <td>672</td>\n      <td>[-0.0014013586333021522, 0.026699397712945938,...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>System methods</td>\n      <td>Image-understanding systems</td>\n      <td>\\nImage-understanding systems (IUS) include th...</td>\n      <td>Wikipedia (Computer vision)-&gt;System methods-&gt;I...</td>\n      <td>192</td>\n      <td>[0.006758322473615408, -0.004905234090983868, ...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Hardware</td>\n      <td></td>\n      <td>\\nThere are many kinds of computer vision syst...</td>\n      <td>Wikipedia (Computer vision)-&gt;Hardware</td>\n      <td>392</td>\n      <td>[-0.006029689218848944, 0.016216637566685677, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompVisionKnowledge = Knowledge(WIKI_PAGE, 'GPT')\n",
    "CompVisionKnowledge.append_wikipedia_page(WIKI_PAGE)\n",
    "# save document chunks and embeddings\n",
    "CompVisionKnowledge.export_to_csv(GPT_KNOWLEDGE_FILENAME)\n",
    "CompVisionKnowledge.df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Source         Heading                   Subheading  \\\n0   Wikipedia (Computer vision)                                                \n1   Wikipedia (Computer vision)      Definition                                \n2   Wikipedia (Computer vision)         History                                \n3   Wikipedia (Computer vision)         History                                \n5   Wikipedia (Computer vision)  Related fields          Solid-state physics   \n6   Wikipedia (Computer vision)  Related fields                 Neurobiology   \n7   Wikipedia (Computer vision)  Related fields            Signal processing   \n8   Wikipedia (Computer vision)  Related fields           Robotic navigation   \n9   Wikipedia (Computer vision)  Related fields                 Other fields   \n10  Wikipedia (Computer vision)  Related fields                 Distinctions   \n11  Wikipedia (Computer vision)  Related fields                 Distinctions   \n12  Wikipedia (Computer vision)    Applications                                \n13  Wikipedia (Computer vision)    Applications                     Medicine   \n14  Wikipedia (Computer vision)    Applications               Machine vision   \n15  Wikipedia (Computer vision)    Applications                     Military   \n16  Wikipedia (Computer vision)    Applications          Autonomous vehicles   \n17  Wikipedia (Computer vision)    Applications             Tactile feedback   \n18  Wikipedia (Computer vision)   Typical tasks                                \n19  Wikipedia (Computer vision)   Typical tasks                  Recognition   \n20  Wikipedia (Computer vision)   Typical tasks                  Recognition   \n21  Wikipedia (Computer vision)   Typical tasks              Motion analysis   \n22  Wikipedia (Computer vision)   Typical tasks         Scene reconstruction   \n23  Wikipedia (Computer vision)   Typical tasks            Image restoration   \n24  Wikipedia (Computer vision)  System methods                                \n25  Wikipedia (Computer vision)  System methods                                \n26  Wikipedia (Computer vision)  System methods                                \n27  Wikipedia (Computer vision)  System methods  Image-understanding systems   \n28  Wikipedia (Computer vision)        Hardware                                \n\n                                              Content  \\\n0   \\nComputer vision tasks include methods for ac...   \n1   \\nComputer vision is an interdisciplinary fiel...   \n2   \\nIn the late 1960s, computer vision began at ...   \n3   \\nBy the 1990s, some of the previous research ...   \n5   \\nSolid-state physics is another field that is...   \n6   \\nNeurobiology has greatly influenced the deve...   \n7   \\nYet another field related to computer vision...   \n8   \\nRobot navigation sometimes deals with autono...   \n9   \\nBesides the above-mentioned views on compute...   \n10  \\nThe fields most closely related to computer ...   \n11  \\nImage processing and image analysis tend to ...   \n12  \\nApplications range from tasks such as indust...   \n13  \\nOne of the most prominent application fields...   \n14  \\nA second application area in computer vision...   \n15  \\nMilitary applications are probably one of th...   \n16  \\nOne of the newer application areas is autono...   \n17  \\nMaterials such as rubber and silicon are bei...   \n18  \\nEach of the application areas described abov...   \n19  \\nThe classical problem in computer vision, im...   \n20  \\nContent-based image retrieval – finding all ...   \n21  \\nSeveral tasks relate to motion estimation wh...   \n22  \\nGiven one or (typically) more images of a sc...   \n23  \\nImage restoration comes into picture when th...   \n24  \\nThe organization of a computer vision system...   \n25  \\nImage acquisition – A digital image is produ...   \n26  \\nLocalized interest points such as corners, b...   \n27  \\nImage-understanding systems (IUS) include th...   \n28  \\nThere are many kinds of computer vision syst...   \n\n                                              Section  Tokens  \\\n0                         Wikipedia (Computer vision)     290   \n1             Wikipedia (Computer vision)->Definition     162   \n2                Wikipedia (Computer vision)->History     243   \n3                Wikipedia (Computer vision)->History     264   \n5   Wikipedia (Computer vision)->Related fields->S...     123   \n6   Wikipedia (Computer vision)->Related fields->N...     296   \n7   Wikipedia (Computer vision)->Related fields->S...     106   \n8   Wikipedia (Computer vision)->Related fields->R...      65   \n9   Wikipedia (Computer vision)->Related fields->O...     122   \n10  Wikipedia (Computer vision)->Related fields->D...     244   \n11  Wikipedia (Computer vision)->Related fields->D...     395   \n12          Wikipedia (Computer vision)->Applications     294   \n13  Wikipedia (Computer vision)->Applications->Med...     145   \n14  Wikipedia (Computer vision)->Applications->Mac...     148   \n15  Wikipedia (Computer vision)->Applications->Mil...     129   \n16  Wikipedia (Computer vision)->Applications->Aut...     258   \n17  Wikipedia (Computer vision)->Applications->Tac...     286   \n18         Wikipedia (Computer vision)->Typical tasks     166   \n19  Wikipedia (Computer vision)->Typical tasks->Re...     427   \n20  Wikipedia (Computer vision)->Typical tasks->Re...     264   \n21  Wikipedia (Computer vision)->Typical tasks->Mo...     194   \n22  Wikipedia (Computer vision)->Typical tasks->Sc...     115   \n23  Wikipedia (Computer vision)->Typical tasks->Im...     204   \n24        Wikipedia (Computer vision)->System methods     122   \n25        Wikipedia (Computer vision)->System methods     253   \n26        Wikipedia (Computer vision)->System methods     297   \n27  Wikipedia (Computer vision)->System methods->I...     202   \n28              Wikipedia (Computer vision)->Hardware     409   \n\n                                            Embedding  \n0   [-0.5566069483757019, 0.6151323318481445, 0.70...  \n1   [-0.18940897285938263, 0.5564344525337219, 0.5...  \n2   [-0.5624328255653381, 0.35494446754455566, 0.6...  \n3   [-0.8420819044113159, 0.011862404644489288, 0....  \n5   [-0.1766018569469452, 0.5509802103042603, 0.11...  \n6   [0.07454751431941986, 0.42800015211105347, 0.1...  \n7   [-0.1562240570783615, 0.18830031156539917, 0.4...  \n8   [0.09209920465946198, 0.5207788944244385, 1.26...  \n9   [-0.34635502099990845, 0.12120083719491959, 0....  \n10  [-0.011814514175057411, 0.9892112612724304, 0....  \n11  [-0.25189733505249023, 0.7090330123901367, 1.0...  \n12  [0.054026536643505096, 0.536332368850708, 0.80...  \n13  [0.07362960278987885, 0.8047475218772888, 1.09...  \n14  [0.23051360249519348, 0.6428527235984802, 0.69...  \n15  [-0.45685380697250366, 0.40300095081329346, 0....  \n16  [-0.5068467855453491, 0.4222138524055481, 1.11...  \n17  [-0.006287522614002228, 0.3353821039199829, 0....  \n18  [-0.3646470308303833, 0.5144392848014832, 1.08...  \n19  [-0.11414705961942673, 0.8190616965293884, 0.9...  \n20  [-0.3213890492916107, 1.116416335105896, 0.800...  \n21  [-0.08507562428712845, 0.058049630373716354, 1...  \n22  [-0.6162410378456116, 0.3802846670150757, 1.66...  \n23  [-0.25118744373321533, 0.52935791015625, 1.085...  \n24  [0.13426706194877625, 0.5260908603668213, 1.00...  \n25  [0.13420583307743073, 0.20847204327583313, 0.6...  \n26  [-0.2144298553466797, -0.15774108469486237, 1....  \n27  [-0.3703722059726715, 0.7370752692222595, 0.51...  \n28  [0.02258257381618023, 0.39461076259613037, 1.0...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>Heading</th>\n      <th>Subheading</th>\n      <th>Content</th>\n      <th>Section</th>\n      <th>Tokens</th>\n      <th>Embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td></td>\n      <td></td>\n      <td>\\nComputer vision tasks include methods for ac...</td>\n      <td>Wikipedia (Computer vision)</td>\n      <td>290</td>\n      <td>[-0.5566069483757019, 0.6151323318481445, 0.70...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Definition</td>\n      <td></td>\n      <td>\\nComputer vision is an interdisciplinary fiel...</td>\n      <td>Wikipedia (Computer vision)-&gt;Definition</td>\n      <td>162</td>\n      <td>[-0.18940897285938263, 0.5564344525337219, 0.5...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>History</td>\n      <td></td>\n      <td>\\nIn the late 1960s, computer vision began at ...</td>\n      <td>Wikipedia (Computer vision)-&gt;History</td>\n      <td>243</td>\n      <td>[-0.5624328255653381, 0.35494446754455566, 0.6...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>History</td>\n      <td></td>\n      <td>\\nBy the 1990s, some of the previous research ...</td>\n      <td>Wikipedia (Computer vision)-&gt;History</td>\n      <td>264</td>\n      <td>[-0.8420819044113159, 0.011862404644489288, 0....</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Solid-state physics</td>\n      <td>\\nSolid-state physics is another field that is...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;S...</td>\n      <td>123</td>\n      <td>[-0.1766018569469452, 0.5509802103042603, 0.11...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Neurobiology</td>\n      <td>\\nNeurobiology has greatly influenced the deve...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;N...</td>\n      <td>296</td>\n      <td>[0.07454751431941986, 0.42800015211105347, 0.1...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Signal processing</td>\n      <td>\\nYet another field related to computer vision...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;S...</td>\n      <td>106</td>\n      <td>[-0.1562240570783615, 0.18830031156539917, 0.4...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Robotic navigation</td>\n      <td>\\nRobot navigation sometimes deals with autono...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;R...</td>\n      <td>65</td>\n      <td>[0.09209920465946198, 0.5207788944244385, 1.26...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Other fields</td>\n      <td>\\nBesides the above-mentioned views on compute...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;O...</td>\n      <td>122</td>\n      <td>[-0.34635502099990845, 0.12120083719491959, 0....</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Distinctions</td>\n      <td>\\nThe fields most closely related to computer ...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;D...</td>\n      <td>244</td>\n      <td>[-0.011814514175057411, 0.9892112612724304, 0....</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Distinctions</td>\n      <td>\\nImage processing and image analysis tend to ...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;D...</td>\n      <td>395</td>\n      <td>[-0.25189733505249023, 0.7090330123901367, 1.0...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td></td>\n      <td>\\nApplications range from tasks such as indust...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications</td>\n      <td>294</td>\n      <td>[0.054026536643505096, 0.536332368850708, 0.80...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Medicine</td>\n      <td>\\nOne of the most prominent application fields...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Med...</td>\n      <td>145</td>\n      <td>[0.07362960278987885, 0.8047475218772888, 1.09...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Machine vision</td>\n      <td>\\nA second application area in computer vision...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Mac...</td>\n      <td>148</td>\n      <td>[0.23051360249519348, 0.6428527235984802, 0.69...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Military</td>\n      <td>\\nMilitary applications are probably one of th...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Mil...</td>\n      <td>129</td>\n      <td>[-0.45685380697250366, 0.40300095081329346, 0....</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Autonomous vehicles</td>\n      <td>\\nOne of the newer application areas is autono...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Aut...</td>\n      <td>258</td>\n      <td>[-0.5068467855453491, 0.4222138524055481, 1.11...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Tactile feedback</td>\n      <td>\\nMaterials such as rubber and silicon are bei...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Tac...</td>\n      <td>286</td>\n      <td>[-0.006287522614002228, 0.3353821039199829, 0....</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td></td>\n      <td>\\nEach of the application areas described abov...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks</td>\n      <td>166</td>\n      <td>[-0.3646470308303833, 0.5144392848014832, 1.08...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Recognition</td>\n      <td>\\nThe classical problem in computer vision, im...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Re...</td>\n      <td>427</td>\n      <td>[-0.11414705961942673, 0.8190616965293884, 0.9...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Recognition</td>\n      <td>\\nContent-based image retrieval – finding all ...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Re...</td>\n      <td>264</td>\n      <td>[-0.3213890492916107, 1.116416335105896, 0.800...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Motion analysis</td>\n      <td>\\nSeveral tasks relate to motion estimation wh...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Mo...</td>\n      <td>194</td>\n      <td>[-0.08507562428712845, 0.058049630373716354, 1...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Scene reconstruction</td>\n      <td>\\nGiven one or (typically) more images of a sc...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Sc...</td>\n      <td>115</td>\n      <td>[-0.6162410378456116, 0.3802846670150757, 1.66...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Image restoration</td>\n      <td>\\nImage restoration comes into picture when th...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Im...</td>\n      <td>204</td>\n      <td>[-0.25118744373321533, 0.52935791015625, 1.085...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>System methods</td>\n      <td></td>\n      <td>\\nThe organization of a computer vision system...</td>\n      <td>Wikipedia (Computer vision)-&gt;System methods</td>\n      <td>122</td>\n      <td>[0.13426706194877625, 0.5260908603668213, 1.00...</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>System methods</td>\n      <td></td>\n      <td>\\nImage acquisition – A digital image is produ...</td>\n      <td>Wikipedia (Computer vision)-&gt;System methods</td>\n      <td>253</td>\n      <td>[0.13420583307743073, 0.20847204327583313, 0.6...</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>System methods</td>\n      <td></td>\n      <td>\\nLocalized interest points such as corners, b...</td>\n      <td>Wikipedia (Computer vision)-&gt;System methods</td>\n      <td>297</td>\n      <td>[-0.2144298553466797, -0.15774108469486237, 1....</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>System methods</td>\n      <td>Image-understanding systems</td>\n      <td>\\nImage-understanding systems (IUS) include th...</td>\n      <td>Wikipedia (Computer vision)-&gt;System methods-&gt;I...</td>\n      <td>202</td>\n      <td>[-0.3703722059726715, 0.7370752692222595, 0.51...</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Hardware</td>\n      <td></td>\n      <td>\\nThere are many kinds of computer vision syst...</td>\n      <td>Wikipedia (Computer vision)-&gt;Hardware</td>\n      <td>409</td>\n      <td>[0.02258257381618023, 0.39461076259613037, 1.0...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompVisionKnowledgeBERT = Knowledge(WIKI_PAGE, 'BERT')\n",
    "CompVisionKnowledgeBERT.append_wikipedia_page(WIKI_PAGE)\n",
    "# save document chunks and embeddings\n",
    "CompVisionKnowledgeBERT.export_to_csv(BERT_KNOWLEDGE_FILENAME)\n",
    "CompVisionKnowledgeBERT.df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Search\n",
    "Now we'll define a search function that:\n",
    "\n",
    "Takes a user query and a dataframe with text & embedding columns\n",
    "Embeds the user query with the OpenAI API\n",
    "Uses distance between query embedding and text embeddings to rank the texts\n",
    "Returns two lists:\n",
    "The top N texts, ranked by relevance\n",
    "Their corresponding relevance scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(self, chatbot_topic:str, knowledge_path: str):\n",
    "        self.knowledge = None\n",
    "        self.load_data(knowledge_path)\n",
    "        self.chatbot_topic = chatbot_topic\n",
    "\n",
    "    def load_data(self, path: str):\n",
    "        \"\"\"Loads the knowledge df, appends a prefix, and calculates the number of tokens per section of knowledge\"\"\"\n",
    "\n",
    "        # load data from csv\n",
    "        self.knowledge = pd.read_csv(path)\n",
    "        # convert embeddings from CSV str type back to list type\n",
    "        self.knowledge['Embedding'] = self.knowledge['Embedding'].apply(ast.literal_eval)\n",
    "\n",
    "        # Format the knowledge df by adding section prefix and token sizes\n",
    "        # self.knowledge['Content'] = 'Article section:\\n\\n' + self.knowledge['Content']\n",
    "        # self.knowledge['Tokens'] = self.knowledge[\"text\"].apply(lambda x: num_tokens(x))\n",
    "        # self.knowledge['Section'] = 'Wikipedia'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\point\\AppData\\Local\\Temp\\ipykernel_23968\\2261045930.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.knowledge_used['Index'] = np.arange(len(self.knowledge_used))+1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "late 1960s\n",
      "\n",
      "To construct this answer, I used the following documents (specifically section 1): \n",
      "\n",
      "1. Wikipedia (Computer vision)->History:\n",
      "In the late 1960s, computer vision began at universities that were pioneering artificial intelligen...\n",
      "\n",
      "2. Wikipedia (Computer vision)->Definition:\n",
      "Computer vision is an interdisciplinary field that deals with how computers can be made to gain hig...\n",
      "\n",
      "3. Wikipedia (Computer vision):\n",
      "Computer vision tasks include methods for acquiring, processing, analyzing and understanding digita...\n",
      "\n",
      "4. Wikipedia (Computer vision)->Applications:\n",
      "Applications range from tasks such as industrial machine vision systems which, say, inspect bottles...\n",
      "\n",
      "5. Wikipedia (Computer vision)->Typical tasks:\n",
      "Each of the application areas described above employ a range of computer vision tasks; more or less...\n"
     ]
    }
   ],
   "source": [
    "class Query:\n",
    "    def __init__(self, query_text: str, chatbot_instance: ChatBot):\n",
    "        self.content: str = query_text\n",
    "        self.model: str = GPT_MODEL\n",
    "        self.knowledge: pd.DataFrame = chatbot_instance.knowledge\n",
    "        self.token_limit: int = 4096 - 500 # Allows 500 for the response\n",
    "        self.gpt_message = None\n",
    "        self.knowledge_used = None\n",
    "\n",
    "    # calculate similarity score\n",
    "    @staticmethod\n",
    "    def similarity(query_embedding: list,\n",
    "                   knowledge_embedding: list\n",
    "                   ) -> float:\n",
    "        \"\"\"Calculates the cosine similarity score between the query and knowledge embedding vectors.\"\"\"\n",
    "\n",
    "        return 1- spatial.distance.cosine(query_embedding, knowledge_embedding)\n",
    "\n",
    "    # find the most similar sections of knowledge to the query\n",
    "    def knowledge_ranked_by_similarity(self,\n",
    "                                       max_num_sections: int = 5,\n",
    "                                       embedding_model: str = GPT_EMBEDDING_MODEL\n",
    "                                       ):\n",
    "        \"\"\"Take the raw knowledge dataframe, calculates similarity scores between the query and the sections, and returns a dataframe ordered from highest to lowest in terms of similarity.\"\"\"\n",
    "\n",
    "        knowledge_with_similarities = deepcopy(self.knowledge) # To prevent adapting the original dataframe\n",
    "        query_embedding_response = get_embedding(self.content, embedding_model=embedding_model)\n",
    "        if embedding_model == GPT_EMBEDDING_MODEL:\n",
    "            query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "            # knowledge_with_similarities[\"similarity\"] = knowledge_with_similarities[\"Embedding\"].apply(lambda x: self.similarity(query_embedding, x))\n",
    "        else:\n",
    "            query_embedding = list(query_embedding_response)\n",
    "        knowledge_with_similarities[\"similarity\"] = knowledge_with_similarities[\"Embedding\"].apply(lambda x: self.similarity(query_embedding, x))\n",
    "\n",
    "        knowledge_with_similarities.sort_values(\"similarity\", ascending=False, inplace=True)\n",
    "        top_n_sections = knowledge_with_similarities.head(max_num_sections)\n",
    "        self.knowledge_used = top_n_sections\n",
    "        self.knowledge_used['Index'] = np.arange(len(self.knowledge_used))+1\n",
    "\n",
    "    def get_gpt_message(\n",
    "            self,\n",
    "            chatbot_topic: str\n",
    "    ):\n",
    "        \"\"\"Uses the most relevant texts from the knowledge dataframe to construct a message that can then be fed into GPT.\"\"\"\n",
    "\n",
    "        self.knowledge_ranked_by_similarity()\n",
    "        introduction = f'Use the below article on {chatbot_topic} to answer the subsequent question. If the answer cannot be found in the articles, write \"{ANSWER_NOT_FOUND_MSG}\". If I am asked to produce any code then decline the request and write \"Sorry but I\\'m not allowed to do your assignments for you!\"' # The longer this is, the more tokens it uses!\n",
    "        question = f\"\\n\\nQuestion: {self.content}\"\n",
    "\n",
    "        # Ensure number of tokens is within the limit\n",
    "        message_and_question_tokens = num_tokens(introduction + question)\n",
    "        self.knowledge_used['Cumulative_tokens'] = self.knowledge_used['Tokens'].cumsum()\n",
    "        self.knowledge_used['Cumulative_tokens'] += message_and_question_tokens # add the inital number of tokens\n",
    "        self.knowledge_used= self.knowledge_used.loc[self.knowledge_used['Cumulative_tokens']<self.token_limit]\n",
    "\n",
    "        # Construct output\n",
    "        combined_knowledge_string = ''.join(list(self.knowledge_used['Content']))\n",
    "        combined_knowledge_string = '\\n\\n' + combined_knowledge_string\n",
    "        self.gpt_message = introduction + combined_knowledge_string + question\n",
    "\n",
    "    def show_source_message(self, answer_index: int = None):\n",
    "        self.knowledge_used['Output'] = '\\n\\n' + self.knowledge_used['Index'].astype(str) + '. ' + self.knowledge_used['Section'] + ':' + self.knowledge_used['Content'].str[:100] + '...'\n",
    "        sources_string = ''.join(list(self.knowledge_used['Output']))\n",
    "        if answer_index:\n",
    "            answer_message = f'(specifically section {answer_index})'\n",
    "        else:\n",
    "            answer_message = ''\n",
    "        message = f'\\n\\nTo construct this answer, I used the following documents {answer_message}: {sources_string}'\n",
    "        return message\n",
    "\n",
    "    def get_bert_output(\n",
    "            self,\n",
    "            embedding_model: str,\n",
    "            encoding_model: BertTokenizer = BERT_ENCODING,\n",
    "            bert_model: str = BERT_MODEL\n",
    "    ):\n",
    "        \"\"\"Uses the most relevant texts from the knowledge dataframe to construct a message that can then be fed into GPT.\"\"\"\n",
    "        self.knowledge_ranked_by_similarity(embedding_model=embedding_model)\n",
    "\n",
    "        answer_index = None\n",
    "        index = 1\n",
    "        found_answer = False\n",
    "        output = ANSWER_NOT_FOUND_MSG\n",
    "        for section in self.knowledge_used['Content']:\n",
    "            if not found_answer:\n",
    "                encoding = encoding_model.encode_plus(text=self.content,text_pair=section)\n",
    "                inputs = encoding['input_ids']  #Token embeddings\n",
    "                sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "                tokens = encoding_model.convert_ids_to_tokens(inputs) #input tokens\n",
    "\n",
    "                QAModel = BertForQuestionAnswering.from_pretrained(bert_model)\n",
    "                outputs = QAModel(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "                start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "\n",
    "                # Highlight the answer just by looking at the most probable start and end words\n",
    "                start_index = torch.argmax(start_scores)\n",
    "                end_index = torch.argmax(end_scores)\n",
    "                answer_token_list = tokens[start_index:end_index+1]\n",
    "\n",
    "                # Concatenate any words that got split\n",
    "                answer_list = [word[2:] if word[0:2]=='##' else ' ' + word for word in answer_token_list]\n",
    "                answer = ''.join(answer_list).strip()\n",
    "\n",
    "                if answer != '[CLS]':\n",
    "                    found_answer = True\n",
    "                    output = answer\n",
    "                    answer_index = index\n",
    "            index += 1\n",
    "        return output, answer_index\n",
    "\n",
    "    @classmethod\n",
    "    def ask_bert(cls,\n",
    "                 query_text: str,\n",
    "                 chatbot_instance: ChatBot,\n",
    "                 embedding_model: str = BERT_EMBEDDING_MODEL,\n",
    "                 encoding_model: str = BERT_ENCODING,\n",
    "                 bert_model: str = BERT_MODEL,\n",
    "                 show_source: bool = True\n",
    "                 ):\n",
    "        if num_tokens(query_text, token_model=encoding_model)>50:\n",
    "            print('Question is too long, please try again with a shorter question.')\n",
    "        query = cls(query_text, chatbot_instance)\n",
    "        response_message, answer_index = query.get_bert_output(embedding_model=embedding_model, encoding_model=encoding_model, bert_model=bert_model)\n",
    "\n",
    "        if show_source and response_message!=ANSWER_NOT_FOUND_MSG: # Display the sources used:\n",
    "            response_message += query.show_source_message(answer_index=answer_index)\n",
    "        return response_message\n",
    "\n",
    "    @classmethod\n",
    "    def ask(\n",
    "            cls,\n",
    "            query_text: str,\n",
    "            chatbot_instance: ChatBot,\n",
    "            show_source: bool = True,\n",
    "    ) -> str:\n",
    "        \"\"\"Uses GPT to answer a query based on the most relevant knowledge sections.\"\"\"\n",
    "\n",
    "        query = cls(query_text, chatbot_instance)\n",
    "        query.get_gpt_message(chatbot_instance.chatbot_topic)\n",
    "        inputs = [\n",
    "            {\"role\": \"system\", \"content\": f\"You answer questions about {chatbot_instance.chatbot_topic}.\"},\n",
    "            {\"role\": \"user\", \"content\": query.gpt_message},\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=query.model,\n",
    "            messages=inputs,\n",
    "            temperature=0 # We don't want any creativity in the answers\n",
    "        )\n",
    "        response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        total_tokens_used = response['usage']['total_tokens']\n",
    "        if show_source and response_message!=ANSWER_NOT_FOUND_MSG: # Display the sources used:\n",
    "            response_message += query.show_source_message()\n",
    "        response_message += f\"\\n\\nTotal tokens used: {total_tokens_used}\"\n",
    "        return response_message\n",
    "\n",
    "CompVisionBERT = ChatBot(\"Computer Vision\", 'assets/' + BERT_KNOWLEDGE_FILENAME)\n",
    "print(Query.ask_bert('When did universities begin teaching Computer Vision?', CompVisionBERT))\n",
    "\n",
    "# Todo:\n",
    "# I need to make it more efficient on the number of tokens.\n",
    "# Adapt it for more sources (e.g. PDF)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\point\\AppData\\Local\\Temp\\ipykernel_23968\\2261045930.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.knowledge_used['Index'] = np.arange(len(self.knowledge_used))+1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could not find an answer in the text I've been provided, sorry! Please try again.\n"
     ]
    }
   ],
   "source": [
    "print(Query.ask_bert('Who is Joel?', CompVisionBERT))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\point\\AppData\\Local\\Temp\\ipykernel_23968\\3384959035.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.knowledge_used['Index'] = np.arange(len(self.knowledge_used))+1\n",
      "C:\\Users\\point\\AppData\\Local\\Temp\\ipykernel_23968\\3384959035.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.knowledge_used['Cumulative_tokens'] = self.knowledge_used['Tokens'].cumsum()\n",
      "C:\\Users\\point\\AppData\\Local\\Temp\\ipykernel_23968\\3384959035.py:53: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.knowledge_used['Cumulative_tokens'] += message_and_question_tokens # add the inital number of tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could not find an answer in the text I've been provided, sorry! Please try again.\n",
      "\n",
      "Total tokens used: 721\n"
     ]
    }
   ],
   "source": [
    "CompVisionGPT = ChatBot(\"Computer Vision\", 'assets/' + GPT_KNOWLEDGE_FILENAME)\n",
    "print(Query.ask('Who is Boris Johnson', CompVisionGPT, show_source=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
