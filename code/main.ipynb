{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# GPT-3.5-Turbo Model\n",
    "Creating a question answering chatbot using GPT-3.5. Adapted from: https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Preamble\n",
    "import PyPDF2 # For parsing PDF documents\n",
    "import ast  # covert embeddings saved as strings back to arrays\n",
    "import openai  # OpenAI API\n",
    "import pandas as pd  # for storing text and embeddings data\n",
    "import numpy as np # for df manipulations\n",
    "import tiktoken  # for counting tokens\n",
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "import wikipedia # For sourcing Wikipedia article text\n",
    "import re  # for cutting <ref> links out of Wikipedia articles\n",
    "import mwparserfromhell  # for splitting Wikipedia articles into sections\n",
    "from copy import deepcopy # for copying dataframes\n",
    "import torch # for BERT's argmax and tensors\n",
    "from transformers import BertForQuestionAnswering # Not used\n",
    "from transformers import BertTokenizer # For BERT's tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "outputs": [],
   "source": [
    "# Config\n",
    "GPT_EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
    "BERT_EMBEDDING_MODEL = 'bert-base-nli-mean-tokens'\n",
    "GPT_MODEL = \"gpt-3.5-turbo\"\n",
    "BERT_MODEL = \"deepset/bert-base-cased-squad2\"\n",
    "GPT_KNOWLEDGE_FILENAME = \"CompVisionGPT.csv\"\n",
    "BERT_KNOWLEDGE_FILENAME = \"CompVisionBERT.csv\"\n",
    "bert_model = BertForQuestionAnswering.from_pretrained(BERT_MODEL)\n",
    "BERT_ENCODING = BertTokenizer.from_pretrained(BERT_MODEL)\n",
    "GPT_ENCODING = tiktoken.encoding_for_model(GPT_MODEL)\n",
    "BATCH_SIZE = 1000  # you can submit up to 2048 embedding inputs per request\n",
    "GPT_MAX_TOKENS = 1600 # max number of tokens per section\n",
    "BERT_MAX_TOKENS = 510 # max tokens per section\n",
    "MIN_LENGTH = 50 # min character length for each section\n",
    "ANSWER_NOT_FOUND_MSG = \"I could not find an answer in the text I\\'ve been provided, sorry! Please try again.\"\n",
    "WIKI_PAGE = \"Computer vision\"\n",
    "SECTIONS_TO_IGNORE = [\n",
    "    \"See also\",\n",
    "    \"References\",\n",
    "    \"External links\",\n",
    "    \"Further reading\",\n",
    "    \"Footnotes\",\n",
    "    \"Bibliography\",\n",
    "    \"Sources\",\n",
    "    \"Citations\",\n",
    "    \"Literature\",\n",
    "    \"Footnotes\",\n",
    "    \"Notes and references\",\n",
    "    \"Photo gallery\",\n",
    "    \"Works cited\",\n",
    "    \"Photos\",\n",
    "    \"Gallery\",\n",
    "    \"Notes\",\n",
    "    \"References and sources\",\n",
    "    \"References and notes\",\n",
    "]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "2.Veryfewvisual taskscanbesuccessfully performed inapurely data-driv en\n",
      "way(\\bottom-up\" image analysis). Consider thenextimage example:\n",
      "aged bytheirtextured backgrounds; thefoxes\n",
      "occlude eachother; theyappearinseveraldi\u000Beren tposesandperspective\n",
      "angles; etc.Howcanthere possibly existmathematical operators forsuch\n",
      "animage thatcan:\n",
      "\u000Fperform the\fgure-ground segmen tation ofthescene (intoitsobjects\n",
      "andbackground)\n",
      "\u000Finferthe3Darrangemen tsofobjectsfromtheirmutual occlusions\n",
      "\u000Finfersurface properties (texture, colour) fromthe2Dimage statistics\n",
      "\u000Finfervolumetric objectproperties fromtheir2Dimage projections\n",
      "\u000Fanddoallofthisin\\real time?\" (This matters quite alotinthe\n",
      "natural world\\redintoothandclaw,\"sincesurviv aldependsonit.)\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# creating a pdf reader instance\n",
    "reader = PyPDF2.PdfReader('assets/online_notes.pdf')\n",
    "\n",
    "# print the number of pages in pdf file\n",
    "print(len(reader.pages))\n",
    "\n",
    "# print the text of the first page\n",
    "print(reader.pages[5].extract_text())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [],
   "source": [
    "# Used throughout\n",
    "def num_tokens(\n",
    "        text: str,\n",
    "        token_model = GPT_ENCODING\n",
    ") -> int:\n",
    "    \"\"\"Returns the number of tokens in a string.\"\"\"\n",
    "    if token_model == GPT_ENCODING:\n",
    "        return len(token_model.encode(text))\n",
    "    elif token_model == BERT_ENCODING:\n",
    "        return len(token_model.tokenize(text))\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "def get_embedding(content: list or str, embedding_model: str = GPT_EMBEDDING_MODEL):\n",
    "    if embedding_model == GPT_EMBEDDING_MODEL:\n",
    "        return openai.Embedding.create(input=content, model=embedding_model)\n",
    "    else:\n",
    "        similarity_model = SentenceTransformer(embedding_model)\n",
    "        return similarity_model.encode(content)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Knowledge:\n",
    "    def __init__(self, topic, model):\n",
    "        self.topic: str = topic\n",
    "        self.model: str = model\n",
    "        self.token_model = self.get_token_model()\n",
    "        self.embedding_model: str = self.get_embedding_model()\n",
    "        self.df: pd.DataFrame = self.get_blank_knowledge_df() # need to add code to remove small sections (<16 chars?)\n",
    "        self.max_tokens: int = self.get_max_tokens() # max number of tokens per section\n",
    "        self.min_section_length = MIN_LENGTH # min character length for each section\n",
    "\n",
    "    def get_token_model(self):\n",
    "        return GPT_ENCODING if self.model=='GPT' else BERT_ENCODING\n",
    "\n",
    "    def get_max_tokens(self):\n",
    "        return GPT_MAX_TOKENS if self.model=='GPT' else BERT_MAX_TOKENS\n",
    "\n",
    "    def get_embedding_model(self):\n",
    "        return GPT_EMBEDDING_MODEL if self.model=='GPT' else BERT_EMBEDDING_MODEL\n",
    "\n",
    "    def get_blank_knowledge_df(self) -> pd.DataFrame:\n",
    "        return pd.DataFrame(columns=['Source', 'Heading', 'Subheading', 'Content'])\n",
    "\n",
    "    def extract_wiki_sections(self,\n",
    "                              page_name: str,\n",
    "                              content: mwparserfromhell.wikicode.Wikicode,\n",
    "                              sections_to_ignore: list = SECTIONS_TO_IGNORE\n",
    "                              ) -> pd.DataFrame:\n",
    "        \"\"\"Creates a df of sections by extracting section content from a Wikicode\"\"\"\n",
    "\n",
    "        knowledge = self.get_blank_knowledge_df()\n",
    "        for section in content.get_sections(levels=[2]):\n",
    "            section_headings = section.filter_headings()\n",
    "            section_header = str(section_headings[0])\n",
    "            if len(section_headings)==1:# therefore a section title, not a subsection\n",
    "                section = section.strip(section_header)\n",
    "                if section_header.strip(\"=\" + \" \") not in sections_to_ignore: # append to df\n",
    "                    new_row = {'Source': f'Wikipedia ({page_name})', 'Heading': section_header.strip(\"=\" + \" \"), 'Content': section}\n",
    "                    knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "            elif len(section_headings)>1 and section_header.strip(\"=\" + \" \") not in sections_to_ignore: # therefore subsections\n",
    "                # Append the text before the first subsection\n",
    "                initial_text = section.split(str(section_headings[1]))[0]\n",
    "                initial_text = initial_text.strip(section_header)\n",
    "                new_row = {'Source': f'Wikipedia ({page_name})', 'Heading': section_header.strip(\"=\" + \" \"), 'Content': initial_text}\n",
    "                knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "                for subsection in section.get_sections(levels=[3]):\n",
    "                    subsection_sections = subsection.get_sections(levels=[3])[0]\n",
    "                    subsection_headings = subsection_sections.filter_headings()\n",
    "                    subsection_header = str(subsection_headings[0])\n",
    "                    subsection = subsection.strip(subsection_header)\n",
    "                    if subsection_header.strip(\"=\" + \" \") not in sections_to_ignore: # append to df\n",
    "                        new_row = {'Source': f'Wikipedia ({page_name})', 'Heading': section_header.strip(\"=\" + \" \"), 'Subheading': subsection_header.strip(\"=\" + \" \"), 'Content': subsection}\n",
    "                        knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "        return knowledge\n",
    "\n",
    "    def generate_source_column(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Creates a new column in the df which contains a summary of the source location\"\"\"\n",
    "\n",
    "        df.fillna('', inplace=True)\n",
    "        df['Section'] = df['Source'] + '->' + df['Heading'] + '->' + df['Subheading']\n",
    "        df['Section'] = df['Section'].str.replace('->->', '')\n",
    "        df['Section'] = df['Section'].str.rstrip('_->')\n",
    "        return df\n",
    "\n",
    "    def clean_section_contents(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Returns a cleaned up section with <ref>xyz</ref> patterns and leading/trailing whitespace removed\"\"\"\n",
    "\n",
    "        # text = re.sub(r\"<ref.*?</ref>\", \"\", text)\n",
    "        df['Content'] = df['Content'].str.replace(r\"<ref.*?</ref>\", \"\", regex=True)\n",
    "        df['Content'] = df['Content'].str.strip() # removes whitespace\n",
    "        df['Content'] = '\\n' + df['Content'] # need to add the \\n back to the start of each title\n",
    "        return df\n",
    "\n",
    "    def merge_elements_of_list(self, list_of_strings: list, delimiter: str = \"\\n\"):\n",
    "        potential_for_more_merging = False\n",
    "        merged_list = []\n",
    "        skip_item = False\n",
    "        for i in range(len(list_of_strings)):\n",
    "            if not skip_item:\n",
    "                if i == len(list_of_strings)-1:\n",
    "                    merged_list.append(list_of_strings[i])\n",
    "                else:\n",
    "                    merged_strings = list_of_strings[i] + delimiter + list_of_strings[i+1]\n",
    "                    if num_tokens(merged_strings)<self.max_tokens:\n",
    "                        merged_list.append(merged_strings)\n",
    "                        skip_item = True # make it skip the element we just merged\n",
    "                        potential_for_more_merging = True\n",
    "                    else:\n",
    "                        merged_list.append(list_of_strings[i])\n",
    "            else:\n",
    "                skip_item = False # set the default back to False unless otherwise specified\n",
    "        return merged_list, potential_for_more_merging\n",
    "\n",
    "    def force_split_string(self,\n",
    "                           string: str,\n",
    "                           encoding = GPT_ENCODING) -> list:\n",
    "        \"\"\"Force a section to be split into 2 (to be used if it has no delimiter)\"\"\"\n",
    "\n",
    "        list_of_strings = []\n",
    "        if num_tokens(string) <= self.max_tokens:\n",
    "            return [string]\n",
    "        else:\n",
    "            needs_truncating = True\n",
    "            while needs_truncating:\n",
    "                encoded_string = encoding.encode(string)\n",
    "                truncated_string = encoding.decode(encoded_string[:self.max_tokens])\n",
    "                remainder_of_string = encoding.decode(encoded_string[self.max_tokens:])\n",
    "                list_of_strings.append(truncated_string)\n",
    "                string = remainder_of_string\n",
    "                if num_tokens(remainder_of_string)<self.max_tokens:\n",
    "                    needs_truncating=False\n",
    "                    list_of_strings.append(remainder_of_string)\n",
    "        return list_of_strings\n",
    "\n",
    "    def split_long_sections(self, df: pd.DataFrame, delimiter: str = '\\n'):\n",
    "        \"\"\"Splits long sections of text into smaller ones\"\"\"\n",
    "\n",
    "        new_dict_of_shorter_sections = self.get_blank_knowledge_df().to_dict('records')\n",
    "        df_as_dict = df.to_dict('records')\n",
    "        for section in df_as_dict:\n",
    "            # for delimiter in delimiters:\n",
    "            if section['Tokens']<=self.max_tokens:\n",
    "                new_dict_of_shorter_sections.append(section)\n",
    "            else:\n",
    "                # needs to be split up\n",
    "                if delimiter == '': # meaning that we just need to truncate it.\n",
    "                    text = self.force_split_string(section['Content'])\n",
    "                else:\n",
    "                    text = section['Content'].split(delimiter)\n",
    "                    if delimiter == '. ':\n",
    "                        for i in range(len(text)-1):\n",
    "                            text[i] += delimiter\n",
    "                potential_for_more_merging = True\n",
    "                i = 0\n",
    "                while potential_for_more_merging:\n",
    "                    if i>20:\n",
    "                        break\n",
    "                    else:\n",
    "                        text, potential_for_more_merging = self.merge_elements_of_list(text)\n",
    "\n",
    "                # The sections should be merged into acceptable sizes:\n",
    "                if len(text)>1:\n",
    "                    for string in text:\n",
    "                        item_to_append = {'Source': section['Source'], 'Heading': section['Heading'], 'Subheading': section['Subheading'], 'Content': string, 'Section': section['Section'], 'Tokens': num_tokens(string)}\n",
    "\n",
    "                        new_dict_of_shorter_sections.append(item_to_append)\n",
    "                else:\n",
    "                    item_to_append = {'Source': section['Source'], 'Heading': section['Heading'], 'Subheading': section['Subheading'], 'Content': text[0], 'Section': section['Section'], 'Tokens': num_tokens(text[0])}\n",
    "                    new_dict_of_shorter_sections.append(item_to_append) # we shouldn't have this because the text should be more than the acceptable number of tokens\n",
    "        return pd.DataFrame(new_dict_of_shorter_sections)\n",
    "\n",
    "    def append_wikipedia_page(self, page_name: str,\n",
    "                              sections_to_ignore: list = SECTIONS_TO_IGNORE):\n",
    "        \"\"\"Takes a wikipedia page and appends the sections to the knowledge df\"\"\"\n",
    "\n",
    "        site = wikipedia.page(page_name, auto_suggest=False)\n",
    "        text = site.content\n",
    "        parsed_text = mwparserfromhell.parse(text)\n",
    "\n",
    "        # Creating initial df and appending the introduction paragraph (the text up to the first heading)\n",
    "        intro = str(parsed_text).split(str(parsed_text.filter_headings()[0]))[0]\n",
    "        knowledge = self.get_blank_knowledge_df()\n",
    "        new_row = {'Source': f'Wikipedia ({page_name})', 'Content': '\\n'+intro}\n",
    "        knowledge = pd.concat([knowledge, pd.DataFrame.from_records([new_row])])\n",
    "\n",
    "        section_content = self.extract_wiki_sections(page_name=page_name, content=parsed_text, sections_to_ignore=sections_to_ignore)\n",
    "        knowledge = pd.concat([knowledge, section_content])\n",
    "\n",
    "        # Generate succinct heading information\n",
    "        knowledge = self.generate_source_column(knowledge)\n",
    "        self.df = pd.concat([self.df, knowledge])\n",
    "\n",
    "        # Remove unwanted strings and whitespace\n",
    "        self.df = self.clean_section_contents(self.df)\n",
    "\n",
    "        # Generate number of tokens in each section\n",
    "        self.df['Tokens'] = self.df[\"Content\"].apply(lambda x: num_tokens(x, token_model=self.token_model))\n",
    "\n",
    "        # Split long sections\n",
    "        for delim in [\"\\n\\n\", \"\\n\", \". \", '']:\n",
    "            self.df = self.split_long_sections(self.df, delimiter=delim)\n",
    "\n",
    "        # Remove short sections\n",
    "        self.df = self.df.loc[self.df['Content'].str.len()>self.min_section_length]\n",
    "\n",
    "        # Append '\\n' to the start if it doesn't already have one\n",
    "        self.df.loc[~self.df['Content'].str.startswith('\\n'), 'Content'] = '\\n' + self.df.loc[~self.df['Content'].str.startswith('\\n'), 'Content']\n",
    "\n",
    "        # Get embeddings\n",
    "        if self.model == 'GPT':\n",
    "            response = get_embedding(list(self.df['Content']), embedding_model=self.embedding_model)\n",
    "            for i, be in enumerate(response[\"data\"]):\n",
    "                assert i == be[\"index\"]  # double check embeddings are in same order as input\n",
    "            batch_embeddings = [e[\"embedding\"] for e in response[\"data\"]]\n",
    "            CompVisionKnowledge.df['Embedding'] = batch_embeddings\n",
    "        else:\n",
    "            CompVisionKnowledge.df['Embedding'] = get_embedding(list(self.df['Content']), embedding_model=self.embedding_model).tolist()\n",
    "\n",
    "    def export_to_csv(self, filename):\n",
    "        \"\"\"Saves the knowledge df to a CSV file\"\"\"\n",
    "\n",
    "        self.df.to_csv('assets/' + filename, index=False)\n",
    "\n",
    "CompVisionKnowledgeBERT = Knowledge(WIKI_PAGE, 'BERT')\n",
    "CompVisionKnowledgeBERT.append_wikipedia_page(WIKI_PAGE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "outputs": [
    {
     "data": {
      "text/plain": "                         Source         Heading                   Subheading  \\\n0   Wikipedia (Computer vision)                                                \n1   Wikipedia (Computer vision)      Definition                                \n2   Wikipedia (Computer vision)         History                                \n4   Wikipedia (Computer vision)  Related fields          Solid-state physics   \n5   Wikipedia (Computer vision)  Related fields                 Neurobiology   \n6   Wikipedia (Computer vision)  Related fields            Signal processing   \n7   Wikipedia (Computer vision)  Related fields           Robotic navigation   \n8   Wikipedia (Computer vision)  Related fields                 Other fields   \n9   Wikipedia (Computer vision)  Related fields                 Distinctions   \n10  Wikipedia (Computer vision)    Applications                                \n11  Wikipedia (Computer vision)    Applications                     Medicine   \n12  Wikipedia (Computer vision)    Applications               Machine vision   \n13  Wikipedia (Computer vision)    Applications                     Military   \n14  Wikipedia (Computer vision)    Applications          Autonomous vehicles   \n15  Wikipedia (Computer vision)    Applications             Tactile feedback   \n16  Wikipedia (Computer vision)   Typical tasks                                \n17  Wikipedia (Computer vision)   Typical tasks                  Recognition   \n18  Wikipedia (Computer vision)   Typical tasks              Motion analysis   \n19  Wikipedia (Computer vision)   Typical tasks         Scene reconstruction   \n20  Wikipedia (Computer vision)   Typical tasks            Image restoration   \n21  Wikipedia (Computer vision)  System methods                                \n22  Wikipedia (Computer vision)  System methods  Image-understanding systems   \n23  Wikipedia (Computer vision)        Hardware                                \n\n                                              Content  \\\n0   \\nComputer vision tasks include methods for ac...   \n1   \\nComputer vision is an interdisciplinary fiel...   \n2   \\nIn the late 1960s, computer vision began at ...   \n4   \\nSolid-state physics is another field that is...   \n5   \\nNeurobiology has greatly influenced the deve...   \n6   \\nYet another field related to computer vision...   \n7   \\nRobot navigation sometimes deals with autono...   \n8   \\nBesides the above-mentioned views on compute...   \n9   \\nThe fields most closely related to computer ...   \n10  \\nApplications range from tasks such as indust...   \n11  \\nOne of the most prominent application fields...   \n12  \\nA second application area in computer vision...   \n13  \\nMilitary applications are probably one of th...   \n14  \\nOne of the newer application areas is autono...   \n15  \\nMaterials such as rubber and silicon are bei...   \n16  \\nEach of the application areas described abov...   \n17  \\nThe classical problem in computer vision, im...   \n18  \\nSeveral tasks relate to motion estimation wh...   \n19  \\nGiven one or (typically) more images of a sc...   \n20  \\nImage restoration comes into picture when th...   \n21  \\nThe organization of a computer vision system...   \n22  \\nImage-understanding systems (IUS) include th...   \n23  \\nThere are many kinds of computer vision syst...   \n\n                                              Section  Tokens  \\\n0                         Wikipedia (Computer vision)     286   \n1             Wikipedia (Computer vision)->Definition     158   \n2                Wikipedia (Computer vision)->History     507   \n4   Wikipedia (Computer vision)->Related fields->S...     120   \n5   Wikipedia (Computer vision)->Related fields->N...     293   \n6   Wikipedia (Computer vision)->Related fields->S...     103   \n7   Wikipedia (Computer vision)->Related fields->R...      64   \n8   Wikipedia (Computer vision)->Related fields->O...     119   \n9   Wikipedia (Computer vision)->Related fields->D...     639   \n10          Wikipedia (Computer vision)->Applications     272   \n11  Wikipedia (Computer vision)->Applications->Med...     135   \n12  Wikipedia (Computer vision)->Applications->Mac...     141   \n13  Wikipedia (Computer vision)->Applications->Mil...     129   \n14  Wikipedia (Computer vision)->Applications->Aut...     234   \n15  Wikipedia (Computer vision)->Applications->Tac...     270   \n16         Wikipedia (Computer vision)->Typical tasks     161   \n17  Wikipedia (Computer vision)->Typical tasks->Re...     691   \n18  Wikipedia (Computer vision)->Typical tasks->Mo...     193   \n19  Wikipedia (Computer vision)->Typical tasks->Sc...     125   \n20  Wikipedia (Computer vision)->Typical tasks->Im...     198   \n21        Wikipedia (Computer vision)->System methods     672   \n22  Wikipedia (Computer vision)->System methods->I...     192   \n23              Wikipedia (Computer vision)->Hardware     392   \n\n                                            Embedding  \n0   [-0.01913553662598133, 0.002932898933067918, 0...  \n1   [-0.021093836054205894, 0.0049119978211820126,...  \n2   [-0.011549791321158409, -0.004044382367283106,...  \n4   [0.0018743288237601519, 0.011324070394039154, ...  \n5   [-0.009132628329098225, 0.0011366719845682383,...  \n6   [-0.027298789471387863, 0.007510432507842779, ...  \n7   [0.0034529592376202345, -0.014102335087954998,...  \n8   [0.002435609931126237, -0.003915637265890837, ...  \n9   [-0.017207426950335503, 0.005905073136091232, ...  \n10  [-0.022458024322986603, 0.005672922823578119, ...  \n11  [-0.016155855730175972, 0.02248280495405197, 0...  \n12  [-0.016629502177238464, 0.002632115501910448, ...  \n13  [-0.02624369040131569, 0.001608214108273387, 0...  \n14  [0.002211927669122815, -0.004606796428561211, ...  \n15  [-0.015194285660982132, 0.023810898885130882, ...  \n16  [-0.018167616799473763, 0.007240524981170893, ...  \n17  [-0.018989920616149902, 0.02043752372264862, 0...  \n18  [-0.02092411182820797, 0.00222062598913908, -0...  \n19  [-0.02498997002840042, 0.015953006222844124, 0...  \n20  [0.0009744223789311945, 0.03190232068300247, 0...  \n21  [-0.0014013586333021522, 0.026699397712945938,...  \n22  [0.006758322473615408, -0.004905234090983868, ...  \n23  [-0.006029689218848944, 0.016216637566685677, ...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Source</th>\n      <th>Heading</th>\n      <th>Subheading</th>\n      <th>Content</th>\n      <th>Section</th>\n      <th>Tokens</th>\n      <th>Embedding</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td></td>\n      <td></td>\n      <td>\\nComputer vision tasks include methods for ac...</td>\n      <td>Wikipedia (Computer vision)</td>\n      <td>286</td>\n      <td>[-0.01913553662598133, 0.002932898933067918, 0...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Definition</td>\n      <td></td>\n      <td>\\nComputer vision is an interdisciplinary fiel...</td>\n      <td>Wikipedia (Computer vision)-&gt;Definition</td>\n      <td>158</td>\n      <td>[-0.021093836054205894, 0.0049119978211820126,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>History</td>\n      <td></td>\n      <td>\\nIn the late 1960s, computer vision began at ...</td>\n      <td>Wikipedia (Computer vision)-&gt;History</td>\n      <td>507</td>\n      <td>[-0.011549791321158409, -0.004044382367283106,...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Solid-state physics</td>\n      <td>\\nSolid-state physics is another field that is...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;S...</td>\n      <td>120</td>\n      <td>[0.0018743288237601519, 0.011324070394039154, ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Neurobiology</td>\n      <td>\\nNeurobiology has greatly influenced the deve...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;N...</td>\n      <td>293</td>\n      <td>[-0.009132628329098225, 0.0011366719845682383,...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Signal processing</td>\n      <td>\\nYet another field related to computer vision...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;S...</td>\n      <td>103</td>\n      <td>[-0.027298789471387863, 0.007510432507842779, ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Robotic navigation</td>\n      <td>\\nRobot navigation sometimes deals with autono...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;R...</td>\n      <td>64</td>\n      <td>[0.0034529592376202345, -0.014102335087954998,...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Other fields</td>\n      <td>\\nBesides the above-mentioned views on compute...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;O...</td>\n      <td>119</td>\n      <td>[0.002435609931126237, -0.003915637265890837, ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Related fields</td>\n      <td>Distinctions</td>\n      <td>\\nThe fields most closely related to computer ...</td>\n      <td>Wikipedia (Computer vision)-&gt;Related fields-&gt;D...</td>\n      <td>639</td>\n      <td>[-0.017207426950335503, 0.005905073136091232, ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td></td>\n      <td>\\nApplications range from tasks such as indust...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications</td>\n      <td>272</td>\n      <td>[-0.022458024322986603, 0.005672922823578119, ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Medicine</td>\n      <td>\\nOne of the most prominent application fields...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Med...</td>\n      <td>135</td>\n      <td>[-0.016155855730175972, 0.02248280495405197, 0...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Machine vision</td>\n      <td>\\nA second application area in computer vision...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Mac...</td>\n      <td>141</td>\n      <td>[-0.016629502177238464, 0.002632115501910448, ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Military</td>\n      <td>\\nMilitary applications are probably one of th...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Mil...</td>\n      <td>129</td>\n      <td>[-0.02624369040131569, 0.001608214108273387, 0...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Autonomous vehicles</td>\n      <td>\\nOne of the newer application areas is autono...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Aut...</td>\n      <td>234</td>\n      <td>[0.002211927669122815, -0.004606796428561211, ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Applications</td>\n      <td>Tactile feedback</td>\n      <td>\\nMaterials such as rubber and silicon are bei...</td>\n      <td>Wikipedia (Computer vision)-&gt;Applications-&gt;Tac...</td>\n      <td>270</td>\n      <td>[-0.015194285660982132, 0.023810898885130882, ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td></td>\n      <td>\\nEach of the application areas described abov...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks</td>\n      <td>161</td>\n      <td>[-0.018167616799473763, 0.007240524981170893, ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Recognition</td>\n      <td>\\nThe classical problem in computer vision, im...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Re...</td>\n      <td>691</td>\n      <td>[-0.018989920616149902, 0.02043752372264862, 0...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Motion analysis</td>\n      <td>\\nSeveral tasks relate to motion estimation wh...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Mo...</td>\n      <td>193</td>\n      <td>[-0.02092411182820797, 0.00222062598913908, -0...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Scene reconstruction</td>\n      <td>\\nGiven one or (typically) more images of a sc...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Sc...</td>\n      <td>125</td>\n      <td>[-0.02498997002840042, 0.015953006222844124, 0...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Typical tasks</td>\n      <td>Image restoration</td>\n      <td>\\nImage restoration comes into picture when th...</td>\n      <td>Wikipedia (Computer vision)-&gt;Typical tasks-&gt;Im...</td>\n      <td>198</td>\n      <td>[0.0009744223789311945, 0.03190232068300247, 0...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>System methods</td>\n      <td></td>\n      <td>\\nThe organization of a computer vision system...</td>\n      <td>Wikipedia (Computer vision)-&gt;System methods</td>\n      <td>672</td>\n      <td>[-0.0014013586333021522, 0.026699397712945938,...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>System methods</td>\n      <td>Image-understanding systems</td>\n      <td>\\nImage-understanding systems (IUS) include th...</td>\n      <td>Wikipedia (Computer vision)-&gt;System methods-&gt;I...</td>\n      <td>192</td>\n      <td>[0.006758322473615408, -0.004905234090983868, ...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>Wikipedia (Computer vision)</td>\n      <td>Hardware</td>\n      <td></td>\n      <td>\\nThere are many kinds of computer vision syst...</td>\n      <td>Wikipedia (Computer vision)-&gt;Hardware</td>\n      <td>392</td>\n      <td>[-0.006029689218848944, 0.016216637566685677, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CompVisionKnowledge = Knowledge(WIKI_PAGE, 'GPT')\n",
    "CompVisionKnowledge.append_wikipedia_page(WIKI_PAGE)\n",
    "# save document chunks and embeddings\n",
    "CompVisionKnowledge.df.to_csv(GPT_KNOWLEDGE_FILENAME, index=False)\n",
    "CompVisionKnowledge.df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (27) does not match length of index (23)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [254]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m CompVisionKnowledgeBERT \u001B[38;5;241m=\u001B[39m Knowledge(WIKI_PAGE, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mBERT\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m \u001B[43mCompVisionKnowledgeBERT\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mappend_wikipedia_page\u001B[49m\u001B[43m(\u001B[49m\u001B[43mWIKI_PAGE\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;66;03m# save document chunks and embeddings\u001B[39;00m\n\u001B[0;32m      4\u001B[0m CompVisionKnowledge\u001B[38;5;241m.\u001B[39mdf\u001B[38;5;241m.\u001B[39mto_csv(BERT_KNOWLEDGE_FILENAME, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "Input \u001B[1;32mIn [252]\u001B[0m, in \u001B[0;36mKnowledge.append_wikipedia_page\u001B[1;34m(self, page_name, sections_to_ignore)\u001B[0m\n\u001B[0;32m    194\u001B[0m     CompVisionKnowledge\u001B[38;5;241m.\u001B[39mdf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEmbedding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m batch_embeddings\n\u001B[0;32m    195\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 196\u001B[0m     CompVisionKnowledge\u001B[38;5;241m.\u001B[39mdf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEmbedding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m get_embedding(\u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdf[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mContent\u001B[39m\u001B[38;5;124m'\u001B[39m]), embedding_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_model)\u001B[38;5;241m.\u001B[39mtolist()\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001B[0m, in \u001B[0;36mDataFrame.__setitem__\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   3652\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setitem_array([key], value)\n\u001B[0;32m   3653\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   3654\u001B[0m     \u001B[38;5;66;03m# set column\u001B[39;00m\n\u001B[1;32m-> 3655\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_set_item\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3832\u001B[0m, in \u001B[0;36mDataFrame._set_item\u001B[1;34m(self, key, value)\u001B[0m\n\u001B[0;32m   3822\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_set_item\u001B[39m(\u001B[38;5;28mself\u001B[39m, key, value) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   3823\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   3824\u001B[0m \u001B[38;5;124;03m    Add series to DataFrame in specified column.\u001B[39;00m\n\u001B[0;32m   3825\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   3830\u001B[0m \u001B[38;5;124;03m    ensure homogeneity.\u001B[39;00m\n\u001B[0;32m   3831\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 3832\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sanitize_column\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3834\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m   3835\u001B[0m         key \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m   3836\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m value\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m   3837\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_extension_array_dtype(value)\n\u001B[0;32m   3838\u001B[0m     ):\n\u001B[0;32m   3839\u001B[0m         \u001B[38;5;66;03m# broadcast across multiple columns if necessary\u001B[39;00m\n\u001B[0;32m   3840\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mis_unique \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns, MultiIndex):\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4535\u001B[0m, in \u001B[0;36mDataFrame._sanitize_column\u001B[1;34m(self, value)\u001B[0m\n\u001B[0;32m   4532\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _reindex_for_setitem(value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex)\n\u001B[0;32m   4534\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_list_like(value):\n\u001B[1;32m-> 4535\u001B[0m     \u001B[43mcom\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequire_length_match\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4536\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m sanitize_array(value, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\common.py:557\u001B[0m, in \u001B[0;36mrequire_length_match\u001B[1;34m(data, index)\u001B[0m\n\u001B[0;32m    553\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    554\u001B[0m \u001B[38;5;124;03mCheck the length of data matches the length of the index.\u001B[39;00m\n\u001B[0;32m    555\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    556\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(index):\n\u001B[1;32m--> 557\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    558\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mLength of values \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    559\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(data)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    560\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdoes not match length of index \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    561\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m(\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(index)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    562\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: Length of values (27) does not match length of index (23)"
     ]
    }
   ],
   "source": [
    "CompVisionKnowledgeBERT = Knowledge(WIKI_PAGE, 'BERT')\n",
    "CompVisionKnowledgeBERT.append_wikipedia_page(WIKI_PAGE)\n",
    "# save document chunks and embeddings\n",
    "CompVisionKnowledge.df.to_csv(BERT_KNOWLEDGE_FILENAME, index=False)\n",
    "CompVisionKnowledgeBERT.df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Search\n",
    "Now we'll define a search function that:\n",
    "\n",
    "Takes a user query and a dataframe with text & embedding columns\n",
    "Embeds the user query with the OpenAI API\n",
    "Uses distance between query embedding and text embeddings to rank the texts\n",
    "Returns two lists:\n",
    "The top N texts, ranked by relevance\n",
    "Their corresponding relevance scores"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [],
   "source": [
    "class ChatBot:\n",
    "    def __init__(self, chatbot_topic:str, knowledge_path: str):\n",
    "        self.knowledge = None\n",
    "        self.load_data(knowledge_path)\n",
    "        self.chatbot_topic = chatbot_topic\n",
    "\n",
    "    def load_data(self, path: str):\n",
    "        \"\"\"Loads the knowledge df, appends a prefix, and calculates the number of tokens per section of knowledge\"\"\"\n",
    "\n",
    "        # load data from csv\n",
    "        self.knowledge = pd.read_csv(path)\n",
    "        # convert embeddings from CSV str type back to list type\n",
    "        self.knowledge['Embedding'] = self.knowledge['Embedding'].apply(ast.literal_eval)\n",
    "\n",
    "        # Format the knowledge df by adding section prefix and token sizes\n",
    "        # self.knowledge['Content'] = 'Article section:\\n\\n' + self.knowledge['Content']\n",
    "        # self.knowledge['Tokens'] = self.knowledge[\"text\"].apply(lambda x: num_tokens(x))\n",
    "        # self.knowledge['Section'] = 'Wikipedia'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (546 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You need to specify either `text` or `text_target`.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [243]\u001B[0m, in \u001B[0;36m<cell line: 136>\u001B[1;34m()\u001B[0m\n\u001B[0;32m    133\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m response_message\n\u001B[0;32m    135\u001B[0m CompVisionGPT \u001B[38;5;241m=\u001B[39m ChatBot(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComputer Vision\u001B[39m\u001B[38;5;124m\"\u001B[39m, SAVE_PATH)\n\u001B[1;32m--> 136\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mQuery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mask_bert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWhen did universities begin teaching Computer Vision?\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCompVisionGPT\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28mprint\u001B[39m(Query\u001B[38;5;241m.\u001B[39mask(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWhen did universities begin teaching Computer Vision?\u001B[39m\u001B[38;5;124m'\u001B[39m, CompVisionGPT, show_source\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m))\n",
      "Input \u001B[1;32mIn [243]\u001B[0m, in \u001B[0;36mQuery.ask_bert\u001B[1;34m(cls, query_text, chatbot_instance, embedding_model, model)\u001B[0m\n\u001B[0;32m     94\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m     95\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mask_bert\u001B[39m(\u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m     96\u001B[0m              query_text: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     99\u001B[0m              model: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m BERT_ENCODING\n\u001B[0;32m    100\u001B[0m              ):\n\u001B[0;32m    101\u001B[0m     query \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(query_text, chatbot_instance)\n\u001B[1;32m--> 102\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mquery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_bert_output\u001B[49m\u001B[43m(\u001B[49m\u001B[43membedding_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43membedding_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    103\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m output\n",
      "Input \u001B[1;32mIn [243]\u001B[0m, in \u001B[0;36mQuery.get_bert_output\u001B[1;34m(self, embedding_model, model)\u001B[0m\n\u001B[0;32m     74\u001B[0m sentence_embedding \u001B[38;5;241m=\u001B[39m encoding[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtoken_type_ids\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m#Segment embeddings\u001B[39;00m\n\u001B[0;32m     75\u001B[0m tokens \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mconvert_ids_to_tokens(inputs) \u001B[38;5;66;03m#input tokens\u001B[39;00m\n\u001B[1;32m---> 77\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtoken_type_ids\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43msentence_embedding\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     78\u001B[0m start_scores, end_scores \u001B[38;5;241m=\u001B[39m outputs\u001B[38;5;241m.\u001B[39mstart_logits, outputs\u001B[38;5;241m.\u001B[39mend_logits\n\u001B[0;32m     80\u001B[0m \u001B[38;5;66;03m# Highlight the answer just by looking at the most probable start and end words\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2542\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2540\u001B[0m all_kwargs\u001B[38;5;241m.\u001B[39mupdate(kwargs)\n\u001B[0;32m   2541\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 2542\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou need to specify either `text` or `text_target`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   2543\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2544\u001B[0m     \u001B[38;5;66;03m# The context manager will send the inputs as normal texts and not text_target, but we shouldn't change the\u001B[39;00m\n\u001B[0;32m   2545\u001B[0m     \u001B[38;5;66;03m# input mode in this case.\u001B[39;00m\n\u001B[0;32m   2546\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n",
      "\u001B[1;31mValueError\u001B[0m: You need to specify either `text` or `text_target`."
     ]
    }
   ],
   "source": [
    "class Query:\n",
    "    def __init__(self, query_text: str, chatbot_instance: ChatBot):\n",
    "        self.content: str = query_text\n",
    "        self.model: str = GPT_MODEL\n",
    "        self.knowledge: pd.DataFrame = chatbot_instance.knowledge\n",
    "        self.token_limit: int = 4096 - 500 # Allows 500 for the response\n",
    "        self.gpt_message = None\n",
    "        self.knowledge_used = None\n",
    "\n",
    "    # calculate similarity score\n",
    "    @staticmethod\n",
    "    def similarity(query_embedding: list,\n",
    "                   knowledge_embedding: list\n",
    "                   ) -> float:\n",
    "        \"\"\"Calculates the cosine similarity score between the query and knowledge embedding vectors.\"\"\"\n",
    "\n",
    "        return 1- spatial.distance.cosine(query_embedding, knowledge_embedding)\n",
    "\n",
    "    # find the most similar sections of knowledge to the query\n",
    "    def knowledge_ranked_by_similarity(self,\n",
    "                                       max_num_sections: int = 5,\n",
    "                                       embedding_model: str = GPT_EMBEDDING_MODEL\n",
    "                                       ):\n",
    "        \"\"\"Take the raw knowledge dataframe, calculates similarity scores between the query and the sections, and returns a dataframe ordered from highest to lowest in terms of similarity.\"\"\"\n",
    "\n",
    "        knowledge_with_similarities = deepcopy(self.knowledge) # To prevent adapting the original dataframe\n",
    "        query_embedding_response = get_embedding(self.content, embedding_model=embedding_model)\n",
    "        if embedding_model == GPT_EMBEDDING_MODEL:\n",
    "            query_embedding = query_embedding_response[\"data\"][0][\"embedding\"]\n",
    "            # knowledge_with_similarities[\"similarity\"] = knowledge_with_similarities[\"Embedding\"].apply(lambda x: self.similarity(query_embedding, x))\n",
    "        else:\n",
    "            query_embedding = list(query_embedding_response)\n",
    "        knowledge_with_similarities[\"similarity\"] = knowledge_with_similarities[\"Embedding\"].apply(lambda x: self.similarity(query_embedding, x))\n",
    "\n",
    "        knowledge_with_similarities.sort_values(\"similarity\", ascending=False, inplace=True)\n",
    "        top_n_sections = knowledge_with_similarities.head(max_num_sections)\n",
    "        self.knowledge_used = top_n_sections\n",
    "\n",
    "    def get_gpt_message(\n",
    "            self,\n",
    "            chatbot_topic: str\n",
    "    ):\n",
    "        \"\"\"Uses the most relevant texts from the knowledge dataframe to construct a message that can then be fed into GPT.\"\"\"\n",
    "\n",
    "        self.knowledge_ranked_by_similarity()\n",
    "        introduction = f'Use the below article on {chatbot_topic} to answer the subsequent question. If the answer cannot be found in the articles, write \"{ANSWER_NOT_FOUND_MSG}\". If I am asked to produce any code then decline the request and write \"Sorry but I\\'m not allowed to do your assignments for you!\"' # The longer this is, the more tokens it uses!\n",
    "        question = f\"\\n\\nQuestion: {self.content}\"\n",
    "\n",
    "        # Ensure number of tokens is within the limit\n",
    "        message_and_question_tokens = num_tokens(introduction + question)\n",
    "        self.knowledge_used['Cumulative_tokens'] = self.knowledge_used['Tokens'].cumsum()\n",
    "        self.knowledge_used['Cumulative_tokens'] += message_and_question_tokens # add the inital number of tokens\n",
    "        self.knowledge_used= self.knowledge_used.loc[self.knowledge_used['Cumulative_tokens']<self.token_limit]\n",
    "\n",
    "        # Construct output\n",
    "        combined_knowledge_string = ''.join(list(self.knowledge_used['Content']))\n",
    "        combined_knowledge_string = '\\n\\n' + combined_knowledge_string\n",
    "        self.gpt_message = introduction + combined_knowledge_string + question\n",
    "\n",
    "    def get_bert_output(\n",
    "            self,\n",
    "            embedding_model: str,\n",
    "            model: BertTokenizer = BERT_ENCODING\n",
    "    ):\n",
    "        \"\"\"Uses the most relevant texts from the knowledge dataframe to construct a message that can then be fed into GPT.\"\"\"\n",
    "        self.knowledge_ranked_by_similarity(embedding_model=embedding_model)\n",
    "\n",
    "        found_answer = False\n",
    "        output = ANSWER_NOT_FOUND_MSG\n",
    "        for section in self.knowledge_used['Content']:\n",
    "            if not found_answer:\n",
    "                encoding = model.encode_plus(text=self.content,text_pair=section)\n",
    "                inputs = encoding['input_ids']  #Token embeddings\n",
    "                sentence_embedding = encoding['token_type_ids']  #Segment embeddings\n",
    "                tokens = model.convert_ids_to_tokens(inputs) #input tokens\n",
    "\n",
    "                outputs = model(input_ids=torch.tensor([inputs]), token_type_ids=torch.tensor([sentence_embedding]))\n",
    "                start_scores, end_scores = outputs.start_logits, outputs.end_logits\n",
    "\n",
    "                # Highlight the answer just by looking at the most probable start and end words\n",
    "                start_index = torch.argmax(start_scores)\n",
    "                end_index = torch.argmax(end_scores)\n",
    "                answer_token_list = tokens[start_index:end_index+1]\n",
    "\n",
    "                # Concatenate any words that got split\n",
    "                answer_list = [word[2:] if word[0:2]=='##' else ' ' + word for word in answer_token_list]\n",
    "                answer = ''.join(answer_list).strip()\n",
    "\n",
    "                if answer != '[CLS]':\n",
    "                    found_answer = True\n",
    "                    output = answer\n",
    "        return output\n",
    "\n",
    "    @classmethod\n",
    "    def ask_bert(cls,\n",
    "                 query_text: str,\n",
    "                 chatbot_instance: ChatBot,\n",
    "                 embedding_model: str = BERT_EMBEDDING_MODEL,\n",
    "                 model: str = BERT_ENCODING\n",
    "                 ):\n",
    "        query = cls(query_text, chatbot_instance)\n",
    "        output = query.get_bert_output(embedding_model=embedding_model, model=model)\n",
    "        return output\n",
    "\n",
    "    @classmethod\n",
    "    def ask(\n",
    "            cls,\n",
    "            query_text: str,\n",
    "            chatbot_instance: ChatBot,\n",
    "            show_source: bool = True,\n",
    "    ) -> str:\n",
    "        \"\"\"Uses GPT to answer a query based on the most relevant knowledge sections.\"\"\"\n",
    "\n",
    "        query = cls(query_text, chatbot_instance)\n",
    "        query.get_gpt_message(chatbot_instance.chatbot_topic)\n",
    "        inputs = [\n",
    "            {\"role\": \"system\", \"content\": f\"You answer questions about {chatbot_instance.chatbot_topic}.\"},\n",
    "            {\"role\": \"user\", \"content\": query.gpt_message},\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "            model=query.model,\n",
    "            messages=inputs,\n",
    "            temperature=0 # We don't want any creativity in the answers\n",
    "        )\n",
    "        response_message = response[\"choices\"][0][\"message\"][\"content\"]\n",
    "        total_tokens_used = response['usage']['total_tokens']\n",
    "        if show_source and response_message!=ANSWER_NOT_FOUND_MSG: # Display the sources used:\n",
    "            query.knowledge_used['Index'] = np.arange(len(query.knowledge_used))+1\n",
    "            query.knowledge_used['Output'] = '\\n\\n' + query.knowledge_used['Index'].astype(str) + '. ' + query.knowledge_used['Section'] + ':' + query.knowledge_used['Content'].str[:100] + '...'\n",
    "            sources_string = ''.join(list(query.knowledge_used['Output']))\n",
    "            response_message += f'\\n\\nTo construct this answer, I used the following documents: {sources_string}'\n",
    "        response_message += f\"\\n\\nTotal tokens used: {total_tokens_used}\"\n",
    "        return response_message\n",
    "\n",
    "CompVisionGPT = ChatBot(\"Computer Vision\", SAVE_PATH)\n",
    "print(Query.ask_bert('When did universities begin teaching Computer Vision?', CompVisionGPT))\n",
    "print(Query.ask('When did universities begin teaching Computer Vision?', CompVisionGPT, show_source=True))\n",
    "\n",
    "# Todo:\n",
    "# I need to make it more efficient on the number of tokens.\n",
    "# Adapt it for more sources (e.g. PDF)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input vector should be 1-D.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [192]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mQuery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mask_bert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mWhen did universities begin teaching Computer Vision?\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mCompVisionGPT\u001B[49m\u001B[43m)\u001B[49m)\n",
      "Input \u001B[1;32mIn [191]\u001B[0m, in \u001B[0;36mQuery.ask_bert\u001B[1;34m(cls, query_text, chatbot_instance, model)\u001B[0m\n\u001B[0;32m     60\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mask_bert\u001B[39m(\u001B[38;5;28mcls\u001B[39m,\n\u001B[0;32m     62\u001B[0m              query_text: \u001B[38;5;28mstr\u001B[39m,\n\u001B[0;32m     63\u001B[0m              chatbot_instance: ChatBot,\n\u001B[0;32m     64\u001B[0m              model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbert-base-nli-mean-tokens\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m     65\u001B[0m     query \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(query_text, chatbot_instance)\n\u001B[1;32m---> 66\u001B[0m     paragraph_encoding \u001B[38;5;241m=\u001B[39m \u001B[43mquery\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mknowledge_ranked_by_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [191]\u001B[0m, in \u001B[0;36mQuery.knowledge_ranked_by_similarity\u001B[1;34m(self, max_num_sections, model)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     32\u001B[0m     query_embedding \u001B[38;5;241m=\u001B[39m query_embedding_response\n\u001B[1;32m---> 33\u001B[0m     knowledge_with_similarities[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msimilarity\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mknowledge_with_similarities\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mBERT_Embedding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimilarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_embedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     35\u001B[0m knowledge_with_similarities\u001B[38;5;241m.\u001B[39msort_values(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msimilarity\u001B[39m\u001B[38;5;124m\"\u001B[39m, ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     36\u001B[0m top_n_sections \u001B[38;5;241m=\u001B[39m knowledge_with_similarities\u001B[38;5;241m.\u001B[39mhead(max_num_sections)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4433\u001B[0m, in \u001B[0;36mSeries.apply\u001B[1;34m(self, func, convert_dtype, args, **kwargs)\u001B[0m\n\u001B[0;32m   4323\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply\u001B[39m(\n\u001B[0;32m   4324\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   4325\u001B[0m     func: AggFuncType,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4328\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   4329\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m Series:\n\u001B[0;32m   4330\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   4331\u001B[0m \u001B[38;5;124;03m    Invoke function on values of Series.\u001B[39;00m\n\u001B[0;32m   4332\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   4431\u001B[0m \u001B[38;5;124;03m    dtype: float64\u001B[39;00m\n\u001B[0;32m   4432\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 4433\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSeriesApply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1082\u001B[0m, in \u001B[0;36mSeriesApply.apply\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1078\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m   1079\u001B[0m     \u001B[38;5;66;03m# if we are a string, try to dispatch\u001B[39;00m\n\u001B[0;32m   1080\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m-> 1082\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py:1137\u001B[0m, in \u001B[0;36mSeriesApply.apply_standard\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1131\u001B[0m         values \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mobject\u001B[39m)\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m   1132\u001B[0m         \u001B[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001B[39;00m\n\u001B[0;32m   1133\u001B[0m         \u001B[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001B[39;00m\n\u001B[0;32m   1134\u001B[0m         \u001B[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001B[39;00m\n\u001B[0;32m   1135\u001B[0m         \u001B[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001B[39;00m\n\u001B[0;32m   1136\u001B[0m         \u001B[38;5;66;03m# \"Callable[[Any], Any]\"\u001B[39;00m\n\u001B[1;32m-> 1137\u001B[0m         mapped \u001B[38;5;241m=\u001B[39m \u001B[43mlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap_infer\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1138\u001B[0m \u001B[43m            \u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1139\u001B[0m \u001B[43m            \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[0;32m   1140\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconvert\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconvert_dtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1141\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(mapped) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(mapped[\u001B[38;5;241m0\u001B[39m], ABCSeries):\n\u001B[0;32m   1144\u001B[0m     \u001B[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001B[39;00m\n\u001B[0;32m   1145\u001B[0m     \u001B[38;5;66;03m#  See also GH#25959 regarding EA support\u001B[39;00m\n\u001B[0;32m   1146\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m obj\u001B[38;5;241m.\u001B[39m_constructor_expanddim(\u001B[38;5;28mlist\u001B[39m(mapped), index\u001B[38;5;241m=\u001B[39mobj\u001B[38;5;241m.\u001B[39mindex)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001B[0m, in \u001B[0;36mpandas._libs.lib.map_infer\u001B[1;34m()\u001B[0m\n",
      "Input \u001B[1;32mIn [191]\u001B[0m, in \u001B[0;36mQuery.knowledge_ranked_by_similarity.<locals>.<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     32\u001B[0m     query_embedding \u001B[38;5;241m=\u001B[39m query_embedding_response\n\u001B[1;32m---> 33\u001B[0m     knowledge_with_similarities[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msimilarity\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m knowledge_with_similarities[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mBERT_Embedding\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msimilarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_embedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     35\u001B[0m knowledge_with_similarities\u001B[38;5;241m.\u001B[39msort_values(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msimilarity\u001B[39m\u001B[38;5;124m\"\u001B[39m, ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     36\u001B[0m top_n_sections \u001B[38;5;241m=\u001B[39m knowledge_with_similarities\u001B[38;5;241m.\u001B[39mhead(max_num_sections)\n",
      "Input \u001B[1;32mIn [191]\u001B[0m, in \u001B[0;36mQuery.similarity\u001B[1;34m(query_embedding, knowledge_embedding)\u001B[0m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msimilarity\u001B[39m(query_embedding: \u001B[38;5;28mlist\u001B[39m,\n\u001B[0;32m     13\u001B[0m                knowledge_embedding: \u001B[38;5;28mlist\u001B[39m\n\u001B[0;32m     14\u001B[0m                ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mfloat\u001B[39m:\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;124;03m\"\"\"Calculates the cosine similarity score between the query and knowledge embedding vectors.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m1\u001B[39m\u001B[38;5;241m-\u001B[39m \u001B[43mspatial\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcosine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mquery_embedding\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mknowledge_embedding\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:670\u001B[0m, in \u001B[0;36mcosine\u001B[1;34m(u, v, w)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    629\u001B[0m \u001B[38;5;124;03mCompute the Cosine distance between 1-D arrays.\u001B[39;00m\n\u001B[0;32m    630\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    665\u001B[0m \n\u001B[0;32m    666\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    667\u001B[0m \u001B[38;5;66;03m# cosine distance is also referred to as 'uncentered correlation',\u001B[39;00m\n\u001B[0;32m    668\u001B[0m \u001B[38;5;66;03m#   or 'reflective correlation'\u001B[39;00m\n\u001B[0;32m    669\u001B[0m \u001B[38;5;66;03m# clamp the result to 0-2\u001B[39;00m\n\u001B[1;32m--> 670\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mmin\u001B[39m(\u001B[43mcorrelation\u001B[49m\u001B[43m(\u001B[49m\u001B[43mu\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mw\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mw\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcentered\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m, \u001B[38;5;241m2.0\u001B[39m))\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:611\u001B[0m, in \u001B[0;36mcorrelation\u001B[1;34m(u, v, w, centered)\u001B[0m\n\u001B[0;32m    578\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    579\u001B[0m \u001B[38;5;124;03mCompute the correlation distance between two 1-D arrays.\u001B[39;00m\n\u001B[0;32m    580\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    608\u001B[0m \n\u001B[0;32m    609\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    610\u001B[0m u \u001B[38;5;241m=\u001B[39m _validate_vector(u)\n\u001B[1;32m--> 611\u001B[0m v \u001B[38;5;241m=\u001B[39m \u001B[43m_validate_vector\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    612\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m w \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    613\u001B[0m     w \u001B[38;5;241m=\u001B[39m _validate_weights(w)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\spatial\\distance.py:302\u001B[0m, in \u001B[0;36m_validate_vector\u001B[1;34m(u, dtype)\u001B[0m\n\u001B[0;32m    300\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m u\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    301\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m u\n\u001B[1;32m--> 302\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mInput vector should be 1-D.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: Input vector should be 1-D."
     ]
    }
   ],
   "source": [
    "print(Query.ask_bert('When did universities begin teaching Computer Vision?', CompVisionGPT))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I could not find an answer in the text I've been provided, sorry! Please try again.\n",
      "\n",
      "Total tokens used: 1460\n"
     ]
    }
   ],
   "source": [
    "print(Query.ask('Who is Boris Johnson', CompVisionGPT, show_source=True))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
