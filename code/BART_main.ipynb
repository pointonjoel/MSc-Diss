{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForQuestionAnswering\n",
    "import torch\n",
    "\n",
    "tokenizer = BartTokenizer.from_pretrained('a-ware/bart-squadv2')\n",
    "model = BartForQuestionAnswering.from_pretrained('a-ware/bart-squadv2')\n",
    "\n",
    "question, text = \"Who was Jim Henson?\", \"Jim Henson was a nice puppet\"\n",
    "encoding = tokenizer(question, text, return_tensors='pt')\n",
    "input_ids = encoding['input_ids']\n",
    "attention_mask = encoding['attention_mask']\n",
    "\n",
    "start_scores, end_scores = model(input_ids, attention_mask=attention_mask, output_attentions=False)[:2]\n",
    "\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(input_ids[0])\n",
    "answer = ' '.join(all_tokens[torch.argmax(start_scores) : torch.argmax(end_scores)+1])\n",
    "answer = tokenizer.convert_tokens_to_ids(answer.split())\n",
    "answer = tokenizer.decode(answer)\n",
    "answer\n",
    "#answer => 'a nice puppet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "'<s>Who was Jim Henson?</s></s>Jim Henson was a nice'"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer vision is the study of how computers can understand images. It is a field of study that is very much in the realm of engineering. It is a field of study that is very much in the realm of science. It is a field of study that is very much in the realm of mathematics. It is a field of study that is very much in the realm of science. It is a field of study that is very much in the realm of engineering. It is a field of study that is very much in the realm of science. It is a field of study that is very much in the realm of engineering. It is a field of study that is very much in the realm of science. It is a field of study that is very much in the realm of engineering. It is a field of study that is very much in the realm of science. It is a field of study that is very much in the realm of engineering. It is a field of study that is very much in the realm of science. It is a field of study that is very much in the realm of engineering. It is a field of study that is very much in the realm of science.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig\n",
    "# see ``examples/summarization/bart/evaluate_cnn.py`` for a longer example\n",
    "model = BartForConditionalGeneration.from_pretrained('vblagoje/bart_lfqa')\n",
    "tokenizer = BartTokenizer.from_pretrained('vblagoje/bart_lfqa')\n",
    "\n",
    "# inputs = tokenizer.batch_encode_plus([ARTICLE_TO_SUMMARIZE], max_length=1024, return_tensors='pt')\n",
    "# # Generate Summary\n",
    "# summary_ids = model.generate(inputs['input_ids'], num_beams=4, max_length=5, early_stopping=True)\n",
    "# print([tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer vision is a field of computer science that deals with how computers can gain high-level understanding from digital images or videos.\n"
     ]
    }
   ],
   "source": [
    "ARTICLE_TO_SUMMARIZE = \"Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do. \\\"Computer vision is concerned with the automatic extraction, analysis and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding.\\\" As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems.\"\n",
    "\n",
    "query = f'question: What is computer vision? context: <P> {ARTICLE_TO_SUMMARIZE}'\n",
    "\n",
    "inputs = tokenizer([query], max_length=1024, return_tensors='pt')\n",
    "\n",
    "# Generate Summary\n",
    "ids = model.generate(inputs['input_ids'], num_beams=8, min_length=20, max_length=256,\n",
    "                                           do_sample=False,\n",
    "                                           early_stopping=True,\n",
    "                                           temperature=1.0,\n",
    "                                           top_k=None,\n",
    "                                           top_p=None,\n",
    "                                           eos_token_id=tokenizer.eos_token_id,\n",
    "                                           no_repeat_ngram_size=3,\n",
    "                                           num_return_sequences=1)\n",
    "answer=tokenizer.batch_decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0  ]\n",
    "print(answer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computer vision researcher\n"
     ]
    }
   ],
   "source": [
    "ARTICLE_TO_SUMMARIZE = \"Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do. \\\"Computer vision is concerned with the automatic extraction, analysis and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding.\\\" As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems.\"\n",
    "\n",
    "query = f'question: Who is Boris Johnson? context: <P> {ARTICLE_TO_SUMMARIZE}'\n",
    "\n",
    "inputs = tokenizer([query], max_length=1024, return_tensors='pt')\n",
    "\n",
    "# Generate Summary\n",
    "ids = model.generate(inputs['input_ids'], num_beams=2, min_length=0, max_length=256,\n",
    "                                           do_sample=False,\n",
    "                                           early_stopping=True,\n",
    "                                           temperature=1.0,\n",
    "                                           top_p=0.95, top_k=50,\n",
    "                                           eos_token_id=tokenizer.eos_token_id,\n",
    "                                           no_repeat_ngram_size=3,\n",
    "                                           num_return_sequences=1, repetition_penalty=2.0)\n",
    "answer=tokenizer.batch_decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0  ]\n",
    "print(answer)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "0.6217034459114075"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import spatial  # for calculating vector similarities for search\n",
    "def similarity(query_embedding: list,\n",
    "                   knowledge_embedding: list\n",
    "    ) -> float:\n",
    "        \"\"\"Calculates the cosine similarity score between the query and knowledge embedding vectors.\"\"\"\n",
    "\n",
    "        return 1- spatial.distance.cosine(query_embedding, knowledge_embedding)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "similarity_model = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "question_encoding = similarity_model.encode('What is computer vision?')\n",
    "paragraph_encoding = similarity_model.encode(context)\n",
    "similarity(question_encoding, paragraph_encoding)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading (…)okenizer_config.json:   0%|          | 0.00/1.99k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6ea50335d85244b6841339fb37cc3f23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5779d7cc4f7141c3a83c29ec4e20f4dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.79k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1be798a178f4423b971b80834430c23"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\point\\anaconda3\\lib\\site-packages\\transformers\\models\\auto\\modeling_auto.py:1352: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.41k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f6db53ccc824b639259c73ae8769b75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "353adb51f75045d39daaf73e9b043f84"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\point\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The answer to life, the universe, and everything in it's entirety.\n"
     ]
    }
   ],
   "source": [
    "from  transformers  import  AutoTokenizer, AutoModelWithLMHead, pipeline\n",
    "\n",
    "model_name = \"MaRiOrOsSi/t5-base-finetuned-question-answering\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelWithLMHead.from_pretrained(model_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\point\\anaconda3\\lib\\site-packages\\transformers\\generation\\utils.py:1346: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two dimensional models for the construction of computer vision systems.\n"
     ]
    }
   ],
   "source": [
    "question = \"What are tensors?\"\n",
    "context = \"Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do. \\\"Computer vision is concerned with the automatic extraction, analysis and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding.\\\" As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems.\"\n",
    "input = f\"question: {question} context: {context}\"\n",
    "encoded_input = tokenizer([input],\n",
    "                             return_tensors='pt',\n",
    "                             max_length=512,\n",
    "                             truncation=True)\n",
    "output = model.generate(input_ids = encoded_input.input_ids,\n",
    "                            attention_mask = encoded_input.attention_mask)\n",
    "output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading (…)lve/main/config.json:   0%|          | 0.00/473 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01b2a1c5d0834c408764575a12ebc7fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/261M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26150b31cd854fc38d3385a1221311c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_model = pipeline(\"question-answering\")\n",
    "question = \"How can computer vision be applied to engineering?\"\n",
    "context = \"Computer vision is an interdisciplinary field that deals with how computers can be made to gain high-level understanding from digital images or videos. From the perspective of engineering, it seeks to automate tasks that the human visual system can do. \\\"Computer vision is concerned with the automatic extraction, analysis and understanding of useful information from a single image or a sequence of images. It involves the development of a theoretical and algorithmic basis to achieve automatic visual understanding.\\\" As a scientific discipline, computer vision is concerned with the theory behind artificial systems that extract information from images. The image data can take many forms, such as video sequences, views from multiple cameras, or multi-dimensional data from a medical scanner. As a technological discipline, computer vision seeks to apply its theories and models for the construction of computer vision systems.\"\n",
    "qa_model(question = question, context = context)\n",
    "## {'answer': 'İstanbul', 'end': 39, 'score': 0.953, 'start': 31}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
