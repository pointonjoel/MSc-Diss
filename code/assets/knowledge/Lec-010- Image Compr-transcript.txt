SPEAKER 0
Hayward. Welcome to Introduction to Image Processing. In today's lecture, we're going to look at image compression. Let's begin. In today's lecture within and defy redundancy. Hoffman Cody. Psycho visual redundancy, also known as JAFF and a compression system that we are familiar with. JP. Let's begin with redundancy. Now many of us know that images carries a lot of information, and because of it, it will contribute to a large size for the image that we want to store. Now, here's where image compression comes in. So in the video, images can be large and easy to acquire. Collections increase rapidly, especially when you have a series of images making a video sequence. Now in some application images, I get it automatically. And this is very, very common in areas like geography and medical. Luckily, image j'Ã©tais redundant in several ways. So we know that in a sense of coding, redundancy, spatial redundancy and physio, visual redundancy. Now, in this light, let's get a better understanding of coding redundancy. Now the grey level histogram of the image should give the probability frequency of occurrences of grey level in the following question. If the number of bits used to represent each value of our case, I ask, the average number of beads required to represent a pixel is as follows. Therefore, to quote an m by an image, it would require an m and L average bit. Now let's break this down even further. Even in miniature, binary code is used to represent grade level. Then this is what we can see. All pixels take the same amount of space PR value some to one. Therefore giving us the following equation. And an image occupies and. And. And bit. But some pixels are more common than others. He is where verbal and encoding comes in, assigning few of it to the more probable grey levels than the less probable ones can achieve better compression better. Let's look at this as an example. Below code book replace true pixel values with code. Now this is where Lossless comes in is the process can be reversed by inverting the code. Sometimes also called as into pixel redundancy. That's what is in reference to spatial redundancy. Now, neighbouring pixels often have similar value compression based on spatial. We don't even see involves some element of pixel grouping or transformation. One of the simplest approach is the one length encoding. What he does is immense. The pixel along each scan line into a sequence of pairs where g. G is the eight three level and our G is the run length of eight. When. To get a better understanding of the spatial redundancy concept that we come into previously. This slide presents us with a binary example. Now this image here on the right is the binary. And in order for us to get the spatial redundancy, we have to encode it in order to get the right len encoding approach that we mentioned previously. In order for us to get back the binary, make sure we just have to decode the wrong len encoding result, which would give us back the subsequent binary example that we see on this left. Now let's get it. Psycho visual reality. Some grade level and colour differences are imperceptible. The goal is to compress without noticeable change to the image. Let's look at these two example here. We have two images here with different grey levels, top one with 26 and one with 60. Take note of the additional artefacts caused by it. Now, how do we solve this? A simpler method is to add a small random number to each pixel before quantisation. Therefore producing a much more nicer image that is compress. Now, how do we evaluate the compression that's before? By using a criteria known as fidelity criteria. Success is judged by comparing original and compressed version. Some measures objective such as root mean square error and signal to noise ratio. So how do we go about it? Now let f x y be the input image. F complement x y, be the reconstructed input image from the compressed bitstream. Then by using. This formula here, we are able to compute the fidelity growth here. To understand the content of the previous slide. Let's use this line as an example, revisiting the images that were introduced earlier. Look at what the results that we get from being applied to the two images. The one without the use of a simple method and the other one with the use of the symbol with. Take note of the result that we get. So Fidelity got to you. The two parameters into use are convenient objective measures. Most compress image are viewed by human beings. Subjective evaluation of compressed image quality by human observers are often more appropriate. Therefore, rating scale or television or location study organisation presents a rating system. On which comparison can be based on the value given here. Now let's look at the image compression system. The first one is known as member. It transformed input data in a way that facilitates reduction of inter pixel redundancy. It can be reversed. Quantised transform input data in a way that facilitates reduction of psycho visual redundancy. Now, this system cannot be reversed. The last one is not a symbol colour. It assigns the shortest court to the most frequently occurring output values. This can be reverse. Now, this slide shows you the image compression system, the functional block diagram of the Jara image compression system, where the tree system is used in the previous slides are put together and is known as an encoder. Now let's get to know more about what is known as the Huffman coding. Exploiting, coding, redundancy. These methods derive from information theory, not limited to images applicable to any digital information. Speak of symbols instead of pixels in sources instead of images. Exploit 90 probability of single ram and use a variable and put. It tried to maintain a higher level of information in compress images. However. Evaluation requires a measure of the information content of a source. Here. This is known as entropy. The idea behind entropy is associate information with probability. A random event E with probability P contains the following units of information. Suppose that grade level values are generated by a random variable. Then Arcade contains the following. Units of. Take note that I equals zero when p e equals to one. So entropy is the average information content of an image, a measure of histogram dispersion. Have a look at the two examples here and take note of its entropy values. Kind of compressed to less than hich bits per pixel without losing information. And as built upon our understanding of entropy. Before we introduce Hoffman, we know that it compute probabilities of each symbol by histogram in the source. Process probabilities to pre compute cookbook cookbook aesthetic and consult symbol by symbol whereby symbol I represent I transmit coded signal and cookbook. They need to pre process the source before encoding begins is a disadvantage. Now let's do it. Huffman, quoting in detail It bills a binary tree in which symbols to be coded. I note path from root to note gives code for corresponding symbol. How to implement it. The following algorithm details a step by step approach. Now, this slide presents an example to eight with our understanding.

UNKNOWN
Of the that could.

SPEAKER 0
Now using the example in the previous slide, let's apply the Huffman coding algorithm which will produce the following tree. Take note of its probability, symbol and quote. So the Harvard coding the algorithm systematically places notes representing hyperbole symbols for arbitrary. Yeah pi and so codes I find that no code is prefixed to any other don't need to mock boundaries between those. Take this as an example. In the example using the previous slide, average length of the code is 2.2 bits per symbol, whereas the entropy of the source is 2.14 bits. The single. So in general. Break image into smaller blocks, perhaps eight by eight, and each block is a symbol to be encoded. Now let's look at psycho visual redundancy. Well, we all know famously as Jeff. Using psycho visual identity. It represents areas of grey level colour space with few objects. Loci cannot be inverted. It finds the best trade-off between maximal compression and minimal distortion. Quantisation is widely used here. Take note of this colour Quantisation. It can happen in two form. Uniform scalar quantisation or non uniform scatter composition. Let's get a better understanding of vector quantisation. Now a pilot's image, you have maps, vector values, RGV or two colour values. Now multiple vectors mapped to each scope. So a true colour RGV whereby each colour channel has eight beats. Produces this a lot of possible colours by performing a vector composition. We are compressing things and we are only getting 256 possible colours whereby each per pixel will have eight bits and we are storing it in a form called air. Now for each pixel in the original image. What it does is it finds the closest colour in the colour table which is represented here. He then records the index of the colour for storage or transmission in order to reconstruct the image place the index colour from the colour table at the corresponding spatial location. Now let's look at how to build a palette. We all know that a pixel correspond to a point in the three dimensional RGV space. Now, let's look at this example. We are taking one pixel and we are placing it in a tree. This piece. Now this is how it looks like when we met all the pixel two RGV space clouds of pixel iPhone. No group picks those that are close to each other and replace them by a single colour close to each other. Means of a similar colour. Now. Roberson Beef colours are put in the pellet. As shown here. Now, in order for us to cluster the colours, the mini cluster algorithm exists, some known as super ones and unsupervised. We know how many clusters we need one pop pellet entry. We need clusters that are spread across the colour space. This is an unsupervised method. Came in close to me. How does it work? Start with estimates of the mean of each cluster. Assign each point to the closest where P minus. The mean is the smallest. Recompute the means. Repeat the process under no changes are made to the clusters. Now let's look at the compression system that all of us are very familiar with. Back. Now let's revisit the special reality concept once more. The encoding needs adjacent pixel to be equal. Pixel are more often highly correlated, meaning dependent, not equal, but can predict the image pixel to be coded from those already coded. Now each pixel value except at the boundaries is predicted based on its neighbours. This is a linear combination to get a predicted image. The difference between the original printed image yields a differential or residue image with a reduced set of values. The differential image is encoded using half coding or similar. Differential pulse, quote, modulation. What it does is it caught the difference between edges and pixel. Look at this example here. Take note of the original pixel and the DHCP scheme is derived from it. Prediction is that the next Excel value could, in one meet the first value to provide a point of reference inevitable. It is lossless and lower entropy. Take note of the two. Graph here for better understanding. Predictive coding. What does it do? How you order pattern prediction. Use both in one dimension as well as two dimension patterns. It is meant to predict shade and pixel. Have a look at its representation in one B and 2D. Here on the left, two examples for a1d casual and no one ne non casual is presented, whereas the diagrams on the right present a 2d casual as well as a 2D non casual. Now, putting everything out there is understood from the previous slides. This is what we call a complete system, shaping a set of methods with a common baseline, discrete, constant transform quantisation and verbal linked coding all. Combine into one. A JP compatibility product must only include support for baseline such as this. J. Compression. Convert rg B to UAB is optional but common. Now why is grade level you and we are colour the colleges in lecture two now why he's kept at full resolution whereas you and I don't sample now human region is more sensitive to grade level variation in colours. The rest of the processes apply separately to each field. To understand JPA compression better, we need to revisit image transform once more like 50 basic functions at different top level. Is DC level or are the AC frequency of bases function increases with distance from origin? Bases, pendants. Very interesting. Now for JPEG compression. The image is broken into eight by eight pixel blocks, which are processed sequentially top left to bottom right now. First half maximum intensity value. So value are distributed above zero. Look at it to represent the point of view. The one on the left is known as the image block. Whereas the one on the right is known as the normalised image from. Building on our understanding of the image transform. Here, the normalise image block is converted to DCP block via 2D DCP conversion. Take note of the DC component highlighted in Red Circle and compare this to the slide that talk about image transfer. Isn't the DC in the same location? Hmm. In Japan, Compression AC and DC components are processed separately. DC components summarise packaging density so should marry smoothly over patches. This is done with the use of difficulty. Take note of its inclusion in graphical representation. A second point is a contest. This is done by dividing the ABC block entries by values in a composition table. Different tables for luminance and prominence blocks. I should be. Take note of the mathematical formula here, as well as its variable representation. Now, many of you might be asking this question Why? Contents. Further compression by sending DCT coefficients with no greater position than is necessary to achieve the desired image quality. Generally, the high frequency coefficients have logic. Quantisation values. Quantisation makes most coefficients zero. It makes JPEG compression efficient but lossy. The executive orders elements of quantised easing block roughly on frequency. Now ordering produces long sequences of zeros and sequences of values can be represented using run like coding. Huffman Code. Look took the example shown here. Now increasing the amount of quantisation reduces file size, but introduces artefacts blocks become feasible. Look at this example here. To better understand the above. Explanation. In summary to this lecture, we have covered what is redundancy. We now have a better understanding of Hoffman, Cody Psycho visual redundancy, also known as Jack in a compression system famously known as JP. As always, if you have questions, know where to find me. With. That brings us to the end of today's lecture. Next week, we'll be looking at interactive methods and compositing so that everyone's busy. And I'll see you also, Jess.
