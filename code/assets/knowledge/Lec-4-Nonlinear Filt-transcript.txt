SPEAKER 0
Hi, John. Welcome back. The induction to Image Processing. Today's lecture, we're going to cover nonlinear filters and thresholding. Let's get started. The following is today's learning outcomes that identify median filtering and as trumping by fusion. But I throw filtering what is thresholding and adaptive thresholding.

UNKNOWN
So we begin.

SPEAKER 0
Let's begin with part one and look at non linear food this. In the last lecture we looked at convolution convolution with a muscle weights compute a linear function of a set of pixel values. How many operations can be implemented easily, but not all. Some of them being median filtering and entropy, diffusion and material filtering. Now, some of you might ask what's the difference between linear filters and non linear filters? Non linear filters, smooth shot image changes, Nonlinear filters tend to preserve or even enhance their. Now let's put it median filtering. Salt and pepper nuts. Yes. It's a real thing. Sometimes sensors either fail to respond or saturate an error. So a false saturation gives a white spot in the image which we call salt. A failed response gives a black spot an image which we call pepper. Sometimes these are called speckle noise. Now, in this example here you can see four images with the original one on the left, the tree images moving towards the right. Different percentage being a plane. So an image with varying amounts of salt and pepper noise behind it. So 1%, 10% and 8%. So you can see the more high the percentage, the more salt and pepper you think will take place into the image. Now this slide shows you the result after applying mean filtering causing filtering respectively to reduce the sign bullish. Now look at the images carefully. What is happening to the output images of the applying the respective filters? Now let's look at the median filter. Statistically, the median is the median value in a set. Each pixel is set to the median value in a local window. Result is a real pixel lead, not a competition. Noise pixels, alas, and noise would have to affect more than half the pixel to appear in the output. So let's put this into an example for better understanding. So we have a tree by tree kernel here. And first things first, we kind of put it into a1d array. So find the values in a local window, sort them and pick the middle. In this case will be one, two, five. Now. Given that median filter is a nonlinear filter, what happens if we put the same tree by tree window to a mean filter? No, a mean filter would give a11 tree, which is maybe not far away from 1 to 5. But trust me when it comes to intensity that display a bit more. Now, this slide shows you the result of applying median filter to the original song goes in image. Now look at the corresponding results generated from it and compare it with slight number seven, whereby we use the mean filter and goes into the to reduce assign the panels. Have a look at the output images on both of these slides and I think you can agree with me. And the result here is a bit more better.

UNKNOWN
What do you think?

SPEAKER 0
Known as the doll of attention to and his trumpet be confusion. Now to understand and is trucking definition, we need to revisit median filtering service key. Now media filtering is good given small regional spec. However, is less good if Aegis are important. Now there exists explicit each preserving smoothing operation. Now where this any definition comes in. So let's look at it in its would place. So entropy implies not the same in all direction. Whereas the fusion means spooning out, meaning goes in filled. This can be seen as the fusion processes. So what is the basic idea of any stroppy effusion? So meaning goes Enfield. This make each pixel more like it's needless. So any stroppy diffusion makes each pixel more like those neighbours that is already similar to. Now to make this even more interesting and easier to understand. So let's say we have a similar function where s p Q has values in the range of zero and one. So if the pixel P and Q are similar, then SB Q is closer to one. Whereas if the pixel P and Q different, then ASP Q is closer to zero. We use SB Q to compute a weighted average of pixel values. Now, the new values at a pixel P is based on all its neighbours. Now this brings us to the similarity function. So the smoothing function, SPQR needs to be fun and it looks the the difference between Q and uppercase D is the maximum possible difference we can use. This will give us the following equation. Now, based on the equation, other function often use the same whereby you can only use the first one here or the second one here. Note that the key value on both determines the amount of smoothing that takes place. Now here is an example using the same function for an issue of big diffusion. The key that we use here is equal to 25. And we can see the result in the images on the right. You can see that it does preserve the information, even though it is performing smoothing. No, a high value kid gives greatest movie. But surprisingly, and in a way, good edges are still quite sharp. If you look at the images shown at the bottom from left to right. We can apply the filter repeatedly to describe this movie. Now, by looking at the images at the bottom. The second leftmost image is obtainable the one at direction, whereas the rightmost image is of the end of the three iteration. Now, when we talk about reducing noise, new ideas, can we say that any strategic vision is to mean filtering as what? East to Gaussian filtering? Now look at the images here to get an idea of what the question mark represents. He. Now let's begin bilateral filtering. So an intrepid air fusion is created to mean filtering. Let me know. Okay. So if a sympathy function is always won, we get a mean filter. Now bilateral filters modified Gaussian smoothing in a very, very similar way. One Gaussian with pixel near the source and another Gaussian with pixel that have similar intensity to the source pixel. So by natural filtering, he's applying Gaussian smoothing yet again. But in this instance they using Gaussian in two separate ways. One is to apply the weight to pixel that is near the source, and the second one is to apply the weight pixel that they similar intensity to the source pixel. Now by extending the equation in the previous slide, we would get the following equation whereby one part of the equation will focus on the space week and then the part will be the range Weight in the leftmost part of the equation will be the normalisation factor. Now that we understand bilateral filtering, let's apply the concept to a one dimensional example. Now here we have one. The EMH was equivalent to a line of pixel. So for better visualisation, let's put it as a plot where the left side of the plot is pixel intensity versus pixel position. In this slight to different mathematical equation. You should one girls in blue and one for bilateral. Now looking at both equation and focusing on the one highlighted in Orange, it is safe to see that bilateral filter aside from performing a Gaussian operation on the range, it is also performing and Gaussian blur on the space, meaning doing two things with one operation. Now that we know that bariatric surgery is based on this model. However, there is some form of difference between the two. In this slide, we are looking at governance moving. If you notice that the same goes in kernel is at play everywhere. Now let's have a look at monitoring filtering. You do the same. You put image and have a look at how they perform. The next slide. For me by filtering the kernel shape depends on the image content. Whereby affecting the output tremendously. If you were to compare this output in this slide with the previous one, you can see a distinct difference in the output for bilateral filtering. Now let's move on to part two of this lecture and cover thresholding. So what is thresholding? Now binary images only have two values zero or one. Many image processing operation make a decision. Is this the column object each? I'm interested. The result is a binary image. Pixels can have only two values as I mentioned. Zero one. Zero Being black. One being white. Binary images. Also need noise removal enhancement, etc. as previously code. The process of thresholding involves the following algorithm a dot object on a light background in a green. Choose a track value t. Consider each pixel to know if the brightness of the pixel is less than t. That pixel is the object. Otherwise, it is the background. The basic idea extends to colour defined sets of colour values that correspond to an object. In this example here, the threshold is equivalent to 96, so brightness of a pixel that is less than 86. That is the object. Whereas those days, higher than 96 is the bedroom. That does sound simple, doesn't it? Now, the value of the threshold is very important. If it's too high, megapixels will be classified as fulcrum. If is too low, object pixel will be considered as Bhangra. In this example here you can see the effect of that, where the threshold is too high and too loose effectively. Now assume there are exactly two regions with no overlap in the brightness. Can that be true? Now let's look at the rules. If the user chooses t for each of a set of images, there is no guarantee the result will be consistent. So automatic methods choose a threshold based on image properties, and how to do that is by using histogram. Next explore further. Now let's dive in into a debt threshold. One of the themost adaptive thresholding known in the image processing community is known as Watson thresholding. Assume histograms are bimodal. Two regions can be separated by one threshold. Think of the histogram as made off to normal golden attributions by a means and to be. Now, if a threshold is wrong, he will include histogram, beans from p, e and B now P is deviation will be too small. B B's deviation will be too big. No Big East size area will be too small and be size area or be too big. Therefore, we need to find the threshold which minimises the weight that some of the variations on the two regions that threshold produce. Now, which are the areas on the histogram assigned to each region? This is small when two regions are both physically small and have no deviation. How do you perform and how to thresholding his algorithm? Consider all possible threshold values. We can see those from a five compute leap at some big with the smallest value. Now, bear in mind that a reclusive world exists that is very efficient. Now, aside from the hot soup thresholding, there's another type of thresholding also in existence called the uni monitor threshold. Now, many histogram are not bimodal. There's often only one peak, Texas mainly white with a small amount of black. So Rossini's uni modal method performs the following. Find the pig. Draw a line from there to the top of the furthest beat. Find that top of the pin. That is the furthest from baseline. That bin menu is the treasure. Now, this is illustrated the diagram on the right. No unique model thresholding can be applied to any suitable images intensity gradient, for example. Now let's use Lena, one of the most famously use image in use processing. Now the result that you see in the middle is obtained from inverting the output from the effect that image, which would usually be black and white. So here you can see the ages of magnitude. Okay. The chart on the right is a histogram of each magnitude. You can see that the frequency where says the intensity. Now that's put the two threshold limit that we just covered to perspective. So the last one, we is the result from Rosin. And the right one you talked to. If you can see, Rosen's output presents more information, but his also therefore suggesting that Grosjean's approach is far better than optimum. Now from the perspective of histogram. You can see that Rule Z perform better with histogram that is non bimodal as well as histogram. That is bimodal. Now let's look at a local adaptive method and let's see how Ansu can help the cause. So imaging conditions and object properties can vary within a single image as well as across sets of images. A histogram can be too complex for any methods assumption to be true. So how can we use hot soup to solve this? Assumptions the histogram miho and be true for local areas of the image. So by dividing the image into subregion, we can apply a fresh selection method independently to each. Now re-using the image. It was presented in the previous slide. We know that the histograms for each what because this image of bimodal, it therefore also can be applied to each strip independently. Therefore improving each region independently. In summary, today we call it median filtering. We now have a better understanding of and is tropic diffusion material filtering. We now also know what is thresholding and adaptive thresholding. As always, if you have any question, please feel free to reach out to me. For further clarification. With everyone. That brings us the end to today's lecture. Next week we'll be covering, using and processing binary images. So then take care. Stay safe and I'll see you soon. Cheers.
