SPEAKER 0
Hi, everyone. Welcome to the lecture on Introduction to Image Processing. Today we're going to cover segment and Super Pixel. Let's begin. In this lecture, we're going to identify what is segmentation, region based limitation, each based segmentation as well as super pixels. So what is it? Segmentation. When we talk about segmentation, we are referring to emit segmentation, a commentator, image analysis and computer vision. No. Why do we do it? Is to identify meaningful regions in any book. We can partition or group of according to local image properties, intensity or colour from origin images or computed values based on image operators, texture or patterns that are unique to each type of region. Spectral profiles that provide multi-dimensional image data. No elaborate system. We use a combination of properties. The reason why we perform such segmentation is for certain region that we want for further processing. For instance, we would like to take a picture of an entire scenery of a tree, but we only want to capture that tree. So we perform the segmentation to extract the tree from the entire scenery. In this image. Emission mitigation plays a vital role in many application. As you can see here. Now there are several approaches that is available to perform image segmentation. Now, many different approaches have been taken to segment problems. One of it is called clustering. Now, these six groups of similar pixels with no regard for where they are views image as an uncorrelated data. The next one is known as Region. This focuses on finding physically connected set of pixels, example of them region growing and splitting. And the last one will be each. These emphasise the boundary between region and example location. An important thing to note here. Thresholding and connected components is a form of segmentation by treats, grey colour and spatial information independently. Now let's begin with region based segmentation. So in region based segmentation, we want the smooth region in the image. We still want the pixel in each region to be similar in those in adjacent region to be different. One way to do this is to work with regions rather than pixel to famous method. Existing region growing. Spinach in region growing. It starts with a small seed and expand by adding similar pixel spin merge on the other hand splitting device region. There are inconsistent and merging combines edges in regions that are consistent. No, we didn't really. We know that it was thought with a small patch of Think so. So how does he go about his algorithm? It computes statistic about the region. Check the neighbours to see if they can be added and recompute the statistic. Keep this process repeats until the region stop growing. Simple example. We computed the mean grey level of pixel in the region. Neighbours added Even the green level is near the average. And this repeats until the region stopped growing. She's an example. So you have the first output. The second output. And it. Know how the spleen, which we're left to speak for us. We start by taking the whole image to be one region. We compute some measure of internal similarity. If this indicates there is too much verity, we divide the region. Repeat until no more splits or we reach a minimum region size. Now we do need some details. For instance, how do we measure severity commonly? Standard deviation is how do we determine whether to speak or not? Thresholding is easy. How do we split regions? Quite trees. The common method used. And if you haven't heard before, this is how quite trees work. Now when you're performing Sleeping, we'll use the tree image again. Split based on intensity. Could use something else if you want to. Speaking based on static deviation with a threshold of 25. Now split using poetry with a maximum of five levels. Now, once the split is done, you need to start merging. So splitting gives us the following regions that are small, consistent or both read to many regions as edges and ones may be very similar. We can now combine edges and region to make bigger ones. So merging things place we much to regions if they are adjacent and similar need a measure of similarity can't compare the mean grade level or use technical tests. Now repeat the merging process until you can do no more. Here's an example of why we consider merging Edison Region two regions on merge. If I mean Greenly, I will defer by less than 25. This leads to less regular shit regions, but they are larger and still consistent. Now let's look at each B segmentation in particular.

UNKNOWN
What this shade.

SPEAKER 0
Now for each based segmentation, the region based method focussed too much on region. That's the question. So each based segmentation takes a different route to segmenting here. Each represent that discontinuities in image intensities. Region should then be areas without edges and should be bounded by aegis. One class of each based segmentation uses what? Not many of you who can still remember your geography classes. Me Remember that in geography what the shit is a reach which divides rainfall into basin on either side. Now catchments in images. We can view the gradient image as the three areas of high gradient, a high point of the terrain catchment basins. A region in the image watershed are the lines dividing them. Now we don't have to use the usual intensity gradient here. Gradients can be computed from hue. If we want to know any value that is low within a region and high at boundaries, could be you. However, using gradient is the common. Now here's an example of great is in highlight aegis. Now let's see what happens when we start emerging to find regions. There you have it. Now watershed in images. We stand by finding image gradients. And we know from previous lecture there is a formula to capture the gradient of an image. So we can use methods like Sobel operate this way, we can compute the gradient magnitude. Now these can be viewed as a tree determine. We then slowly fled to Turin. Now flat areas of the image become areas of low gradient. So our valleys in the Turin now ages in the image of high gradient, and so are ridges in the Turin. Now let's dive into the algorithm for watershed. So since we're dealing with pixel firstly, so the pixel from low to high. Now for each pixel do the following. If its neighbours are all unlabelled, give it a new label if it has neighbours with a single label. It gets that label. However, if it has neighbours with two or more labels, it is a watershed. Now, this is the very basic version. It has certain problems in that it can give thick watershed rather than fine lines. It is sensitive to noise and so it can generate lots of small regions. However, it does show the basic idea. Now let's use this example to aid with our understanding. To begin with, we know that we need to start the pixel from low to high. Then for each pixel we need to do the following if its neighbours are all unlabelled. Give it a new label. If it has neighbour with a single label, it gives that label if it has neighbours with two or more labels. It is one to hit. There you have it. A watershed algorithm implemented in a flash. No competing. A water based segmentation can be very efficient. It is possible to implement it in a big or end time location, where end is the number of pixels. Since it takes a big or end time to read or write an image. This is a good SC gig in most situation. To implement watershed. We need to start the pixel. They need to be salted from highest to lowest gradient. Something is big, all notation and lock in. So how do we get in big or in algorithm? So. Shopping in linear time. In any situation where we have a large number of values and those values are drawn from a smaller set of possibilities, we can sort in linear time with a been solved. How many of you guys remember being sought from your first year? So make a bin a lease, a Q Is that for each possible value for each item? Put it in the appropriate people. Once that is done, the items are now sorted. Now let's apply an origin image to this. Segmenting the streaming. Now, the basic algorithm has been modified to avoid the effects of noise. The gradient has been quantised to remove small variation above a threshold water level. Normal new segments are introduced.

UNKNOWN
As the water rises.

SPEAKER 0
Watershed can also be applied to some greyscale images directly. For example, in many medical and biological images, the regions are dark or light regions against a light or dark background showing how good and effective what they say is. Now let's have a discussion on segmentation in Super pixel. Segmentation has motivate the development of so many useful things. But segmentation is poorly defined. It is trying to achieve meaningful, semantically correct results without knowledge of the application domain is optimistic and best segmentation methods really just divide the image into smaller regions. So. Let's accept that and forget the semantics. Do you think? Here's where superPACs are in. One of the techniques they famously use is called simple linear activity clarity. It's a high quality, compact, nearly uniform, super pixel, simple efficient algorithm based on K means clustering. Only parameter is number. So the pixel required here represented as key. Now let's walk through the five steps of ASL. I see. First initial clusters had the pixel three in that is so image has an pixel unique case of a pixel. Each super pixel is roughly square area of roughly in the white key pixels. Now it's a book because it is roughly square root of and over k by square root of a.k.a. So x is equal to square root of end over key. Set two move centres to the position in a tree by tree window with the smallest intensity or colour green. Now move centres away from edges onto flat. This area available only a small move. These are still initial positions. Step three Compare each pixel to all class centres within two x pixels and assign it to the best matching centre. Now best matching here equals nearby and Simulink. Now distance measure is some of colour distance and image plane distance. You can see a relevant people on moodle for detailed. So therefore we compute the cluster centres as mean colour and position of the pixel belonging to each cluster. Last step. Step number five. Repeat that three and four. And the total change me to position. And Kylo said this is below a tracker all for a fixed number of items. This slide shows you the effectiveness of SL by C evaluated on severity of peak setting super pixels versus variation of values between any of living cells. Proportion of object boundaries. Monk Maxillary Secondary. Example image on the brain mitochondria in. And where segmentation meets each detection. Interesting question that you think. Now, if you would like to give this a try in MATLAB, he has a snippet of the algorithm. More details can be found in the link below. I find. In summary to this lecture, we call it What you say imitation, what Eastern Region basic imitation, as well as each piece imitation. We also look at an alternative of segmentation called super pixels. As always, if you have questions, you know, find me. And with that, everyone, that brings us to the end of today's lecture. Next week, within an hour and a half, transform frequency to me will then take ecstasy. I'll see you guys. Cheers.
