SPEAKER 0
Hi, everyone. Welcome to Introduction to Image Processing. Today's lecture we're going to cover on interactive methods and compositing. Let's begin. In today's lecture, we're going to defy what is life way algorithm blending images as well as geometric transformation. We begin our lecture by looking at life way algorithm. Compositing is a process of taking several images, segmenting out certain objects in those images and overlaying it in another image. Take this image as an example where you have various pictures here taken from other images and overlaid in an image which shows the scenery of Mars. Copies of the extract Spirits using intelligent scissors, for example, in Photoshop. Here you can see two images, first converted into a binary image whereby the information in the binary image will be used to extract that information in the original image, which is then combined together to produce one new image which is shown here on the right. If that is his. This is a technique known to extract information of the boundary so that you can extract or segment out the object in accordance to the shape. So how does it digest Caesar's work? We need a path from the sea to mount that follows the object boundary as closely as possible. Define a path that stays as close as possible to the edges. Quantify the costs of including each pixel in the path. Each pixel had low cost and find lowest cost path from seed to closer. To implement maintenance. He. There is a bit of ground theory that we need to understand. So let's dive into this. Treat the image as a graph. Note for every pixel link between every adjacent pair of pixel and the costs for each link. The cost combined several each measures. So in a place in zero crossing gradient magnitude gradient direction is huge. Now P is an hb1q to mean each two with a higher gradient in the gradient direction to be similar at P and Q. Once all the information is known, we then find the minimum cost path between Setpoint and every point in the growth. Output is a pointer at each pixel indicating the minimum cost path back to the seat. As the mouse moves over the image, the path from the current pixel is followed back to the seat X. You can see the diagram on your lower rate. Every point is pointing back leading back to the seat. Now let's break down the way algorithm step by step. First, initiate court costs to infinity. Setting P to the SETPOINT cost B equals zero. Then we expect P. S points for each of peace neighbours Q that are not expended. You set costs. Q To the minimum costs of P Plus CPQ costs. Q. Next, we perform a check. If Q's cost change, make Q point back to P. Put Q on the active list. If not already dead. Now, once we have done step one and two, proceed to step three, set R to not with minimum cost of the active list. Repeat step two for P equals two R. Now, while you are trying to understand the algorithm and make sense of it will be good as well to monitor the diagram on your left. So go back a few slides and start from the beginning and look at how the diagram changes as this court is it. Now, this is an example representing life when you take a look at how it works now. Bear in mind that every number here is treated as a pixel value and it points back to the seed. Now let's move our attention to cooling. So what is cooling? The two allows multiple seat, but all seats must be manually selected. Complex object may require many seat points. Now you can detect seat points automatically. How do you do that? As the user reps the object, the early sections tend to and need to be fixed past segments that remain fixed or will end because some movements are considered steep. New seat points are created at the ends of stable segments. Now let's look at the effect of cooling. The image on the left. Presents a basic version where several men will see points are needed to capture the heat. However, with cooling, two seats are enough and the rest are created automatically. Therefore giving an indication that by adding the cooling effect into your life, you helps with the seat creation. As well as obtaining the actual shape of the object. Let's look at interactive dynamic training. Some objects have stronger edges. Net I was if the desired edge is weaker than in you buy each. Then the pilot jumps over to the stronger each. Now train the gradient magnitude to desire, the weaker each. Use a symbol of good path to train regen magnitude. Example Change the weighting of the gradient magnitude to now a bit simple as path moves along the desired each. Now here you meet allow user to enable and disable training as needed. By doing so, this will optimise your livewire and make it even more intelligent. In detecting an object's boundary. He. This slide shows several examples of applying knife y algorithm to real life images. Now let's move forward to understand blending of images. No. One of the good things about possessing is you are able to produce a new image by blending one or more images together. Just putting prints next to each other isn't enough. Boundaries are clear and you can attract the eye. As you can see in this example, on the lower right. So now how do we ensure that the meeting of two agents when blending two images are not visible to the eye? The solution may lie in a technique called alpha blending filtering by applying these formula to the two images that you see here. We are able to ensure that the meeting of the two images ages in the resulting image is not that obvious to the eye. Take a look at the image at the bottom left to see the effect of this technique. Was reference to the formula in the previous slide. It should be noted that setting out for the simple averaging is the key to the entire process working well. In this example here you can see that Alpha is set to 0.5 in the overlap region. Now let's look at distance, transfer it aside and non-negative integer each pixel giving the distance from that pixel to example nearest black pixel. Take a look at the example given below. A range of distance measure exists characterise the shape of a binary can be used to guide blending. Now let's revisit our setting of Alpha once more. Here we're going to incorporate distance transform into our equation. Now, in order to do this, we're going to get the centre scene. Okay. So the two images that you see on the top is actually the result of applying distance transform to the actual image. The alpha here is a logical distance from one over distance transform to. Now each pixel uses the image. Who said this scene is the closest to. The method presented in the previous slide is a good approach moving forward. Nevertheless, external factors may influence its result. Therefore, giving us not the most optimum result that we can produce. External factors such as the effect of growth. As you can see at the bottom right here. So how do we factor this in in order to set the alpha? We take each state a centre within. The formula is presented here where distance transform. One is divided by the sum of distant transform one plus distant transform to. To obtain a good blindly image result. The effect of window size plays a big role. This is shown in the slide Q where two different window sizes are used. If you look at the blending image results, the image on the right seems to be clearer than the image on the left. Furthermore, the ghosting effect doesn't seem to be so obvious in the image on the right. Here we are using a much more smaller window size. As you can see, the image on the right is more clearer. However, it is more clear as well. The aegis that defines the two images is blended together. Now a good window size determines how good your blending of two images is. The optimal window size leaves the blend smooth but not ghosted. Therefore, to a white Sim's window sizes should be size of the largest prominent feature. Whereas to a white ghosting window size should be less or equal to two times the size of the largest prominent feature. Now let's look at geometric transformations. The transform we have look so far. Effect the content of the imagery, but leaves the spatial arrangement of the pixels in take now geometric or rubber sheet transformation do not. As you can see from the example here now, Geometric transformation has two stages. One spatial transformation of pixel coordinates and the other assign intensity values to new pixels. No in spatial transformation coordinate transforms. I express as follows whereby x y can be calculated as medium by two, W divided by two, which shrinks the image to Harvey size in both dimensions. One of the most common is the affine transformation process whereby you can see the formula given here. Now this a fine transformation scale will be translate or shear an image. Now those can be applied separately, or a sequence of transformation can be applied by a single tree by tree matrix. Take note of the following and the order in which transform apply methods. Here. This slide presents this different transformation mean it's a fine matrix, the relevant coordinate equation and examples of how the resulting image will look like. So how do you apply transformation? Forward mappings scanned the input image. Compute the new position of each pixel in the output image. What do you do if two input pixels map to one output pixel? Some output locations may not be allocated a pixel at all. Inverse mappings in the output image. Use the inverse of the transformation to work out which point in the input image mapped to each output pixel location. Use image interpolation to compute a new output pixel value from nearby input Pixel value. Now let's get a better understanding of what image interpolation means in general. Transform pixel coordinates will not met neatly onto the coordinates of a regular rectangular array. We must use the nearby input intensity values to compute a suitable output value and X-Y. Look at the graphical representation presented in the middle of the slide. For better understanding of image interpolation. Image interpolation can be done in three different ways. The first is known as the nearest neighbour interpolation whereby you just pick the nearest pixel value and use that. The second one is by leaning into pollution. When you take the fall, nearest neighbours and assume intensity varies linearly, then apply the following equation. The last is known as the cubic interpolation, where you take the 16 nearest neighbours for a cubic. So you will get the following equation. Now becoming interpolation is the standard that is used in image processing. It's mostly used in software such as Photoshop. Now, this slide presents to you an example of using the three different emission of pollution techniques mentioned previously. Take a look at each of these three image results and be the judge on which interpolation method. Produces the best result. In summary, in this lecture we have covered what is Life Wyatt algorithm. We now have a better understanding of blending images and we now also have a better understanding of geometric transformation. As always, if you have any question, please feel free to reach out. For further clarification. And we that brings us to the end of today's lecture. Next week, we will look at the finale of this module and a quick revision of what we have covered in the last few weeks. Till then, take care, everyone. Stay safe and I'll see you also. Cheers.
