SPEAKER 0
Hi, everyone. Welcome to another lecture on Introduction to Image Processing. Today, with a look at the whole image method, let's begin. So what? Other than alcohol? Today's lecture. Today we going to define why he still grand histogram equalisation in terms of theory and practical image making with colour, histogram, histogram intersection and using histogram for object allocation. Why he's so green. Let's answer this question together. So the histogram of a digital image with grey levels in the range of zero to Alma is one is a discrete function here. And you can see from this mathematical formula the representation of each of its variables. Histogram poets useful global information about the image, use computation of some image properties and can be manipulated to improve the image. Now, when we talk about histogram, we will note we try to go with a normal X histogram. Now the meat, the reason of this is that is because normal histogram is much easier to manage because the bins in a normal life is a gram sums up to one here. Each bin gives the probability of the corresponding grain level appearing in the image and the probabilistic interpretation is available. In contrast, enhancing an automatic threshold is a discrete function. To remember is the following where n equals two width times height is a total number of pixels in the image. In other words, is the dimension on the. Now let's look at the functionality of it. So histogram can be applied to adopt an image or a light image. Now take note on the histogram of the image in the light image. Now these represents a low contrast. Whereas this represents a high contrast. Take note of its distribution. Now in order for us to have a much more standardise distribution of histogram, this is where histogram equalisation comes in. So the popular he still radicalisation is to improve the contrast of an image is to transform an image in such a way that the transforming image has a nearly uniform resolution of pixel values. Here we are referring to intensity more general than linear piece. By contrast, touching the in colour. In the earlier chapters, no parameters to specify apply a transform that makes the output histogram flat. Now. How do you perform it? He's a grand principal. So you map out an input histogram are onto a new histogram. Assume R has been normalised to the interval of between zero and one with our equals zero representing black and ah equals to one representing white. Now, what do we need to know about history of transport? We need a transformation function to satisfy the following conditions. This means it is possible to invert the process. It also gives us the relationship, allows the derivation of histogram equalisation. Now remember as intensity transform. But now apply to all the pixels in each bin of a histogram. So that's what I'm going to do. So in order to do a historical ization, we need to perform the following mathematical formula. So we need to map out the distribution of the bins and fair distributed. So that gives it a much more standardised distribution of the intensity for each bin. But look at this in greater detail. So in Gonzalez in Woods notation, let P, R, and S denote the probability density function of random variables are and ask respectively. If parity are known, then the probability is the function of off the transform variable can be obtained. So by applying this which is the histogram transform. We are actually going to implement this as well. So let's have a look. Now, if we choose as a transformation function, the cumulative distribution function or in CBF, TR depends on PR, but the resulting PS is always uniform. Now this is how you implement a CDF. So we have a discrete histogram, not a PDF of a continuous random variable. The probability of a occurrence of a grey level in an image can be given as such. Now the transformation function is as follows. And by applying this in output, images obtained by mapping each pixel with a level arc in the input image into a corresponding pixel with level ASCII. Now, let's put this into perspective. By looking at the following practical example. So this is the algorithm to perform a histogram equalisation. Compute the curve of an image. Okay. For each pixel in the input image, the corresponding output pixel intensity is calculated by using the CDR as a lookup table. CDR values will be in the range of zero one scale. The equalised image to see the range supported by the output image format. Now the histogram of the upward revision will be approximately uniform. Now let's put it into an example. Consider 64 by 64 pixel 3b8 grey level. Okay, so you have the histogram of their respective image and you tend to produce or you tend to calculate it CDF. And by knowing it after that you are able to mapping out accordingly basis occurrences. Now this basically rounds up the venues on which your bins are going to be normalised. Now let's use a few charts to help with our understanding, shall we? The chart on the left is the equal histogram. The child in the middle is actually the CEF produce calculation which had the TRT scale back to 027. Now from the CDF we're going to compute a much more normalised distribution of the beans. And this will produce the equalised histogram affecting the intensity in the output in. So when you apply the histogram equalisation. Method onto an image. This is what you get from a docker. You get a much more better contrast from a lighter. You get Docker contrast, meaning a much more better. You can see that both of these two image looks about the same because of histogram acquisition. So by performing the histogram equalisation, what you're going to do is now you're going to make low contrast images real balance in this contrast as a result of applying his vocalisation. The high contrast image will become well contrast as well from applying the same histogram equalisation. So in the end, both of a low contrast and high contrast, you're kind of standardising out the contrast Egyptian so that it comes in a well-balanced.

UNKNOWN
Contrast upper image.

SPEAKER 0
Now each of the four transformation below use a different transform tune to the input histogram. As you can see, the numbers here represent the respective. Transformation. It takes place. With every method available. That's always tricky with Mrs.. His rehabilitation looks well when the input images don't have large, bright or dark areas. And also they are not too noisy. However. Here, the bright sky has dominated the process. Equalisation has introduced an artificial boundary between sunlight and the sky, but not enhance the tree people. He as well. You see, there's a break, some form like a break in the sky and resulting in additional noise. That wasn't a day in the originating. Here. The upper right area of interest is in homes by the north in the upper income region is also obvious.

UNKNOWN
Here you go.

SPEAKER 0
So look at Huntsman. If some areas are much darker like that than the rest of the image, they may not meet it hard enough as it adeptly, treacherously. Local histograms may be better suited to equalisation. So here you see an image of a tungsten filament. A global equation gives artefacts, whereas a local equalisation gives better output. Okay. Here you can see from the globalisation additional regions here are becoming darker, which doesn't exist in the original image. Whereas the local equalisation does not cause these to appear. Now in terms of medical education, in my mind, he studied this play an important role. So he's to the specification is a related method which transformed the image histogram so that it matches a target histogram. So this is an original histogram before graduation. This is a histogram after the funding equalisation. Now in order for you to do matching, you need to perform histogram specification. So let's look at this in more general. So you had the input histogram and you have the target histogram. In order for you to do the P signal specification. We need to do the transformation. Okay. And from the transformation you would produce the resulting output that would be able.

UNKNOWN
To perform the match.

SPEAKER 0
Now that's the image making with coloured histograms. Now story A few images from large database is no easy feat. Given the light image at their base final image containing the horse. So we will focus on images, images. But many of the problems and methods discussed extend to medial pieces to. So this text based approach is available. So annotation relevant words, phrases are added to each image. Retrieval is via text search, but on a T-shirt is subjective, Labour is unnecessary. So for instance, this image here you have a mother, a child vegetable, yellow green bubble is too many annotation. It's hard to distinguish one over the other. So this brings us to content based retrieval indexes. The image database and visual features each state such as colour, shape, texture. Now queries I express in those terms obvious visual examples. So simple approaches compute metric distances between the query image within each image in the database. Now advanced Approaches uses artificial intelligence, machine learning, and many other interactive approaches. Some simple measures and other strategies can be very, very useful. So we performed content based retrieval. This is what we do. You have a metadata that holds all the records and you represents the distribution of this metadata in the imagery. All these are stored in the image database. So in order for you to extract which image that you want, you need to have said the keywords here that you would need to type in so that you'll be matched with the relevant metadata for each record. Therefore, putting on the accurate imagery that you are looking to find. So let's look at colour histograms. So choose a colour space. I rgv. Now divide the axis to create a reasonable number of division, trade of detail against memory and computational time. Now build your histogram and normalise it. If the image of different sizes or colour resolution. So for instance, we are taking a rabbit here and we are distributing each colour according to the respective beads. Now. Why Colour histogram? Many of you want us images with similar colour distribution looks similar. So colour distribution equals colour histogram. Now let me talk about colour histogram. Colour correlates well with class identity. Human vision works hard to preserve colour consistency, possibly because colour is useful. Therefore histogram is use is because they are invariant the translation and rotation. They change slowly as new direction changes it slowly with object size and they change slowly with occlusion. So colour histogram summarises target objects quite well and should match a good range of images. Now let's explore this further. So when we create a colour histogram, it is representing the colours of the shape of the image. So for instance, you have two images here, but one of the rabbit has different orientation with the other. However, if you notice the colour histogram of blue has similar colour distribution. Therefore showing us that both of these images rabbit as compared to the technology here which is a top is. So how do you compute this distance in terms of similarity? So common then metrics used is the famous computed distance. Okay. And that is what people tend to use. Now, this is to ensure how far apart the two points are in terms of finding its correlation. No. Some problems exist. Colour, quantisation noise and or different camera responses can give similar images. Very different histogram. Take a look at this example here. You have two topics having same orientation in both image. However, the histogram generated from it are different. So he's on a resolution, meaning many more bins to increase for resolution, which is very, very expensive. The illumination may be coloured the same object, major differences of RAM and a different lighting. Further to that colour histograms ignore spatial information more and ones method takes special shit into account, but the comparative simple image processing methods and representation methods covered so far can do useful things. Oh, let's do it. Histogram Intersection. So what is histogram intersection? Now it measures how much the quality may be present in a target image and vice versa. Obtaining a target histogram can have a larger value than the corresponding reading and vice versa. Let's take this as an example. Here we have two histogram here. You're trying to check the intersection of. How much do the two reposition overlap? That is the question that you're trying to find out. In the first histogram in this section paper by Bala and Swine 1981, a database of 66 colour histogram with the day to images. Now recognition rate was almost 100%. Now Bala and Swan use component colour axes as shown here and match images under range of condition conditions such as normal condition varying u vary in image resolution, occlusion vary in beam resolution.

UNKNOWN
And varying in light intensity.

SPEAKER 0
So how was the method based on different conditions? So it was good until images are very small and not back when object only partially visible. However, overall it performed quite well. Making it one of the most used approach to this thing. Now let's use histogram for object location. So making a whole image isn't always appropriate. Example If the time of day is only expected to fill part of the image and you want to know where it is, for instance, where's the rabbit? Now, here's where rigid object based clothes comes in. We know the rabbit is more hungry. Divide the image in the windows and see how great each window is. Highlight pixels in the image that are similar to those in the query and look for regions with lots on this. Here is where you kind of say yes to similar colours and note the dissimilar colours. But the image is usually much bigger than the region. Other objects in the image may be the same colour as part of the clay object. So some colours are not reliable use. If you're looking for a Z, Brian might look for white pixels. Here's where the histogram measure comes in. Compute the ratio of corresponding model and images of Grimm means. If the image has many more pixels of a given colour, r.g is small and that colour is not useful. However, if the model has more args one and that colour is useful. The greater the value of r.g, the more valuable the colours represented by being G. Consider each image pixel in that pixel next to histogram being key. Replace the pixel value with a grey value are key. Now this is still image processing. We have processed an image to create an image. The pixel values are related to the likelihood of that showing that target. Now hear how higher average brightness at places where the rabbit is, whereas low average brightness and location where the rabbit be not noted. Now regions with high average brightness are likely to contain the rabbit. It's more complex, but still a histogram matching approach will be able to identify it. No. If you guys can remember, we have seen back projection before. Remember, skin shows a very clear peak and narrow reach in u V. Now you guys know why histogram is commonly used to represent. So in summary, today we kind of identify why he's where we kind of have a better understanding of histogram equalisation into what is jewellery practical. We also now know image matching with colour, histogram, histogram intersection and using histogram for object notation. As always, if you have question, please feel free to reach out to me for clarification. And with that brings us to the end of today's lecture next week and then college segment and Super Pixel. Until then, everyone take care. Stay safe and I'll see you guys soon. Yes.
