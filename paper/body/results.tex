\chapter{Results and Discussion}\label{ch:results}
% Explaining how your software was tested (using different datasets or in different environments), statistical evaluation of performance, results of user evaluation questionnaires, etc.
The results of each of the three models will now be compared, with discussion on both the qualitative answers and empirical evaluation where appropriate. The discussion will begin with the model trained using \acrfull{mlm}, will be followed by the document store and \acrshort{gpt}-3.5 Turbo model, and will end with the fine-tuned T5 model using the Natural Questions dataset. For ease of comparison, the same three questions will be used as a prompt for each model.


% ---------------------------------------------
\section{\acrlong{mlm}}\label{sec:results_mlm}
\subsection{Empirical Results}
A \acrshort{gpt}-2 model was fine-tuned using \acrlong{mlm} as per Section \ref{sec:methodology_mlm}. The validation metrics can be found in Table \ref{tab:results_mlm}, with full training results and access to the Huggingface repo available in Appendix \ref{ch:appendixA}.

\begin{table}[ht!]
    \centering
    \begin{tabular}{l|l}
        \textbf{Metric} & \textbf{Value} \\ \hline
        Training Loss & 3.3968 \\ \hline
        Validation Loss & 4.0711 \\ \hline
        Perplexity & 58.62 \\
    \end{tabular}
    \caption{Training Results for \acrshort{gpt}-2 Using \acrshort{mlm} Fine-Tuning}
    \label{tab:results_mlm}
\end{table}

The early-stopping callback was activated after almost 7 epochs, due to the validation loss failing to fall sufficiently further. The training loss and validation loss both finished the training process stubbornly high at 3.40 and 4.07 respectively. This is demonstrated graphically in Figure \ref{fig:results_mlm_loss}. The model had the potential to decrease the training loss further, but the validation loss reached a plateau, indicating possible overfitting to the training data. Furthermore, the associated perplexity value of 58.62 indicates the model's difficulty in accurately learning the context and semantic meaning of the text, or at least in learning topic-specific information as opposed to textbook-specific information.

\begin{figure}[ht!]
\centering
\caption{Training and Validation Loss at Each Epoch using \acrshort{mlm}}
\begin{tikzpicture}
\begin{axis}[xlabel={Step}, ylabel={Validation loss}]
\addplot table [x=Epoch, y=Train, col sep=comma] {images/train_loss_mlm.csv};
\addlegendentry{Training Loss}
\addplot table [x=Epoch, y=Val, col sep=comma] {images/train_loss_mlm.csv};
\addlegendentry{Validation Loss}
\end{axis}
\end{tikzpicture}
\label{fig:results_mlm_loss}
\end{figure}

There were a number of factors causing the model's poor performance. Firstly, the model had only one textbook, consisting of 1000 pages, which included specific figures and interrelated chapters. Cleaning the dataset to remove these nuances might enhance training results, but it would require considerable effort and time constraints prevented this. Furthermore, the very poor results above did not justify further investigation. In particular, the training loss exhibited slow and limited improvements, indicating significant difficulties in learning from the training data.

\subsection{Qualitative Output}
To evaluate the model output and confirm the empirical results discussed above, a series of questions were given to the model.

As can be seen in Figure \ref{fig:results_mlm_ex1}, the model answers using natural language which is grounded in the domain/context of the training data (textbook). However, unfortunately, the answer has several issues. Firstly, the model has failed to grasp the concept of \acrfull{pca}, and has given a vague and incorrect answer. Secondly, the answer contains words (tokens) which are not present in the training data (e.g. ``NONAMBOW''). Finally, the model has not given a succinct answer and has been cutoff by the 150 token limit (introduced for demonstration purposes). 

\begin{figure}[ht!]
    \begin{itquote}
        \textbf{What is principal component analysis?} \\ NONAMBOW: *The term principal component analysis is defined in the context of classifying a continuous graph as a matrix-by-matrix function of spatial and temporal dimensions. This approach is equivalent to a function of all principal components in a binary variable, but is more detailed. Lista: * Principal component analysis does not involve discrete spatial data, and spatial aspects of a continuous graph, but simply spatial images. NONAMB, M: *Principal, M, and T is the probability of defining a function from the binary variables. NONAMB: *Principal function analysis does not depend on discrete spatial data, but consists of discrete spatial features (such, pixels and color pixels
    \end{itquote}
    \caption{Fine-tuned \acrshort{gpt}-2's response to the prompt ``What is principal component analysis?''}
    \label{fig:results_mlm_ex1}
\end{figure}

A second prompt asking about meaning of the acronym \acrshort{rgb} is shown in Figure \ref{fig:results_mlm_ex2} and demonstrates a more promising response. The model provides a succinct natural-sounding answer grounded in the context of the training corpus but fails to give a correct answer. It also suffers from `hallucinations' (see Section \ref{sec:background_implementations}), providing a misleading colour range.

\begin{figure}[ht!]
    \begin{itquote}
        \textbf{What does RGB stand for?} \\
       For example, on screen a black square with the color range 0, 1, 15, 60.
        Then you can see on retina, black squares are always a rectangle but there is no color in those
        black gray pixels.
    \end{itquote}
    \caption{Fine-tuned \acrshort{gpt}-2's response to the prompt ``What does RGB stand for?''}
    \label{fig:results_mlm_ex2}
\end{figure}

It is also pertinent to ask a question which is not related to the training data, to observe how the model responds. This final example output is given in Figure \ref{fig:results_mlm_ex3}, where the model gives an irrelevant, incorrect, and poorly formed answer. Additionally, it contains specific tokens from the training data, such as references and figure numbers. While the model could be improved by cleaning the training data to remove these artefacts, the model is still highly likely to respond poorly to irrelevant questions.

\begin{figure}[ht!]
    \begin{itquote}
        \textbf{Who is prime minister of the uk?} \\ 
        (). These two concepts of  representation are based on the representation of a set of  subset of an integer or the set of elements defined in terms of [17] [20]. The function of representa d is  the sum of every subsets of  representatives in a set. All subset  of an integer or set of elements is represented in an integer. EXAMPLE 54 Example 54a.1  (a) f (b)  (c)  (d)  (e)  (f)  (g)   (h)  (i)  (
    \end{itquote}
    \caption{Fine-tuned \acrshort{gpt}-2's response to the prompt ``Who is prime minister of the uk?''}
    \label{fig:results_mlm_ex3}
\end{figure}

\section{Document Store With \acrshort{gpt}-3.5 Turbo}\label{sec:results_gpt_turbo}
The framework using a document store and \acrshort{gpt}-3.5 Turbo has no evaluation metrics, as the model has already been fine-tuned and is not available on open-source platforms. Therefore, only the qualitative output of the model will be discussed. The first question about \acrshort{pca} was posed to the model, with the response given in Figure \ref{fig:results_gpt_ex1}.

\begin{figure}[ht!]
    \begin{itquote}
        \textbf{What is principal component analysis?} \\
        \acrfull{pca} is a statistical technique used for dimensionality reduction. It identifies the dominant subset of orthogonal directions in a feature space and discards the components that contribute little variance to the data. By using only the significant components, \acrshort{pca} can accurately approximate and describe the data in a more compact way. It is commonly used in multidimensional problems, such as analyzing digital images, where there may be tens, hundreds, or even thousands of variables. \acrshort{pca} calculates the principal axes, which are uncorrelated variables
        that maximize the variance of the data along each axis.
        
        To construct this answer, I used the following documents:
           
        \begin{enumerate}
            \item Fundamentals\_of\_Digital\_Image\_Processing\_Textbook->Page(s)274/275:  Depending on the precise context, there may be several closely related reasons for doing  \acrshort{pca}, but...
            \item Fundamentals\_of\_Digital\_Image\_Processing\_Textbook->Page(s)265/266/267:  To grasp the essence of \acrshort{pca}, suppose we have a large sample of M children and that we wish  to ass...
            \item Fundamentals\_of\_Digital\_Image\_Processing\_Textbook->Page(s)267/268/269:  Weight  90.57  73.43  w 1/4  69:42  Weight  1  0.57  Height  73.43  182.99  h  1/4  173:25  Heigh...
            \item Fundamentals\_of\_Digital\_Image\_Processing\_Textbook->Page(s)278/279/280/281:  When we carry out a \acrshort{pca} on this ensemble of faces, we find that the eigenvalue spectrum  dies off ...
        \end{enumerate}
    \end{itquote}
    \caption{\acrshort{gpt}-3.5 Turbo's Response to the Prompt ``What is principal component analysis?''}
    \label{fig:results_gpt_ex1}
\end{figure}

The response is excellent for several reasons. Firstly, it succinctly provides an accurate answer using the sources. Secondly, the framework (outlined in Figure \ref{fig:initial_framework}) enables the specific sources to be referenced so that any user/student can conduct further reading. Thirdly, and finally, the answer is grounded in the context of computer vision using a combination of the provided sources, such that the model does not suffer from `hallucinations' and its output can be trusted.

The second example regarding the \acrshort{rgb} colour model is shown in Figure \ref{fig:results_gpt_ex2} and demonstrates a good response, but has room for improvement. 

\begin{figure}[ht!]
    \begin{itquote}
        \textbf{What does \acrshort{rgb} stand for?} \\ 
        \acrshort{rgb} stands for Red, Green, Blue.
        
        To construct this answer, I used the following documents:
           
        \begin{enumerate}
            \item Fundamentals\_of\_Digital\_Image\_Processing\_Textbook->Page(s)28/29:  \acrshort{rgb} (or true colour) images are 3-D arrays that we may consider conceptually as three  distinct 2-...
            \item Digital\_Image\_Processing\_Textbook->Page(s)408/409:  In the \acrshort{rgb} model, each color appears in its primary spectral components of red,   green, and blue....
            \item Digital\_Image\_Processing\_Textbook->Page(s)412:  As we have seen, creating colors in the \acrshort{rgb}, CMY, and CMYK models, and chang-   ing from one model ...
            \item Digital\_Image\_Processing\_Textbook->Page(s)409/410:  The cube in Fig. 6.8 is a solid, composed of the (  )  28 3 colors mentioned in the preceding para...
        \end{enumerate}
    \end{itquote}
    \caption{\acrshort{gpt}-3.5 Turbo's Response to the Prompt ``What does \acrshort{rgb} stand for?''}
    \label{fig:results_gpt_ex2}
\end{figure}

While the model provided a correct answer, it stopped short of providing any additional detail, in part because of the phrasing of the question. Additionally, the model could have answered the question using only the first two sources, as the third and fourth sources contain no additional useful information, meaning that tokens were wasted which incurs a higher financial cost through using the \acrshort{api}. Consequently, the framework could be improved by either increasing the cosine similarity needed to use a section of knowledge, reducing the token limit, or reducing the number of sources passed to the model.

The third and final example is the irrelevant question regarding the UK Prime Minister. The output in Figure \ref{fig:results_gpt_ex3} demonstrates how the framework/model can correctly identify questions which are beyond the scope of the chatbot's topic and respond appropriately.

\begin{figure}[ht!]
    \begin{itquote}
        \textbf{Who is prime minister of the uk?} \\
        I could not find an answer in the text I've been provided, sorry! Please try again.
    \end{itquote}
    \caption{\acrshort{gpt}-3.5 Turbo's Response to the Prompt ``Who is prime minister of the uk?''}
    \label{fig:results_gpt_ex3}
\end{figure}

\section{Document Store With Fine-Tuned T5}\label{sec:results_t5}
\subsection{Empirical Results}\label{sec:results_t5_empirical}
The third and final model to discuss is the T5 model fine-tuned for question-answering. Figure \ref{fig:results_t5_loss} shows how the training loss had a steep decline in the first couple of epochs, and continued to fall even approaching 10 epochs. The validation loss, however, steadily declined until epoch 7. A small rise and plateau occurred after this, with the early stopping callback ending the training after almost 10 epochs. There is no clear sign of overfitting from this data, with the training and validation loss both below 1 and close together. 

\begin{figure}[ht!]
\centering
\caption{Training and Validation Loss at Each Epoch for Fine-Tuned T5}
\begin{tikzpicture}
\begin{axis}[xlabel={Step}, ylabel={Validation loss}]
\addplot table [x=Epoch, y=Train, col sep=comma] {images/train_loss_t5.csv};
\addlegendentry{Training Loss}
\addplot table [x=Epoch, y=Val, col sep=comma] {images/train_loss_t5.csv};
\addlegendentry{Validation Loss}
\end{axis}
\end{tikzpicture}
\label{fig:results_t5_loss}
\end{figure}

After almost 10 epochs, the model achieves excellent results. Table \ref{tab:results_t5} shows that the model achieved an average cosine similarity of 0.762 between the generated answer and the target answer, with the \acrshort{rouge}1 and \acrshort{rouge}2 scores showing that uni- and bi-grams had an overlap of 44.4\% and 38.8\% respectively. Similar results using the \acrshort{bleu} and \acrshort{meteor} metrics confirm a significant overlap between generated answers and target answers. Encouragingly, the model can confidently distinguish between answerable and unanswerable questions, with only 10.4\% of answerable questions being classified as unanswerable questions. However, there is room for improvement, with only 69.7\% of unanswerable questions being detected; the model is relatively likely (incorrectly) respond to a question which cannot be answered using the provided context. Additionally, the generated length of an answer is only 12.7 tokens, on average, indicating that the model may only produce short answers rather than provide explanatory content or reasoning. 

\begin{table}[ht!]
    \centering
    \begin{tabular}{l|l}
        \textbf{Metric} & \textbf{Value} \\ \hline
        Training Loss & 0.465 \\ \hline
        Validation Loss & 0.729 \\ \hline
        \acrshort{rouge}1 & 44.4 \\ \hline
        \acrshort{rouge}2 & 38.8 \\ \hline
        \acrshort{rouge}l & 43.1 \\ \hline
        \acrshort{rouge}lsum & 43.1 \\ \hline
        \acrshort{bleu} & 34.2 \\ \hline
        Generated Length & 12.7 \\ \hline
        \acrshort{meteor} & 0.405 \\ \hline
        True negatives & 69.7\% \\ \hline
        False negatives & 10.4\% \\ \hline
        Cosine Similarity & 0.763 \\
    \end{tabular}
    \caption{Validation Results for T5 Fine-Tuned for Question-Answering}
    \label{tab:results_t5}
\end{table}

\subsection{Qualitative Output}
While the evaluation results are very promising, most metrics are difficult to compare between different models, so the output from testing the model will provide the greatest insights. The first prompt and response is shown in Figure \ref{fig:results_t5_ex1} and demonstrates the potential for false negatives. Even though the model was provided with the context to extract a correct answer, it failed to produce an answer.

\begin{figure}[ht!]
    \begin{itquote}
        \textbf{What is principal component analysis?} \\
        I could not find an answer in the text I've been provided, sorry! Please try again.
    \end{itquote}
    \caption{Fine-Tuned T5's Response to the Prompt ``What is principal component analysis?''}
    \label{fig:results_t5_ex1}
\end{figure}

The second prompt in Figure \ref{fig:results_t5_ex2} demonstrates the model's ability to provide a factually accurate response regarding the acronym \acrshort{rgb}. Furthermore, this framework benefits from accountability, with the source referenced for the user to explore. However, this answer corroborates the discussion in Section \ref{sec:results_t5_empirical}, with the answer being short and not identifying the correct intent of the question (the meaning of the acronym). This is a consequence of the training data and relatively succinct training answers that were created when enhancing the dataset (see Section \ref{sec:methodology_data_enhancement}).

\begin{figure}[ht!]
    \begin{itquote}
        \textbf{What does \acrshort{rgb} stand for?} \\ 
        \acrshort{rgb} stands for the three primary colours mixed for display on a monitor or similar device.

        To construct this answer, I used the following documents:
        \begin{enumerate}
            \item Fundamentals\_of\_Digital\_Image\_Processing\_Textbook->Page(s)28/29:  \acrshort{rgb} (or true colour) images are3-D arrays that we may consider conceptually as three  distinct 2-...
        \end{enumerate}
    \end{itquote}
    \caption{Fine-Tuned T5's Response to the Prompt ``What does \acrshort{rgb} stand for?''}
    \label{fig:results_t5_ex2}
\end{figure}

The third and final prompt confirms the ability of the model to detect unanswerable questions, with it correctly identifying an irrelevant question given its `knowledge' base, as shown in Figure \ref{fig:results_t5_ex3}

\begin{figure}[ht!]
    \begin{itquote}
        \textbf{Who is prime minister of the uk?} \\
        I could not find an answer in the text I've been provided, sorry! Please try again.
    \end{itquote}
    \caption{Fine-Tuned T5's Response to the Prompt ``Who is prime minister of the uk?''}
    \label{fig:results_t5_ex3}
\end{figure}

\section{Costs}\label{sec:results_costs}
\acrshort{gpt}-3.5 Turbo demonstrates superior performance, but it comes at a higher cost compared to open-source models. As shown in Table \ref{tab:results_cost_comparison}, \acrshort{gpt}-2 and T5 have no outright cost for usage (aside from the running costs: electricity, hardware, setup time etc.). The only model which has ongoing usage costs is \acrshort{gpt}-3.5 Turbo. Although each query using this model is inexpensive, the cumulative cost for each module using the model may reach several hundred pounds per year. for each module that uses it, which might be unattainable for several departments. Additionally, departments would need to justify that this model is sufficiently more robust, reliable, and beneficial than ChatGPT, which is currently free \citep{ChatGPTrelease}. Note that there is also a very small cost each time a query embedding is requested (\$0.0004/1,000 tokens), but this is negligible compared to the cost of each query \acrshort{gpt}, as the number of tokens per query is very small (typically under 50).

\begin{table}[h!]
    \centering
    \caption{Comparison of Estimated AI Costs}
    \begin{tabularx}{0.8\textwidth}{p{3.5cm}|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X|>{\raggedright\arraybackslash}X}
        \hline
        \textbf{Model} & \textbf{Cost per query\parnote{Estimated cost using based on each query using 2000 tokens}} & \textbf{Cost per student\parnote{Estimated cost using based on 100 queries per student}} & \textbf{Cost per module\parnote{Estimated cost using based on 300 students in a module}}\\
        \hline
        \texttt{\acrshort{gpt}-2} & \$0.000 & \$0.00 & \$0 \\
        \hline
        \texttt{\acrshort{gpt}-3.5 Turbo} & \$0.004 & \$0.40 & \$120\parnote{Excluding the small cost of embedding students' questions} \\
        \hline
        \texttt{T5} & \$0.000 & \$0.00 & \$0 \\
        \hline
    \end{tabularx}
    \parnotes
    \vspace{-15pt}
    \label{tab:results_cost_comparison}
\end{table} 

\section{Applications}
% Write about any applications (everywhere!) and specific dependencies on gpt etc.
The framework used by the two most impressive models, \acrshort{gpt}-3.5 Turbo and fine-tuned T5, can be used in an almost limitless number of applications. Neither model is fined-tuned to work only on a specific domain, and rely solely on the input documents. In the context of educational use, academics need to only provide a few high-quality text-based documents (such as textbooks or detailed lecture notes) and the framework will chunk them into sections for use with the chosen \acrshort{ai} model. Therefore, this framework can also be used in a variety of applications: customer service, general \acrshort{faq} services, healthcare, legal advice, technical support and more. 

The custom fine-tuned T5 chatbot (see Section \ref{sec:methodology_t5}) has no ongoing dependency on \acrshort{gpt} or OpenAI in general. It is completely open-source (if \acrshort{gpt} embeddings are not used) and can be run without a \acrshort{gpu}.

\section{Limitations}
There are several limitations to the findings in this paper. Firstly, T5 was the only model fine-tuned for question-answering, and was chosen because of the availability of the `small' variant. However, other models such as \acrshort{bart} are available and could have produced better outcomes.

The second limitation pertains to the evaluation process. Due to limited access to the high-performance \acrshort{gpu}s required to fine-tune the models, nested cross-validation was not used to provide a generalisation error. Therefore, the results may not be a reliable estimate of the generalisation error. If more resources were available for this research, the generalisation error and optimal hyperparameters could be found using grid search or otherwise, which could have also improved model performance.

Qualitative output from the T5 model demonstrates the model can claim that a question cannot be answered using the context, even when it can. Additionally, answers often fail to contain explanatory reasoning, which is likely to be a consequence of the dataset used and the quality of answers. Use of an improved dataset with more diverse, higher quality answers could improve the model further. 

The final limitation is that the \acrshort{gpt}-3.5 Turbo model requires ongoing use of the OpenAI \acrshort{api}, which may be discontinued in the future.